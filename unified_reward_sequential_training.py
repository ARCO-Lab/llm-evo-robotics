#!/usr/bin/env python3
"""
ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„å®Œæ•´ä¾æ¬¡è®­ç»ƒè„šæœ¬ï¼š
ğŸ¯ åŸºäºGPT-5å»ºè®®ï¼Œå®ç°æ‰€æœ‰å…³èŠ‚æ•°çš„å¥–åŠ±å¯æ¯”æ€§
ğŸ”§ æ ¸å¿ƒæ”¹è¿›ï¼š
   1. è·ç¦»å½’ä¸€åŒ–ï¼šç”¨å¯è¾¾åŠå¾„Rå½’ä¸€åŒ–è·ç¦»
   2. æˆåŠŸé˜ˆå€¼å½’ä¸€åŒ–ï¼šSUCCESS_THRESHOLD = k * Rï¼Œç»Ÿä¸€k=0.25
   3. æˆåŠŸå¥–åŠ±ä¸è·ç¦»é¡¹é‡çº§åŒ¹é…ï¼šsuccess_bonus=+2.0
   4. æ§åˆ¶ä»£ä»·æŒ‰å…³èŠ‚æ•°å‡å€¼åŒ–ï¼šé¿å…å¤šå…³èŠ‚å¹³ç™½å¤šæƒ©ç½š
   5. ç›®æ ‡åˆ†å¸ƒç»Ÿä¸€æŒ‰Rå–æ¯”ä¾‹ï¼šä¿è¯å¯åˆ°è¾¾æ€§ä¸€è‡´
   6. åŠ¨åŠ›å­¦æ—¶é—´å°ºåº¦ä¸€è‡´ï¼šç»Ÿä¸€gearã€è´¨é‡ã€é˜»å°¼
"""

import os
import numpy as np
import gymnasium as gym
import torch
import torch.nn as nn
from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.evaluation import evaluate_policy
import time
import tempfile
from gymnasium.envs.mujoco import MujocoEnv
from gymnasium.spaces import Box

# è®¾ç½®æ¸²æŸ“ç¯å¢ƒå˜é‡
os.environ['MUJOCO_GL'] = 'glfw'
os.environ['MUJOCO_RENDERER'] = 'glfw'

# ğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒå‚æ•°
SUCCESS_THRESHOLD_RATIO = 0.25  # k = 0.25ï¼ŒæˆåŠŸé˜ˆå€¼ä¸å¯è¾¾åŠå¾„çš„æ¯”ä¾‹
DISTANCE_WEIGHT = 1.0          # w_d = 1.0ï¼Œè·ç¦»é¡¹æƒé‡
SUCCESS_BONUS = 2.0            # æˆåŠŸå¥–åŠ±ï¼Œä¸å½’ä¸€åŒ–è·ç¦»é¡¹é‡çº§åŒ¹é…
CONTROL_WEIGHT = 0.01          # Î»_u = 0.01ï¼Œæ§åˆ¶ä»£ä»·æƒé‡
TARGET_MIN_RATIO = 0.15        # ç›®æ ‡æœ€å°è·ç¦»æ¯”ä¾‹
TARGET_MAX_RATIO = 0.85        # ç›®æ ‡æœ€å¤§è·ç¦»æ¯”ä¾‹

class UnifiedRewardExtractor(BaseFeaturesExtractor):
    """ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„ç‰¹å¾æå–å™¨"""
    
    def __init__(self, observation_space: gym.Space, features_dim: int = 128):
        super(UnifiedRewardExtractor, self).__init__(observation_space, features_dim)
        
        obs_dim = observation_space.shape[0]
        
        print(f"ğŸ”§ UnifiedRewardExtractor: {obs_dim}ç»´ -> {features_dim}ç»´")
        
        # ç®€åŒ–ç½‘ç»œç»“æ„ï¼Œç§»é™¤Dropout
        self.net = nn.Sequential(
            nn.Linear(obs_dim, 256),
            nn.ReLU(),
            nn.LayerNorm(256),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.LayerNorm(256),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.LayerNorm(128),
            nn.Linear(128, features_dim),
            nn.ReLU()
        )
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        return self.net(observations)

class UnifiedRewardReacherEnv(MujocoEnv):
    """ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„Reacherç¯å¢ƒåŸºç±»"""
    
    def __init__(self, xml_content, num_joints, link_lengths, render_mode=None, **kwargs):
        self.num_joints = num_joints
        self.link_lengths = link_lengths
        
        # ğŸ¯ è®¡ç®—å¯è¾¾åŠå¾„Rå’Œç»Ÿä¸€çš„æˆåŠŸé˜ˆå€¼
        self.max_reach = sum(link_lengths)
        self.success_threshold = SUCCESS_THRESHOLD_RATIO * self.max_reach
        
        # åˆ›å»ºä¸´æ—¶XMLæ–‡ä»¶
        self.xml_file = tempfile.NamedTemporaryFile(mode='w', suffix='.xml', delete=False)
        self.xml_file.write(xml_content)
        self.xml_file.flush()
        
        # è®¡ç®—è§‚å¯Ÿç©ºé—´ç»´åº¦
        obs_dim = num_joints * 3 + 4  # cos, sin, vel + ee_pos + target_pos
        observation_space = Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float64)
        
        super().__init__(
            self.xml_file.name,
            frame_skip=2,
            observation_space=observation_space,
            render_mode=render_mode
        )
        
        self.step_count = 0
        self.max_episode_steps = 100
        
        print(f"âœ… {num_joints}å…³èŠ‚Reacheråˆ›å»ºå®Œæˆ (ç»Ÿä¸€å¥–åŠ±è§„èŒƒ)")
        print(f"   é“¾é•¿: {link_lengths}")
        print(f"   ğŸ¯ å¯è¾¾åŠå¾„R: {self.max_reach:.3f}")
        print(f"   ğŸ¯ æˆåŠŸé˜ˆå€¼: {self.success_threshold:.3f} ({SUCCESS_THRESHOLD_RATIO:.1%} * R)")
        print(f"   ğŸ¯ ç›®æ ‡ç”ŸæˆèŒƒå›´: {self.calculate_target_min_distance():.3f} ~ {self.calculate_target_max_distance():.3f}")
    
    def calculate_target_min_distance(self):
        """è®¡ç®—ç›®æ ‡ç”Ÿæˆçš„æœ€å°è·ç¦»"""
        return TARGET_MIN_RATIO * self.max_reach
    
    def calculate_target_max_distance(self):
        """è®¡ç®—ç›®æ ‡ç”Ÿæˆçš„æœ€å¤§è·ç¦»"""
        return TARGET_MAX_RATIO * self.max_reach
    
    def generate_unified_target(self):
        """ğŸ¯ ç»Ÿä¸€çš„ç›®æ ‡ç”Ÿæˆç­–ç•¥ - æŒ‰Rå–æ¯”ä¾‹"""
        min_distance = self.calculate_target_min_distance()
        max_distance = self.calculate_target_max_distance()
        
        # ä½¿ç”¨æåæ ‡ç”Ÿæˆç›®æ ‡
        target_distance = self.np_random.uniform(min_distance, max_distance)
        target_angle = self.np_random.uniform(-np.pi, np.pi)
        
        target_x = target_distance * np.cos(target_angle)
        target_y = target_distance * np.sin(target_angle)
        
        return target_x, target_y
    
    def step(self, action):
        # æ˜¾å¼æ¸²æŸ“
        if self.render_mode == 'human':
            self.render()
        
        self.do_simulation(action, self.frame_skip)
        
        observation = self._get_obs()
        reward = self.unified_reward(action)
        
        # è®¡ç®—å½’ä¸€åŒ–è·ç¦»
        fingertip_pos = self.get_body_com("fingertip")[:2]
        target_pos = self.get_body_com("target")[:2]
        distance = np.linalg.norm(fingertip_pos - target_pos)
        normalized_distance = distance / self.max_reach
        
        # ğŸ¯ ç»Ÿä¸€çš„æˆåŠŸåˆ¤æ–­ï¼šè·ç¦»å°äºç»Ÿä¸€çš„æˆåŠŸé˜ˆå€¼
        terminated = distance < self.success_threshold
        
        self.step_count += 1
        truncated = self.step_count >= self.max_episode_steps
        
        info = {
            'distance_to_target': distance,
            'normalized_distance': normalized_distance,
            'is_success': terminated,
            'max_reach': self.max_reach,
            'success_threshold': self.success_threshold,
            'fingertip_pos': fingertip_pos.copy(),
            'target_pos': target_pos.copy()
        }
        
        return observation, reward, terminated, truncated, info
    
    def unified_reward(self, action):
        """ğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„å¥–åŠ±å‡½æ•°"""
        fingertip_pos = self.get_body_com("fingertip")[:2]
        target_pos = self.get_body_com("target")[:2]
        distance = np.linalg.norm(fingertip_pos - target_pos)
        
        # 1. ğŸ¯ è·ç¦»å½’ä¸€åŒ–ï¼šç”¨å¯è¾¾åŠå¾„Rå½’ä¸€åŒ–
        normalized_distance = distance / self.max_reach
        distance_reward = -DISTANCE_WEIGHT * normalized_distance
        
        # 2. ğŸ¯ æˆåŠŸå¥–åŠ±ï¼šä¸è·ç¦»é¡¹é‡çº§åŒ¹é…
        success_reward = SUCCESS_BONUS if distance < self.success_threshold else 0.0
        
        # 3. ğŸ¯ æ§åˆ¶ä»£ä»·æŒ‰å…³èŠ‚æ•°å‡å€¼åŒ–ï¼šé¿å…å¤šå…³èŠ‚å¹³ç™½å¤šæƒ©ç½š
        control_cost = -CONTROL_WEIGHT * np.mean(np.square(action))
        
        total_reward = distance_reward + success_reward + control_cost
        
        return total_reward
    
    def _get_obs(self):
        # Nå…³èŠ‚çš„è§‚å¯Ÿï¼šcos, sin, vel, fingertip_pos, target_pos
        theta = self.data.qpos.flat[:self.num_joints]
        obs = np.concatenate([
            np.cos(theta),                    # Nä¸ªcoså€¼
            np.sin(theta),                    # Nä¸ªsinå€¼
            self.data.qvel.flat[:self.num_joints],  # Nä¸ªå…³èŠ‚é€Ÿåº¦
            self.get_body_com("fingertip")[:2],     # æœ«ç«¯æ‰§è¡Œå™¨ä½ç½® (x,y)
            self.get_body_com("target")[:2],        # ç›®æ ‡ä½ç½® (x,y)
        ])
        return obs
    
    def reset_model(self):
        # é‡ç½®ç­–ç•¥
        qpos = self.init_qpos + self.np_random.uniform(low=-0.1, high=0.1, size=self.model.nq)
        qvel = self.init_qvel.copy()
        
        # åªç»™æœºæ¢°è‡‚å…³èŠ‚æ·»åŠ éšæœºé€Ÿåº¦ï¼Œç›®æ ‡å…³èŠ‚é€Ÿåº¦ä¿æŒä¸º0
        qvel[:self.num_joints] += self.np_random.standard_normal(self.num_joints) * 0.1
        
        # ğŸ¯ ä½¿ç”¨ç»Ÿä¸€çš„ç›®æ ‡ç”Ÿæˆç­–ç•¥
        target_x, target_y = self.generate_unified_target()
        qpos[-2:] = [target_x, target_y]
        
        self.set_state(qpos, qvel)
        self.step_count = 0
        return self._get_obs()

# ğŸ¯ ç»Ÿä¸€åŠ¨åŠ›å­¦æ—¶é—´å°ºåº¦çš„XMLé…ç½®
def get_unified_2joint_xml():
    """2å…³èŠ‚XMLé…ç½®ï¼ˆç»Ÿä¸€åŠ¨åŠ›å­¦å‚æ•°ï¼‰"""
    return """
<mujoco model="unified_2joint_reacher">
  <compiler angle="radian" inertiafromgeom="true"/>
  <default>
    <joint armature="1" damping="1" limited="true"/>
    <geom contype="0" friction="1 0.1 0.1" rgba="0.7 0.7 0 1" density="1000"/>
  </default>
  <option gravity="0 0 -9.81" integrator="RK4" timestep="0.01"/>
  <worldbody>
    <geom conaffinity="0" contype="0" name="ground" pos="0 0 0" rgba="0.9 0.9 0.9 1" size="1 1 10" type="plane"/>
    <geom conaffinity="0" fromto="-.3 -.3 .01 .3 -.3 .01" name="sideS" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto=" .3 -.3 .01 .3  .3 .01" name="sideE" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.3  .3 .01 .3  .3 .01" name="sideN" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.3 -.3 .01 -.3 .3 .01" name="sideW" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" contype="0" fromto="0 0 0 0 0 0.02" name="root" rgba="0.9 0.4 0.6 1" size=".011" type="cylinder"/>
    <body name="body0" pos="0 0 .01">
      <geom fromto="0 0 0 0.1 0 0" name="link0" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
      <joint axis="0 0 1" limited="false" name="joint0" pos="0 0 0" type="hinge"/>
      <body name="body1" pos="0.1 0 0">
        <joint axis="0 0 1" limited="true" name="joint1" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
        <geom fromto="0 0 0 0.1 0 0" name="link1" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
        <body name="fingertip" pos="0.11 0 0">
          <geom contype="0" name="fingertip" pos="0 0 0" rgba="0.0 0.8 0.6 1" size=".01" type="sphere"/>
        </body>
      </body>
    </body>
    <body name="target" pos=".2 -.2 .01">
      <joint armature="0" axis="1 0 0" damping="0" limited="true" name="target_x" pos="0 0 0" range="-.27 .27" ref=".2" stiffness="0" type="slide"/>
      <joint armature="0" axis="0 1 0" damping="0" limited="true" name="target_y" pos="0 0 0" range="-.27 .27" ref="-.2" stiffness="0" type="slide"/>
      <geom conaffinity="0" contype="0" name="target" pos="0 0 0" rgba="0.9 0.2 0.2 1" size=".009" type="sphere"/>
    </body>
  </worldbody>
  <actuator>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint0"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint1"/>
  </actuator>
</mujoco>
"""

def get_unified_3joint_xml():
    """3å…³èŠ‚XMLé…ç½®ï¼ˆç»Ÿä¸€åŠ¨åŠ›å­¦å‚æ•°ï¼‰"""
    return """
<mujoco model="unified_3joint_reacher">
  <compiler angle="radian" inertiafromgeom="true"/>
  <default>
    <joint armature="1" damping="1" limited="true"/>
    <geom contype="0" friction="1 0.1 0.1" rgba="0.7 0.7 0 1" density="1000"/>
  </default>
  <option gravity="0 0 -9.81" integrator="RK4" timestep="0.01"/>
  <worldbody>
    <geom conaffinity="0" contype="0" name="ground" pos="0 0 0" rgba="0.9 0.9 0.9 1" size="0.5 0.5 10" type="plane"/>
    <geom conaffinity="0" fromto="-.5 -.5 .01 .5 -.5 .01" name="sideS" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto=" .5 -.5 .01 .5  .5 .01" name="sideE" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.5  .5 .01 .5  .5 .01" name="sideN" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.5 -.5 .01 -.5 .5 .01" name="sideW" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" contype="0" fromto="0 0 0 0 0 0.02" name="root" rgba="0.9 0.4 0.6 1" size=".011" type="cylinder"/>
    <body name="body0" pos="0 0 .01">
      <geom fromto="0 0 0 0.1 0 0" name="link0" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
      <joint axis="0 0 1" limited="false" name="joint0" pos="0 0 0" type="hinge"/>
      <body name="body1" pos="0.1 0 0">
        <joint axis="0 0 1" limited="true" name="joint1" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
        <geom fromto="0 0 0 0.1 0 0" name="link1" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
        <body name="body2" pos="0.1 0 0">
          <joint axis="0 0 1" limited="true" name="joint2" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
          <geom fromto="0 0 0 0.1 0 0" name="link2" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
          <body name="fingertip" pos="0.11 0 0">
            <geom contype="0" name="fingertip" pos="0 0 0" rgba="0.0 0.8 0.6 1" size=".01" type="sphere"/>
          </body>
        </body>
      </body>
    </body>
    <body name="target" pos=".2 -.2 .01">
      <joint armature="0" axis="1 0 0" damping="0" limited="true" name="target_x" pos="0 0 0" range="-.5 .5" ref=".2" stiffness="0" type="slide"/>
      <joint armature="0" axis="0 1 0" damping="0" limited="true" name="target_y" pos="0 0 0" range="-.5 .5" ref="-.2" stiffness="0" type="slide"/>
      <geom conaffinity="0" contype="0" name="target" pos="0 0 0" rgba="0.9 0.2 0.2 1" size=".009" type="sphere"/>
    </body>
  </worldbody>
  <actuator>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint0"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint1"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint2"/>
  </actuator>
</mujoco>
"""

def get_unified_4joint_xml():
    """4å…³èŠ‚XMLé…ç½®ï¼ˆç»Ÿä¸€åŠ¨åŠ›å­¦å‚æ•°ï¼‰"""
    return """
<mujoco model="unified_4joint_reacher">
  <compiler angle="radian" inertiafromgeom="true"/>
  <default>
    <joint armature="1" damping="1" limited="true"/>
    <geom contype="0" friction="1 0.1 0.1" rgba="0.7 0.7 0 1" density="1000"/>
  </default>
  <option gravity="0 0 -9.81" integrator="RK4" timestep="0.01"/>
  <worldbody>
    <geom conaffinity="0" contype="0" name="ground" pos="0 0 0" rgba="0.9 0.9 0.9 1" size="0.6 0.6 10" type="plane"/>
    <geom conaffinity="0" fromto="-.6 -.6 .01 .6 -.6 .01" name="sideS" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto=" .6 -.6 .01 .6  .6 .01" name="sideE" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.6  .6 .01 .6  .6 .01" name="sideN" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.6 -.6 .01 -.6 .6 .01" name="sideW" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" contype="0" fromto="0 0 0 0 0 0.02" name="root" rgba="0.9 0.4 0.6 1" size=".011" type="cylinder"/>
    <body name="body0" pos="0 0 .01">
      <geom fromto="0 0 0 0.08 0 0" name="link0" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
      <joint axis="0 0 1" limited="false" name="joint0" pos="0 0 0" type="hinge"/>
      <body name="body1" pos="0.08 0 0">
        <joint axis="0 0 1" limited="true" name="joint1" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
        <geom fromto="0 0 0 0.08 0 0" name="link1" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
        <body name="body2" pos="0.08 0 0">
          <joint axis="0 0 1" limited="true" name="joint2" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
          <geom fromto="0 0 0 0.08 0 0" name="link2" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
          <body name="body3" pos="0.08 0 0">
            <joint axis="0 0 1" limited="true" name="joint3" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
            <geom fromto="0 0 0 0.08 0 0" name="link3" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
            <body name="fingertip" pos="0.088 0 0">
              <geom contype="0" name="fingertip" pos="0 0 0" rgba="0.0 0.8 0.6 1" size=".01" type="sphere"/>
            </body>
          </body>
        </body>
      </body>
    </body>
    <body name="target" pos=".25 -.25 .01">
      <joint armature="0" axis="1 0 0" damping="0" limited="true" name="target_x" pos="0 0 0" range="-.6 .6" ref=".25" stiffness="0" type="slide"/>
      <joint armature="0" axis="0 1 0" damping="0" limited="true" name="target_y" pos="0 0 0" range="-.6 .6" ref="-.25" stiffness="0" type="slide"/>
      <geom conaffinity="0" contype="0" name="target" pos="0 0 0" rgba="0.9 0.2 0.2 1" size=".009" type="sphere"/>
    </body>
  </worldbody>
  <actuator>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint0"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint1"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint2"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint3"/>
  </actuator>
</mujoco>
"""

def get_unified_5joint_xml():
    """5å…³èŠ‚XMLé…ç½®ï¼ˆç»Ÿä¸€åŠ¨åŠ›å­¦å‚æ•°ï¼‰"""
    return """
<mujoco model="unified_5joint_reacher">
  <compiler angle="radian" inertiafromgeom="true"/>
  <default>
    <joint armature="1" damping="1" limited="true"/>
    <geom contype="0" friction="1 0.1 0.1" rgba="0.7 0.7 0 1" density="1000"/>
  </default>
  <option gravity="0 0 -9.81" integrator="RK4" timestep="0.01"/>
  <worldbody>
    <geom conaffinity="0" contype="0" name="ground" pos="0 0 0" rgba="0.9 0.9 0.9 1" size="0.7 0.7 10" type="plane"/>
    <geom conaffinity="0" fromto="-.7 -.7 .01 .7 -.7 .01" name="sideS" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto=" .7 -.7 .01 .7  .7 .01" name="sideE" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.7  .7 .01 .7  .7 .01" name="sideN" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.7 -.7 .01 -.7 .7 .01" name="sideW" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" contype="0" fromto="0 0 0 0 0 0.02" name="root" rgba="0.9 0.4 0.6 1" size=".011" type="cylinder"/>
    <body name="body0" pos="0 0 .01">
      <geom fromto="0 0 0 0.06 0 0" name="link0" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
      <joint axis="0 0 1" limited="false" name="joint0" pos="0 0 0" type="hinge"/>
      <body name="body1" pos="0.06 0 0">
        <joint axis="0 0 1" limited="true" name="joint1" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
        <geom fromto="0 0 0 0.06 0 0" name="link1" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
        <body name="body2" pos="0.06 0 0">
          <joint axis="0 0 1" limited="true" name="joint2" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
          <geom fromto="0 0 0 0.06 0 0" name="link2" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
          <body name="body3" pos="0.06 0 0">
            <joint axis="0 0 1" limited="true" name="joint3" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
            <geom fromto="0 0 0 0.06 0 0" name="link3" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
            <body name="body4" pos="0.06 0 0">
              <joint axis="0 0 1" limited="true" name="joint4" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
              <geom fromto="0 0 0 0.06 0 0" name="link4" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
              <body name="fingertip" pos="0.066 0 0">
                <geom contype="0" name="fingertip" pos="0 0 0" rgba="0.0 0.8 0.6 1" size=".01" type="sphere"/>
              </body>
            </body>
          </body>
        </body>
      </body>
    </body>
    <body name="target" pos=".3 -.3 .01">
      <joint armature="0" axis="1 0 0" damping="0" limited="true" name="target_x" pos="0 0 0" range="-.7 .7" ref=".3" stiffness="0" type="slide"/>
      <joint armature="0" axis="0 1 0" damping="0" limited="true" name="target_y" pos="0 0 0" range="-.7 .7" ref="-.3" stiffness="0" type="slide"/>
      <geom conaffinity="0" contype="0" name="target" pos="0 0 0" rgba="0.9 0.2 0.2 1" size=".009" type="sphere"/>
    </body>
  </worldbody>
  <actuator>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint0"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint1"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint2"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint3"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint4"/>
  </actuator>
</mujoco>
"""

# ç¯å¢ƒç±»
class Unified2JointReacherEnv(UnifiedRewardReacherEnv):
    """ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„2å…³èŠ‚Reacherç¯å¢ƒ"""
    
    def __init__(self, render_mode=None, **kwargs):
        print("ğŸŒŸ Unified2JointReacherEnv åˆå§‹åŒ–")
        
        super().__init__(
            xml_content=get_unified_2joint_xml(),
            num_joints=2,
            link_lengths=[0.1, 0.1],
            render_mode=render_mode,
            **kwargs
        )

class Unified3JointReacherEnv(UnifiedRewardReacherEnv):
    """ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„3å…³èŠ‚Reacherç¯å¢ƒ"""
    
    def __init__(self, render_mode=None, **kwargs):
        print("ğŸŒŸ Unified3JointReacherEnv åˆå§‹åŒ–")
        
        super().__init__(
            xml_content=get_unified_3joint_xml(),
            num_joints=3,
            link_lengths=[0.1, 0.1, 0.1],
            render_mode=render_mode,
            **kwargs
        )

class Unified4JointReacherEnv(UnifiedRewardReacherEnv):
    """ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„4å…³èŠ‚Reacherç¯å¢ƒ"""
    
    def __init__(self, render_mode=None, **kwargs):
        print("ğŸŒŸ Unified4JointReacherEnv åˆå§‹åŒ–")
        
        super().__init__(
            xml_content=get_unified_4joint_xml(),
            num_joints=4,
            link_lengths=[0.08, 0.08, 0.08, 0.08],
            render_mode=render_mode,
            **kwargs
        )

class Unified5JointReacherEnv(UnifiedRewardReacherEnv):
    """ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„5å…³èŠ‚Reacherç¯å¢ƒ"""
    
    def __init__(self, render_mode=None, **kwargs):
        print("ğŸŒŸ Unified5JointReacherEnv åˆå§‹åŒ–")
        
        super().__init__(
            xml_content=get_unified_5joint_xml(),
            num_joints=5,
            link_lengths=[0.06, 0.06, 0.06, 0.06, 0.06],
            render_mode=render_mode,
            **kwargs
        )

# ğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„2å…³èŠ‚åŒ…è£…å™¨ï¼ˆç”¨äºæ ‡å‡†Reacher-v5ï¼‰
class Unified2JointReacherWrapper(gym.Wrapper):
    """ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„2å…³èŠ‚ReacheråŒ…è£…å™¨ - ä½¿ç”¨æ ‡å‡†Reacher-v5"""
    
    def __init__(self, env):
        super().__init__(env)
        self.link_lengths = [0.1, 0.1]
        self.max_episode_steps = 100
        
        # ğŸ¯ è®¡ç®—å¯è¾¾åŠå¾„Rå’Œç»Ÿä¸€çš„æˆåŠŸé˜ˆå€¼
        self.max_reach = sum(self.link_lengths)
        self.success_threshold = SUCCESS_THRESHOLD_RATIO * self.max_reach
        
        print("ğŸŒŸ Unified2JointReacherWrapper åˆå§‹åŒ–")
        print(f"   é“¾é•¿: {self.link_lengths}")
        print(f"   ğŸ¯ å¯è¾¾åŠå¾„R: {self.max_reach:.3f}")
        print(f"   ğŸ¯ æˆåŠŸé˜ˆå€¼: {self.success_threshold:.3f} ({SUCCESS_THRESHOLD_RATIO:.1%} * R)")
        print(f"   ğŸ¯ ç›®æ ‡ç”ŸæˆèŒƒå›´: {self.calculate_target_min_distance():.3f} ~ {self.calculate_target_max_distance():.3f}")
    
    def calculate_target_min_distance(self):
        return TARGET_MIN_RATIO * self.max_reach
    
    def calculate_target_max_distance(self):
        return TARGET_MAX_RATIO * self.max_reach
    
    def generate_unified_target(self):
        min_distance = self.calculate_target_min_distance()
        max_distance = self.calculate_target_max_distance()
        
        target_distance = self.np_random.uniform(min_distance, max_distance)
        target_angle = self.np_random.uniform(-np.pi, np.pi)
        
        target_x = target_distance * np.cos(target_angle)
        target_y = target_distance * np.sin(target_angle)
        
        return target_x, target_y
    
    def reset(self, **kwargs):
        obs, info = self.env.reset(**kwargs)
        
        # åº”ç”¨ç»Ÿä¸€çš„ç›®æ ‡ç”Ÿæˆç­–ç•¥
        target_x, target_y = self.generate_unified_target()
        
        # ä¿®å¤ç›®æ ‡æ»šåŠ¨é—®é¢˜
        reacher_env = self.env.unwrapped
        qpos = reacher_env.data.qpos.copy()
        qvel = reacher_env.data.qvel.copy()
        
        qpos[-2:] = [target_x, target_y]
        qvel[-2:] = [0.0, 0.0]
        
        reacher_env.set_state(qpos, qvel)
        
        # è·å–æ–°çš„è§‚å¯Ÿ
        obs = reacher_env._get_obs()
        
        if info is None:
            info = {}
        info.update({
            'max_reach': self.max_reach,
            'success_threshold': self.success_threshold,
            'target_pos': [target_x, target_y]
        })
        
        return obs, info
    
    def step(self, action):
        obs, reward, terminated, truncated, info = self.env.step(action)
        
        # ğŸ¯ é‡æ–°è®¡ç®—ç»Ÿä¸€å¥–åŠ±
        reacher_env = self.env.unwrapped
        fingertip_pos = reacher_env.get_body_com("fingertip")[:2]
        target_pos = reacher_env.get_body_com("target")[:2]
        distance = np.linalg.norm(fingertip_pos - target_pos)
        
        # ğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒ
        normalized_distance = distance / self.max_reach
        distance_reward = -DISTANCE_WEIGHT * normalized_distance
        success_reward = SUCCESS_BONUS if distance < self.success_threshold else 0.0
        control_cost = -CONTROL_WEIGHT * np.mean(np.square(action))
        
        unified_reward = distance_reward + success_reward + control_cost
        
        # ğŸ¯ ç»Ÿä¸€çš„æˆåŠŸåˆ¤æ–­
        is_success = distance < self.success_threshold
        
        if info is None:
            info = {}
        info.update({
            'max_reach': self.max_reach,
            'success_threshold': self.success_threshold,
            'distance_to_target': distance,
            'normalized_distance': normalized_distance,
            'is_success': is_success,
            'fingertip_pos': fingertip_pos.copy(),
            'target_pos': target_pos.copy()
        })
        
        return obs, unified_reward, terminated, truncated, info

def create_unified_env(num_joints, render_mode=None):
    """åˆ›å»ºæŒ‡å®šå…³èŠ‚æ•°çš„ç»Ÿä¸€å¥–åŠ±ç¯å¢ƒ"""
    if num_joints == 2:
        # ä½¿ç”¨æ ‡å‡†Reacher-v5 + ç»Ÿä¸€å¥–åŠ±åŒ…è£…å™¨
        env = gym.make('Reacher-v5', render_mode=render_mode)
        env = Unified2JointReacherWrapper(env)
    elif num_joints == 3:
        env = Unified3JointReacherEnv(render_mode=render_mode)
    elif num_joints == 4:
        env = Unified4JointReacherEnv(render_mode=render_mode)
    elif num_joints == 5:
        env = Unified5JointReacherEnv(render_mode=render_mode)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å…³èŠ‚æ•°: {num_joints}")
    
    env = Monitor(env)
    return env

def train_unified_model(num_joints, total_timesteps=30000):
    """è®­ç»ƒç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„å•ä¸ªå…³èŠ‚æ•°æ¨¡å‹"""
    print(f"\\nğŸš€ å¼€å§‹è®­ç»ƒç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„{num_joints}å…³èŠ‚Reacheræ¨¡å‹")
    print(f"ğŸ“Š è®­ç»ƒæ­¥æ•°: {total_timesteps}")
    print(f"ğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒ:")
    print(f"   - æˆåŠŸé˜ˆå€¼æ¯”ä¾‹: {SUCCESS_THRESHOLD_RATIO:.1%}")
    print(f"   - è·ç¦»æƒé‡: {DISTANCE_WEIGHT}")
    print(f"   - æˆåŠŸå¥–åŠ±: {SUCCESS_BONUS}")
    print(f"   - æ§åˆ¶æƒé‡: {CONTROL_WEIGHT}")
    print(f"   - ç›®æ ‡èŒƒå›´: {TARGET_MIN_RATIO:.1%} ~ {TARGET_MAX_RATIO:.1%} * R")
    print("="*60)
    
    # åˆ›å»ºè®­ç»ƒç¯å¢ƒï¼ˆå¼€å¯æ¸²æŸ“ï¼‰
    train_env = create_unified_env(num_joints, render_mode='human')
    
    # åˆ›å»ºSACæ¨¡å‹
    policy_kwargs = {
        'features_extractor_class': UnifiedRewardExtractor,
        'features_extractor_kwargs': {'features_dim': 128},
    }
    
    model = SAC(
        'MlpPolicy',
        train_env,
        policy_kwargs=policy_kwargs,
        verbose=2,
        learning_starts=1000,
        device='cpu',
        tensorboard_log=f"./tensorboard_logs/unified_reward_{num_joints}joint/",
        batch_size=256,
        buffer_size=100000,
        learning_rate=3e-4,
        gamma=0.99,
        tau=0.005,
    )
    
    print(f"âœ… ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„{num_joints}å…³èŠ‚SACæ¨¡å‹åˆ›å»ºå®Œæˆ")
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\\nğŸ¯ å¼€å§‹{num_joints}å…³èŠ‚è®­ç»ƒ...")
    
    try:
        start_time = time.time()
        
        model.learn(
            total_timesteps=total_timesteps,
            log_interval=4,
            progress_bar=True
        )
        
        training_time = time.time() - start_time
        
        print(f"\\nâœ… {num_joints}å…³èŠ‚è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸ è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
        print(f"ğŸ“Š å¹³å‡FPS: {total_timesteps/training_time:.1f}")
        
        # ä¿å­˜æ¨¡å‹
        model_path = f"models/unified_reward_{num_joints}joint_reacher"
        model.save(model_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        return model, training_time
        
    except KeyboardInterrupt:
        training_time = time.time() - start_time
        print(f"\\nâš ï¸ {num_joints}å…³èŠ‚è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        print(f"â±ï¸ å·²è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
        
        model_path = f"models/unified_reward_{num_joints}joint_reacher_interrupted"
        model.save(model_path)
        print(f"ğŸ’¾ ä¸­æ–­æ¨¡å‹å·²ä¿å­˜: {model_path}")
        return model, training_time
    
    finally:
        train_env.close()

def test_unified_model(num_joints, model, n_eval_episodes=10):
    """æµ‹è¯•ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„å•ä¸ªå…³èŠ‚æ•°æ¨¡å‹"""
    print(f"\\nğŸ§ª å¼€å§‹æµ‹è¯•ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„{num_joints}å…³èŠ‚æ¨¡å‹")
    print(f"ğŸ“Š æµ‹è¯•episodes: {n_eval_episodes}, æ¯ä¸ªepisode: 100æ­¥")
    print("-"*40)
    
    # åˆ›å»ºæµ‹è¯•ç¯å¢ƒï¼ˆå¸¦æ¸²æŸ“ï¼‰
    test_env = create_unified_env(num_joints, render_mode='human')
    
    try:
        # æ‰‹åŠ¨è¿è¡Œepisodesæ¥è®¡ç®—æˆåŠŸç‡
        success_episodes = 0
        total_episodes = n_eval_episodes
        episode_rewards = []
        episode_distances = []
        episode_normalized_distances = []
        
        for episode in range(n_eval_episodes):
            obs, info = test_env.reset()
            episode_reward = 0
            episode_success = False
            min_distance = float('inf')
            min_normalized_distance = float('inf')
            
            # è·å–ç¯å¢ƒä¿¡æ¯
            max_reach = info.get('max_reach', 1.0)
            success_threshold = info.get('success_threshold', 0.05)
            
            for step in range(100):  # æ¯ä¸ªepisode 100æ­¥
                action, _ = model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = test_env.step(action)
                episode_reward += reward
                
                # è·å–è·ç¦»å’ŒæˆåŠŸä¿¡æ¯
                distance = info.get('distance_to_target', float('inf'))
                normalized_distance = info.get('normalized_distance', float('inf'))
                is_success = info.get('is_success', False)
                
                min_distance = min(min_distance, distance)
                min_normalized_distance = min(min_normalized_distance, normalized_distance)
                
                if is_success and not episode_success:
                    episode_success = True
                
                if terminated or truncated:
                    break
            
            if episode_success:
                success_episodes += 1
            
            episode_rewards.append(episode_reward)
            episode_distances.append(min_distance)
            episode_normalized_distances.append(min_normalized_distance)
            
            print(f"   Episode {episode+1}: å¥–åŠ±={episode_reward:.2f}, æœ€å°è·ç¦»={min_distance:.4f}, å½’ä¸€åŒ–è·ç¦»={min_normalized_distance:.3f}, æˆåŠŸ={'âœ…' if episode_success else 'âŒ'}")
        
        success_rate = success_episodes / total_episodes
        avg_reward = np.mean(episode_rewards)
        avg_min_distance = np.mean(episode_distances)
        avg_normalized_distance = np.mean(episode_normalized_distances)
        
        print(f"\\nğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„{num_joints}å…³èŠ‚æ¨¡å‹æµ‹è¯•ç»“æœ:")
        print(f"   æˆåŠŸç‡: {success_rate:.1%} ({success_episodes}/{total_episodes})")
        print(f"   å¹³å‡å¥–åŠ±: {avg_reward:.2f}")
        print(f"   å¹³å‡æœ€å°è·ç¦»: {avg_min_distance:.4f}")
        print(f"   å¹³å‡å½’ä¸€åŒ–è·ç¦»: {avg_normalized_distance:.3f}")
        print(f"   ğŸ¯ å¯è¾¾åŠå¾„R: {max_reach:.3f}")
        print(f"   ğŸ¯ æˆåŠŸé˜ˆå€¼: {success_threshold:.3f} ({SUCCESS_THRESHOLD_RATIO:.1%} * R)")
        
        return {
            'num_joints': num_joints,
            'success_rate': success_rate,
            'success_episodes': success_episodes,
            'total_episodes': total_episodes,
            'avg_reward': avg_reward,
            'avg_min_distance': avg_min_distance,
            'avg_normalized_distance': avg_normalized_distance,
            'max_reach': max_reach,
            'success_threshold': success_threshold,
            'episode_rewards': episode_rewards,
            'episode_distances': episode_distances,
            'episode_normalized_distances': episode_normalized_distances
        }
        
    except KeyboardInterrupt:
        print(f"\\nâš ï¸ {num_joints}å…³èŠ‚æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return None
    
    finally:
        test_env.close()

def main():
    """ä¸»å‡½æ•°ï¼šç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„ä¾æ¬¡è®­ç»ƒå’Œæµ‹è¯•2-5å…³èŠ‚Reacher"""
    print("ğŸŒŸ ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„å®Œæ•´ä¾æ¬¡è®­ç»ƒå’Œæµ‹è¯•2-5å…³èŠ‚Reacherç³»ç»Ÿ")
    print("ğŸ¯ åŸºäºGPT-5å»ºè®®ï¼Œå®ç°æ‰€æœ‰å…³èŠ‚æ•°çš„å¥–åŠ±å¯æ¯”æ€§")
    print(f"ğŸ“Š é…ç½®: æ¯ä¸ªæ¨¡å‹è®­ç»ƒ30000æ­¥ï¼Œæµ‹è¯•10ä¸ªepisodes")
    print("ğŸ”§ ç»Ÿä¸€å¥–åŠ±è§„èŒƒ:")
    print(f"   1. è·ç¦»å½’ä¸€åŒ–: ç”¨å¯è¾¾åŠå¾„Rå½’ä¸€åŒ–è·ç¦»")
    print(f"   2. æˆåŠŸé˜ˆå€¼å½’ä¸€åŒ–: SUCCESS_THRESHOLD = {SUCCESS_THRESHOLD_RATIO:.1%} * R")
    print(f"   3. æˆåŠŸå¥–åŠ±ä¸è·ç¦»é¡¹é‡çº§åŒ¹é…: success_bonus = {SUCCESS_BONUS}")
    print(f"   4. æ§åˆ¶ä»£ä»·æŒ‰å…³èŠ‚æ•°å‡å€¼åŒ–: é¿å…å¤šå…³èŠ‚å¹³ç™½å¤šæƒ©ç½š")
    print(f"   5. ç›®æ ‡åˆ†å¸ƒç»Ÿä¸€æŒ‰Rå–æ¯”ä¾‹: {TARGET_MIN_RATIO:.1%} ~ {TARGET_MAX_RATIO:.1%} * R")
    print(f"   6. åŠ¨åŠ›å­¦æ—¶é—´å°ºåº¦ä¸€è‡´: ç»Ÿä¸€gear=200ã€density=1000ã€damping=1")
    print("ğŸ’¾ è¾“å‡º: æ¯ä¸ªå…³èŠ‚æ•°ä¿å­˜ç‹¬ç«‹çš„æ¨¡å‹æ–‡ä»¶")
    print("ğŸ“ˆ æœ€ç»ˆ: ç»Ÿè®¡æ‰€æœ‰å…³èŠ‚æ•°çš„æˆåŠŸç‡å’Œå½’ä¸€åŒ–è·ç¦»å¯¹æ¯”")
    print()
    
    # ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨
    os.makedirs("models", exist_ok=True)
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_results = []
    training_times = []
    
    # ä¾æ¬¡è®­ç»ƒ2-5å…³èŠ‚
    joint_numbers = [2, 3, 4, 5]
    
    for num_joints in joint_numbers:
        try:
            print(f"\\n{'='*60}")
            print(f"ğŸ”„ å½“å‰è¿›åº¦: {num_joints}å…³èŠ‚ Reacher ({joint_numbers.index(num_joints)+1}/{len(joint_numbers)})")
            print(f"{'='*60}")
            
            # è®­ç»ƒæ¨¡å‹
            model, training_time = train_unified_model(num_joints, total_timesteps=30000)
            training_times.append(training_time)
            
            # æµ‹è¯•æ¨¡å‹
            test_result = test_unified_model(num_joints, model, n_eval_episodes=10)
            
            if test_result:
                all_results.append(test_result)
            
            print(f"\\nâœ… {num_joints}å…³èŠ‚ Reacher å®Œæˆ!")
            
        except KeyboardInterrupt:
            print(f"\\nâš ï¸ åœ¨{num_joints}å…³èŠ‚è®­ç»ƒæ—¶è¢«ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"\\nâŒ {num_joints}å…³èŠ‚è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # è¾“å‡ºæœ€ç»ˆæ€»ç»“
    print(f"\\n{'='*80}")
    print("ğŸ‰ ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„å®Œæ•´ä¾æ¬¡è®­ç»ƒå’Œæµ‹è¯•2-5å…³èŠ‚Reacherå®Œæˆ!")
    print(f"{'='*80}")
    
    if all_results:
        print("\\nğŸ“Š æ‰€æœ‰æ¨¡å‹æ€§èƒ½æ€»ç»“:")
        print("-"*100)
        print(f"{'å…³èŠ‚æ•°':<8} {'æˆåŠŸç‡':<10} {'å¹³å‡å¥–åŠ±':<12} {'å¹³å‡è·ç¦»':<12} {'å½’ä¸€åŒ–è·ç¦»':<12} {'å¯è¾¾åŠå¾„R':<12} {'è®­ç»ƒæ—¶é—´':<10}")
        print("-"*100)
        
        for i, result in enumerate(all_results):
            training_time_min = training_times[i] / 60 if i < len(training_times) else 0
            print(f"{result['num_joints']:<8} {result['success_rate']:<10.1%} {result['avg_reward']:<12.2f} {result['avg_min_distance']:<12.4f} {result['avg_normalized_distance']:<12.3f} {result['max_reach']:<12.3f} {training_time_min:<10.1f}åˆ†é’Ÿ")
        
        print("-"*100)
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model = max(all_results, key=lambda x: x['success_rate'])
        print(f"\\nğŸ† æœ€ä½³æˆåŠŸç‡æ¨¡å‹: {best_model['num_joints']}å…³èŠ‚")
        print(f"   æˆåŠŸç‡: {best_model['success_rate']:.1%}")
        print(f"   å¹³å‡å¥–åŠ±: {best_model['avg_reward']:.2f}")
        print(f"   å¹³å‡å½’ä¸€åŒ–è·ç¦»: {best_model['avg_normalized_distance']:.3f}")
        print(f"   å¯è¾¾åŠå¾„R: {best_model['max_reach']:.3f}")
        
        # ğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒæ•ˆæœåˆ†æ
        print(f"\\nğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒæ•ˆæœåˆ†æ:")
        success_rates = [r['success_rate'] for r in all_results]
        normalized_distances = [r['avg_normalized_distance'] for r in all_results]
        rewards = [r['avg_reward'] for r in all_results]
        
        print(f"   æˆåŠŸç‡ä¸€è‡´æ€§: æ ‡å‡†å·® {np.std(success_rates):.3f} (è¶Šå°è¶Šä¸€è‡´)")
        print(f"   å½’ä¸€åŒ–è·ç¦»ä¸€è‡´æ€§: æ ‡å‡†å·® {np.std(normalized_distances):.3f} (è¶Šå°è¶Šä¸€è‡´)")
        print(f"   å¥–åŠ±ä¸€è‡´æ€§: æ ‡å‡†å·® {np.std(rewards):.3f} (è¶Šå°è¶Šä¸€è‡´)")
        
        # æˆåŠŸç‡è¶‹åŠ¿åˆ†æ
        print(f"\\nğŸ“ˆ æˆåŠŸç‡è¶‹åŠ¿åˆ†æ:")
        joint_nums = [r['num_joints'] for r in all_results]
        
        for i, (joints, rate, norm_dist) in enumerate(zip(joint_nums, success_rates, normalized_distances)):
            trend = ""
            if i > 0:
                prev_rate = success_rates[i-1]
                if rate > prev_rate:
                    trend = f" (â†— +{(rate-prev_rate)*100:.1f}%)"
                elif rate < prev_rate:
                    trend = f" (â†˜ -{(prev_rate-rate)*100:.1f}%)"
                else:
                    trend = " (â†’ æŒå¹³)"
            print(f"   {joints}å…³èŠ‚: æˆåŠŸç‡{rate:.1%}, å½’ä¸€åŒ–è·ç¦»{norm_dist:.3f}{trend}")
        
        # æ¨¡å‹æ–‡ä»¶æ€»ç»“
        print(f"\\nğŸ’¾ æ‰€æœ‰æ¨¡å‹å·²ä¿å­˜åˆ° models/ ç›®å½•:")
        for result in all_results:
            print(f"   - models/unified_reward_{result['num_joints']}joint_reacher.zip")
        
        # è¯¦ç»†ç»Ÿè®¡
        print(f"\\nğŸ“‹ ç»Ÿä¸€å¥–åŠ±è§„èŒƒç»Ÿè®¡:")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {sum(training_times)/60:.1f} åˆ†é’Ÿ")
        print(f"   å¹³å‡æˆåŠŸç‡: {np.mean(success_rates):.1%}")
        print(f"   æˆåŠŸç‡æ ‡å‡†å·®: {np.std(success_rates):.1%}")
        print(f"   å¹³å‡å½’ä¸€åŒ–è·ç¦»: {np.mean(normalized_distances):.3f}")
        print(f"   å½’ä¸€åŒ–è·ç¦»æ ‡å‡†å·®: {np.std(normalized_distances):.3f}")
        print(f"   ğŸ¯ æˆåŠŸé˜ˆå€¼æ¯”ä¾‹: {SUCCESS_THRESHOLD_RATIO:.1%}")
        print(f"   ğŸ¯ è·ç¦»æƒé‡: {DISTANCE_WEIGHT}")
        print(f"   ğŸ¯ æˆåŠŸå¥–åŠ±: {SUCCESS_BONUS}")
        print(f"   ğŸ¯ æ§åˆ¶æƒé‡: {CONTROL_WEIGHT}")
        
        # ç»“è®º
        print(f"\\nğŸ¯ ç»“è®º:")
        if np.std(success_rates) < 0.1:  # æˆåŠŸç‡æ ‡å‡†å·®å°äº10%
            print(f"   âœ… ç»Ÿä¸€å¥–åŠ±è§„èŒƒéå¸¸æˆåŠŸï¼å„å…³èŠ‚æ•°æˆåŠŸç‡ä¸€è‡´æ€§å¾ˆå¥½")
        elif np.std(success_rates) < 0.2:  # æˆåŠŸç‡æ ‡å‡†å·®å°äº20%
            print(f"   âœ… ç»Ÿä¸€å¥–åŠ±è§„èŒƒæ•ˆæœè‰¯å¥½ï¼å„å…³èŠ‚æ•°æˆåŠŸç‡ç›¸å¯¹ä¸€è‡´")
        else:
            print(f"   âš ï¸ ç»Ÿä¸€å¥–åŠ±è§„èŒƒæœ‰ä¸€å®šæ•ˆæœï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
        
        if best_model['success_rate'] > 0.5:
            print(f"   ğŸ† æ•´ä½“è®­ç»ƒæˆåŠŸï¼{best_model['num_joints']}å…³èŠ‚æ¨¡å‹è¡¨ç°æœ€ä½³")
        elif max(success_rates) > 0.3:
            print(f"   âš ï¸ éƒ¨åˆ†æˆåŠŸï¼Œæœ€ä½³æ¨¡å‹æˆåŠŸç‡ä¸º{max(success_rates):.1%}")
        else:
            print(f"   âŒ æ•´ä½“è¡¨ç°è¾ƒå·®ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´å‚æ•°")
    
    print(f"\\nğŸ¯ ç»Ÿä¸€å¥–åŠ±è§„èŒƒçš„å®Œæ•´è®­ç»ƒå®Œæˆï¼å®ç°äº†æ‰€æœ‰å…³èŠ‚æ•°çš„å¥–åŠ±å¯æ¯”æ€§å’Œå…¬å¹³æ€§ã€‚")

if __name__ == "__main__":
    main()


