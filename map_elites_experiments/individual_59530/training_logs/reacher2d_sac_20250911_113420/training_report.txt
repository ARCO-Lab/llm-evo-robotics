Training Report - reacher2d_sac_20250911_113420
================================================================================

📋 实验基本信息:
  实验名称: reacher2d_sac_20250911_113420
  开始时间: 2025-09-11T11:34:20.102542
  结束时间: 2025-09-11T11:34:29.121598
  Python版本: 3.10.12
  平台: posix
  日志目录: ./map_elites_experiments/individual_59530/training_logs/reacher2d_sac_20250911_113420

⚙️ 训练超参数:
  SAC算法参数:
    alpha: 0.6858275248937906
    batch_size: 64
    buffer_capacity: 10000
  训练流程参数:
    warmup_steps: 1000
    seed: 42
    num_processes: 2
    update_frequency: 1
  其他参数:
    learning_rate: 1.2686061632720327e-05
    target_entropy_factor: 0.8
    gamma: 0.99
    total_steps: 120000
    optimizer: Adam
    network_architecture: {'attn_model_dims': '128-130-130-4', 'action_dim': 6}

🌍 环境配置:
  env_name: reacher2d
  env_type: reacher2d
  goal_threshold: 20.0
  action_dim: 6
  num_links: 6
  link_lengths: [76.06690538814658, 77.61905020493052, 63.85134563996502, 59.85154116072559, 45.31278077841106, 99.04435573277809]
  config_path: /home/xli149/Documents/repos/test_robo/examples/2d_reacher/configs/reacher_with_zigzag_obstacles.yaml
  render_mode: None
  reward_function: 距离+进度+成功+碰撞+方向奖励
  physics_engine: PyMunk
  obstacle_type: zigzag
  action_space: continuous
  observation_space: joint_angles_and_positions

📊 训练统计概览:
  总训练步数: 1000
  总训练时间: 0.00 小时
  平均训练速度: 120.66 步/秒
  总Episode数: 10
  平均Episode长度: 100.0 步

📈 训练损失分析:
  critic_loss:
    最终值: 5.313874
    平均值: 5.313874
    标准差: 0.000000
    最小值: 5.313874
    最大值: 5.313874

  actor_loss:
    最终值: -2.552884
    平均值: -2.552884
    标准差: 0.000000
    最小值: -2.552884
    最大值: -2.552884

  alpha_loss:
    最终值: -0.000000
    平均值: 0.000000
    标准差: 0.000000
    最小值: -0.000000
    最大值: -0.000000

  alpha:
    最终值: 0.999987
    平均值: 0.999987
    标准差: 0.000000
    最小值: 0.999987
    最大值: 0.999987

🎯 训练细节统计:
  q1_mean:
    最终值: 0.102910
    平均值: 0.102910
    最小值: 0.102910
    最大值: 0.102910

  q2_mean:
    最终值: -2.180119
    平均值: -2.180119
    最小值: -2.180119
    最大值: -2.180119

  buffer_size:
    最终值: 1002.000000
    平均值: 1002.000000

  learning_rate:
    最终值: 0.000013
    平均值: 0.000013

💡 训练分析建议:
  ❌ Critic Loss过高 (>= 5.0)，需要调整超参数或奖励函数
  ✅ Actor Loss表现优秀 (< -2.0)

================================================================================
