#!/usr/bin/env python3
"""
æ¨¡å—åŒ–é€šç”¨ SAC æ¶æ„
åŸºäº ChatGPT-5 å»ºè®®ï¼šSAC + Set/Graph ç¼–ç å™¨ + é€å…³èŠ‚é«˜æ–¯å¤´ Ã— J_max + å…¨æµç¨‹ mask

è®¾è®¡ç†å¿µï¼š
1. æŠŠæ¯ä¸ªå…³èŠ‚å½“ä½œä¸€ä¸ª"é›†åˆå…ƒç´ /å›¾èŠ‚ç‚¹"
2. ç”¨å…±äº«çš„é€å…³èŠ‚ç¼–ç å™¨æç‰¹å¾
3. ç”¨è½»é‡è‡ªæ³¨æ„åŠ›å»ºæ¨¡å…³èŠ‚é—´äº¤äº’
4. æ³¨æ„åŠ›æ± åŒ–å½¢æˆå…¨å±€ä¸Šä¸‹æ–‡
5. åŠ¨ä½œç«¯ç”¨"é€å…³èŠ‚é«˜æ–¯å¤´Ã—J_max"
6. è®­ç»ƒ/æ‰§è¡Œæ—¶ç”¨ mask ç²¾ç¡®å±è”½ padding å…³èŠ‚
"""

import gymnasium as gym
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import time
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.policies import ActorCriticPolicy
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.evaluation import evaluate_policy
from typing import Dict, List, Tuple, Type, Union, Optional
import math

# ============================================================================
# ğŸ§© æ¨¡å— 1: é€å…³èŠ‚ç¼–ç å™¨ (ç°æˆç»„ä»¶ - ç®€å• MLP)
# ============================================================================

class JointEncoder(nn.Module):
    """
    é€å…³èŠ‚ç¼–ç å™¨ï¼šå°†æ¯ä¸ªå…³èŠ‚çš„åŸå§‹ç‰¹å¾æ˜ å°„åˆ°ç»Ÿä¸€ç»´åº¦
    ç°æˆç»„ä»¶ï¼šæ ‡å‡† MLP
    """
    def __init__(self, joint_input_dim: int = 2, joint_feature_dim: int = 64):
        super(JointEncoder, self).__init__()
        self.joint_input_dim = joint_input_dim
        self.joint_feature_dim = joint_feature_dim
        
        # æ ‡å‡† MLP ç¼–ç å™¨
        self.encoder = nn.Sequential(
            nn.Linear(joint_input_dim, 32),
            nn.ReLU(),
            nn.LayerNorm(32),
            nn.Linear(32, joint_feature_dim),
            nn.ReLU(),
            nn.LayerNorm(joint_feature_dim)
        )
        
        print(f"ğŸ”§ JointEncoder: {joint_input_dim} â†’ {joint_feature_dim}")
    
    def forward(self, joint_features: torch.Tensor) -> torch.Tensor:
        """
        ç¼–ç å…³èŠ‚ç‰¹å¾
        joint_features: [batch_size, num_joints, joint_input_dim]
        return: [batch_size, num_joints, joint_feature_dim]
        """
        batch_size, num_joints, _ = joint_features.shape
        
        # é‡å¡‘ä¸º [batch_size * num_joints, joint_input_dim]
        flat_features = joint_features.view(-1, self.joint_input_dim)
        
        # ç¼–ç 
        encoded_flat = self.encoder(flat_features)
        
        # é‡å¡‘å› [batch_size, num_joints, joint_feature_dim]
        encoded_features = encoded_flat.view(batch_size, num_joints, self.joint_feature_dim)
        
        return encoded_features

# ============================================================================
# ğŸ§© æ¨¡å— 2: è½»é‡è‡ªæ³¨æ„åŠ› (åŸºäºç°æˆ Transformer ç»„ä»¶)
# ============================================================================

class LightweightSelfAttention(nn.Module):
    """
    è½»é‡è‡ªæ³¨æ„åŠ›ï¼šå»ºæ¨¡å…³èŠ‚é—´äº¤äº’
    åŸºäºç°æˆ Transformer è‡ªæ³¨æ„åŠ›æœºåˆ¶
    """
    def __init__(self, feature_dim: int = 64, num_heads: int = 4, dropout: float = 0.1):
        super(LightweightSelfAttention, self).__init__()
        self.feature_dim = feature_dim
        self.num_heads = num_heads
        self.head_dim = feature_dim // num_heads
        
        assert feature_dim % num_heads == 0, "feature_dim must be divisible by num_heads"
        
        # æ ‡å‡† Multi-Head Attention (ç°æˆç»„ä»¶)
        self.multihead_attn = nn.MultiheadAttention(
            embed_dim=feature_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True  # PyTorch 1.9+ æ”¯æŒ
        )
        
        # Layer Norm (ç°æˆç»„ä»¶)
        self.layer_norm = nn.LayerNorm(feature_dim)
        
        # Feed Forward (ç°æˆç»„ä»¶)
        self.feed_forward = nn.Sequential(
            nn.Linear(feature_dim, feature_dim * 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(feature_dim * 2, feature_dim),
            nn.Dropout(dropout)
        )
        
        self.layer_norm2 = nn.LayerNorm(feature_dim)
        
        print(f"ğŸ§  LightweightSelfAttention: {feature_dim}d, {num_heads} heads")
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        è‡ªæ³¨æ„åŠ›å¤„ç†
        x: [batch_size, num_joints, feature_dim]
        mask: [batch_size, num_joints] - True è¡¨ç¤ºæœ‰æ•ˆå…³èŠ‚ï¼ŒFalse è¡¨ç¤º padding
        return: [batch_size, num_joints, feature_dim]
        """
        # å‡†å¤‡æ³¨æ„åŠ›æ©ç 
        attn_mask = None
        if mask is not None:
            # è½¬æ¢ä¸ºæ³¨æ„åŠ›æ©ç æ ¼å¼
            # mask: [batch_size, num_joints] -> attn_mask: [batch_size * num_heads, num_joints, num_joints]
            batch_size, num_joints = mask.shape
            
            # åˆ›å»ºå› æœæ©ç ï¼špadding ä½ç½®ä¸èƒ½è¢«æ³¨æ„åˆ°
            attn_mask = mask.unsqueeze(1) & mask.unsqueeze(2)  # [batch_size, num_joints, num_joints]
            attn_mask = ~attn_mask  # åè½¬ï¼šTrue è¡¨ç¤ºå±è”½ï¼ŒFalse è¡¨ç¤ºå…è®¸
            
            # æ‰©å±•åˆ°å¤šå¤´
            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.num_heads, 1, 1)
            attn_mask = attn_mask.view(batch_size * self.num_heads, num_joints, num_joints)
        
        # Multi-Head Self-Attention
        attn_output, _ = self.multihead_attn(
            query=x, key=x, value=x,
            attn_mask=attn_mask,
            need_weights=False
        )
        
        # æ®‹å·®è¿æ¥ + Layer Norm
        x = self.layer_norm(x + attn_output)
        
        # Feed Forward
        ff_output = self.feed_forward(x)
        
        # æ®‹å·®è¿æ¥ + Layer Norm
        x = self.layer_norm2(x + ff_output)
        
        # åº”ç”¨æ©ç åˆ°è¾“å‡º
        if mask is not None:
            x = x * mask.unsqueeze(-1).float()
        
        return x

# ============================================================================
# ğŸ§© æ¨¡å— 3: æ³¨æ„åŠ›æ± åŒ– (åŸºäºç°æˆæ³¨æ„åŠ›æœºåˆ¶)
# ============================================================================

class AttentionPooling(nn.Module):
    """
    æ³¨æ„åŠ›æ± åŒ–ï¼šå°†å˜é•¿å…³èŠ‚ç‰¹å¾èšåˆä¸ºå›ºå®šé•¿åº¦å…¨å±€ç‰¹å¾
    åŸºäºç°æˆæ³¨æ„åŠ›æ± åŒ–æœºåˆ¶
    """
    def __init__(self, input_dim: int = 64, output_dim: int = 128):
        super(AttentionPooling, self).__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        
        # æ³¨æ„åŠ›æƒé‡è®¡ç®— (ç°æˆç»„ä»¶)
        self.attention_weights = nn.Sequential(
            nn.Linear(input_dim, input_dim // 2),
            nn.ReLU(),
            nn.Linear(input_dim // 2, 1),
            nn.Softmax(dim=1)
        )
        
        # è¾“å‡ºæŠ•å½± (ç°æˆç»„ä»¶)
        self.output_proj = nn.Sequential(
            nn.Linear(input_dim, output_dim),
            nn.ReLU(),
            nn.LayerNorm(output_dim)
        )
        
        print(f"ğŸ¯ AttentionPooling: {input_dim} â†’ {output_dim}")
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        æ³¨æ„åŠ›æ± åŒ–
        x: [batch_size, num_joints, input_dim]
        mask: [batch_size, num_joints] - True è¡¨ç¤ºæœ‰æ•ˆå…³èŠ‚
        return: [batch_size, output_dim]
        """
        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        attention_scores = self.attention_weights(x)  # [batch_size, num_joints, 1]
        
        # åº”ç”¨æ©ç 
        if mask is not None:
            # å°† padding ä½ç½®çš„æ³¨æ„åŠ›æƒé‡è®¾ä¸ºæå°å€¼
            mask_expanded = mask.unsqueeze(-1).float()  # [batch_size, num_joints, 1]
            attention_scores = attention_scores * mask_expanded + (1 - mask_expanded) * (-1e9)
        
        # é‡æ–°å½’ä¸€åŒ–
        attention_weights = F.softmax(attention_scores, dim=1)  # [batch_size, num_joints, 1]
        
        # åŠ æƒèšåˆ
        pooled_features = torch.sum(x * attention_weights, dim=1)  # [batch_size, input_dim]
        
        # è¾“å‡ºæŠ•å½±
        output = self.output_proj(pooled_features)  # [batch_size, output_dim]
        
        return output

# ============================================================================
# ğŸ§© æ¨¡å— 4: é€å…³èŠ‚é«˜æ–¯å¤´ Ã— J_max (åŸºäºç°æˆ SAC ç­–ç•¥å¤´)
# ============================================================================

class JointGaussianHeads(nn.Module):
    """
    é€å…³èŠ‚é«˜æ–¯å¤´ï¼šä¸ºæ¯ä¸ªå…³èŠ‚ç”Ÿæˆç‹¬ç«‹çš„é«˜æ–¯ç­–ç•¥
    åŸºäºç°æˆ SAC ç­–ç•¥å¤´è®¾è®¡
    """
    def __init__(self, input_dim: int = 128, max_joints: int = 10, action_dim_per_joint: int = 1):
        super(JointGaussianHeads, self).__init__()
        self.input_dim = input_dim
        self.max_joints = max_joints
        self.action_dim_per_joint = action_dim_per_joint
        
        # ä¸ºæ¯ä¸ªå…³èŠ‚åˆ›å»ºç‹¬ç«‹çš„é«˜æ–¯å¤´
        self.joint_heads = nn.ModuleList()
        
        for i in range(max_joints):
            # æ¯ä¸ªå…³èŠ‚çš„ç­–ç•¥å¤´ (åŸºäº SAC è®¾è®¡)
            joint_head = nn.Sequential(
                nn.Linear(input_dim, 64),
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, action_dim_per_joint * 2)  # mean + log_std
            )
            self.joint_heads.append(joint_head)
        
        # åŠ¨ä½œç¼©æ”¾å‚æ•°
        self.action_scale = 1.0
        self.action_bias = 0.0
        
        print(f"ğŸ¯ JointGaussianHeads: {max_joints} joints, {action_dim_per_joint}D each")
    
    def forward(self, features: torch.Tensor, num_joints: int, mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ç”Ÿæˆé€å…³èŠ‚é«˜æ–¯ç­–ç•¥
        features: [batch_size, input_dim]
        num_joints: å½“å‰å®é™…å…³èŠ‚æ•°
        mask: [batch_size, max_joints] - True è¡¨ç¤ºæœ‰æ•ˆå…³èŠ‚
        return: (mean, log_std) æ¯ä¸ªéƒ½æ˜¯ [batch_size, num_joints * action_dim_per_joint]
        """
        batch_size = features.size(0)
        
        # æ”¶é›†æ‰€æœ‰å…³èŠ‚çš„è¾“å‡º
        joint_outputs = []
        
        for i in range(self.max_joints):
            joint_output = self.joint_heads[i](features)  # [batch_size, action_dim_per_joint * 2]
            joint_outputs.append(joint_output)
        
        # å †å æ‰€æœ‰å…³èŠ‚è¾“å‡º
        all_outputs = torch.stack(joint_outputs, dim=1)  # [batch_size, max_joints, action_dim_per_joint * 2]
        
        # åˆ†ç¦» mean å’Œ log_std
        mean_all = all_outputs[:, :, :self.action_dim_per_joint]  # [batch_size, max_joints, action_dim_per_joint]
        log_std_all = all_outputs[:, :, self.action_dim_per_joint:]  # [batch_size, max_joints, action_dim_per_joint]
        
        # åªå–å‰ num_joints ä¸ªå…³èŠ‚
        mean_active = mean_all[:, :num_joints]  # [batch_size, num_joints, action_dim_per_joint]
        log_std_active = log_std_all[:, :num_joints]  # [batch_size, num_joints, action_dim_per_joint]
        
        # åº”ç”¨æ©ç  (å¦‚æœæä¾›)
        if mask is not None:
            active_mask = mask[:, :num_joints].unsqueeze(-1).float()  # [batch_size, num_joints, 1]
            mean_active = mean_active * active_mask
            log_std_active = log_std_active * active_mask
        
        # é‡å¡‘ä¸º SAC æœŸæœ›çš„æ ¼å¼
        mean_flat = mean_active.view(batch_size, -1)  # [batch_size, num_joints * action_dim_per_joint]
        log_std_flat = log_std_active.view(batch_size, -1)  # [batch_size, num_joints * action_dim_per_joint]
        
        # é™åˆ¶ log_std èŒƒå›´
        log_std_flat = torch.clamp(log_std_flat, -20, 2)
        
        return mean_flat, log_std_flat

# ============================================================================
# ğŸ§© æ¨¡å— 5: å…¨æµç¨‹ Mask ç³»ç»Ÿ
# ============================================================================

class MaskSystem:
    """
    å…¨æµç¨‹ Mask ç³»ç»Ÿï¼šå¤„ç†ä»»æ„å…³èŠ‚æ•°çš„è¾“å…¥è¾“å‡º
    """
    
    @staticmethod
    def create_joint_mask(batch_size: int, num_joints: int, max_joints: int, device: torch.device) -> torch.Tensor:
        """
        åˆ›å»ºå…³èŠ‚æ©ç 
        return: [batch_size, max_joints] - True è¡¨ç¤ºæœ‰æ•ˆå…³èŠ‚
        """
        mask = torch.zeros(batch_size, max_joints, dtype=torch.bool, device=device)
        mask[:, :num_joints] = True
        return mask
    
    @staticmethod
    def parse_observation(obs: torch.Tensor, num_joints: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è§£æè§‚å¯Ÿç©ºé—´ï¼šåˆ†ç¦»å…³èŠ‚ç‰¹å¾å’Œå…¨å±€ç‰¹å¾
        obs: [batch_size, obs_dim]
        return: (joint_features, global_features)
        """
        batch_size = obs.size(0)
        
        if num_joints == 2:
            # MuJoCo Reacher-v5 æ ¼å¼
            # [0:2] - joint angles (cos/sin)
            # [2:4] - joint velocities
            # [4:10] - global features (end effector, target, etc.)
            
            joint_angles = obs[:, :2]  # [batch_size, 2]
            joint_velocities = obs[:, 2:4]  # [batch_size, 2]
            global_features = obs[:, 4:]  # [batch_size, 6]
            
            # ç»„åˆå…³èŠ‚ç‰¹å¾
            joint_features = torch.stack([
                torch.cat([joint_angles[:, 0:1], joint_velocities[:, 0:1]], dim=1),  # joint 1
                torch.cat([joint_angles[:, 1:2], joint_velocities[:, 1:2]], dim=1),  # joint 2
            ], dim=1)  # [batch_size, 2, 2]
            
        else:
            # é€šç”¨æ ¼å¼ï¼šå‰ num_joints*2 æ˜¯å…³èŠ‚ç‰¹å¾ï¼Œå‰©ä½™æ˜¯å…¨å±€ç‰¹å¾
            joint_dim = num_joints * 2
            joint_obs = obs[:, :joint_dim]  # [batch_size, num_joints*2]
            global_features = obs[:, joint_dim:]  # [batch_size, remaining]
            
            # é‡å¡‘å…³èŠ‚ç‰¹å¾
            joint_features = joint_obs.view(batch_size, num_joints, 2)  # [batch_size, num_joints, 2]
        
        return joint_features, global_features

# ============================================================================
# ğŸ§© ä¸»æ¶æ„ï¼šæ¨¡å—åŒ–é€šç”¨ç‰¹å¾æå–å™¨
# ============================================================================

class ModularUniversalExtractor(BaseFeaturesExtractor):
    """
    æ¨¡å—åŒ–é€šç”¨ç‰¹å¾æå–å™¨
    ç»„åˆæ‰€æœ‰æ¨¡å—å®ç° ChatGPT-5 å»ºè®®çš„æ¶æ„
    """
    def __init__(self, observation_space: gym.Space, features_dim: int = 128, 
                 num_joints: int = 2, max_joints: int = 10):
        super(ModularUniversalExtractor, self).__init__(observation_space, features_dim)
        
        self.obs_dim = observation_space.shape[0]
        self.num_joints = num_joints
        self.max_joints = max_joints
        self.joint_input_dim = 2  # æ¯ä¸ªå…³èŠ‚ï¼šè§’åº¦ + é€Ÿåº¦
        
        print(f"ğŸŒŸ ModularUniversalExtractor åˆå§‹åŒ–:")
        print(f"   è§‚å¯Ÿç©ºé—´ç»´åº¦: {self.obs_dim}")
        print(f"   å½“å‰å…³èŠ‚æ•°: {num_joints}")
        print(f"   æœ€å¤§å…³èŠ‚æ•°: {max_joints}")
        print(f"   è¾“å‡ºç‰¹å¾ç»´åº¦: {features_dim}")
        print(f"   æ¶æ„: ChatGPT-5 å»ºè®®çš„æ¨¡å—åŒ–è®¾è®¡")
        
        # æ¨¡å— 1: é€å…³èŠ‚ç¼–ç å™¨
        self.joint_encoder = JointEncoder(
            joint_input_dim=self.joint_input_dim,
            joint_feature_dim=64
        )
        
        # æ¨¡å— 2: è½»é‡è‡ªæ³¨æ„åŠ›
        self.self_attention = LightweightSelfAttention(
            feature_dim=64,
            num_heads=4,
            dropout=0.1
        )
        
        # æ¨¡å— 3: æ³¨æ„åŠ›æ± åŒ–
        self.attention_pooling = AttentionPooling(
            input_dim=64,
            output_dim=features_dim // 2  # ä¸ºå…¨å±€ç‰¹å¾ç•™ç©ºé—´
        )
        
        # å…¨å±€ç‰¹å¾å¤„ç†
        global_dim = self.obs_dim - (num_joints * self.joint_input_dim)
        if global_dim > 0:
            self.global_processor = nn.Sequential(
                nn.Linear(global_dim, features_dim // 2),
                nn.ReLU(),
                nn.LayerNorm(features_dim // 2)
            )
            fusion_dim = features_dim
        else:
            self.global_processor = None
            fusion_dim = features_dim // 2
        
        # æœ€ç»ˆèåˆ
        self.final_fusion = nn.Sequential(
            nn.Linear(fusion_dim, features_dim),
            nn.ReLU(),
            nn.LayerNorm(features_dim),
            nn.Dropout(0.1)
        )
        
        # Mask ç³»ç»Ÿ
        self.mask_system = MaskSystem()
        
        print(f"âœ… ModularUniversalExtractor æ„å»ºå®Œæˆ")
        print(f"   ğŸ§© æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤")
        print(f"   ğŸ¯ æ”¯æŒ {max_joints} ä¸ªå…³èŠ‚çš„é€šç”¨æ¶æ„")
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        """
        æ¨¡å—åŒ–å‰å‘ä¼ æ’­
        """
        batch_size = observations.size(0)
        device = observations.device
        
        # æ­¥éª¤ 1: è§£æè§‚å¯Ÿç©ºé—´
        joint_features, global_features = self.mask_system.parse_observation(
            observations, self.num_joints
        )
        
        # æ­¥éª¤ 2: åˆ›å»ºå…³èŠ‚æ©ç 
        joint_mask = self.mask_system.create_joint_mask(
            batch_size, self.num_joints, self.max_joints, device
        )
        
        # æ­¥éª¤ 3: é€å…³èŠ‚ç¼–ç 
        encoded_joints = self.joint_encoder(joint_features)  # [batch_size, num_joints, 64]
        
        # æ­¥éª¤ 4: è‡ªæ³¨æ„åŠ›å»ºæ¨¡å…³èŠ‚é—´äº¤äº’
        attended_joints = self.self_attention(
            encoded_joints, 
            mask=joint_mask[:, :self.num_joints]
        )  # [batch_size, num_joints, 64]
        
        # æ­¥éª¤ 5: æ³¨æ„åŠ›æ± åŒ–
        pooled_joint_features = self.attention_pooling(
            attended_joints,
            mask=joint_mask[:, :self.num_joints]
        )  # [batch_size, features_dim//2]
        
        # æ­¥éª¤ 6: å¤„ç†å…¨å±€ç‰¹å¾
        if self.global_processor is not None and global_features.size(1) > 0:
            processed_global = self.global_processor(global_features)  # [batch_size, features_dim//2]
            fused_features = torch.cat([pooled_joint_features, processed_global], dim=1)
        else:
            fused_features = pooled_joint_features
        
        # æ­¥éª¤ 7: æœ€ç»ˆèåˆ
        final_features = self.final_fusion(fused_features)  # [batch_size, features_dim]
        
        return final_features

# ============================================================================
# ğŸ§© è®­ç»ƒå‡½æ•°
# ============================================================================

def train_modular_universal_sac(num_joints: int = 2, max_joints: int = 10, total_timesteps: int = 50000):
    """
    è®­ç»ƒæ¨¡å—åŒ–é€šç”¨ SAC
    """
    print("ğŸŒŸ æ¨¡å—åŒ–é€šç”¨ SAC è®­ç»ƒ")
    print(f"ğŸ”— å½“å‰å…³èŠ‚æ•°: {num_joints}")
    print(f"ğŸ”— æœ€å¤§æ”¯æŒå…³èŠ‚æ•°: {max_joints}")
    print(f"ğŸ’¡ æ¶æ„: ChatGPT-5 å»ºè®®çš„æ¨¡å—åŒ–è®¾è®¡")
    print(f"ğŸ¯ ç›®æ ‡: å·¥ç¨‹æœ€ç¨³çš„é€šç”¨æ¶æ„")
    print("=" * 70)
    
    # åˆ›å»ºç¯å¢ƒ
    print(f"ğŸ­ åˆ›å»ºç¯å¢ƒ...")
    if num_joints == 2:
        env = gym.make('Reacher-v5', render_mode='human')
        eval_env = gym.make('Reacher-v5')
    else:
        print(f"âš ï¸ æš‚ä¸æ”¯æŒ {num_joints} å…³èŠ‚ç¯å¢ƒï¼Œä½¿ç”¨ 2 å…³èŠ‚è¿›è¡ŒéªŒè¯")
        env = gym.make('Reacher-v5', render_mode='human')
        eval_env = gym.make('Reacher-v5')
    
    env = Monitor(env)
    eval_env = Monitor(eval_env)
    
    print(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ")
    print(f"ğŸ® åŠ¨ä½œç©ºé—´: {env.action_space}")
    print(f"ğŸ‘ï¸ è§‚å¯Ÿç©ºé—´: {env.observation_space}")
    
    print("=" * 70)
    
    # åˆ›å»ºæ¨¡å—åŒ–æ¨¡å‹
    print("ğŸ¤– åˆ›å»ºæ¨¡å—åŒ–é€šç”¨ SAC æ¨¡å‹...")
    
    policy_kwargs = {
        "features_extractor_class": ModularUniversalExtractor,
        "features_extractor_kwargs": {
            "features_dim": 128,
            "num_joints": num_joints,
            "max_joints": max_joints
        },
        "net_arch": [256, 256],
        "activation_fn": torch.nn.ReLU,
    }
    
    model = SAC(
        "MlpPolicy",
        env,
        learning_rate=3e-4,
        buffer_size=1000000,
        learning_starts=100,
        batch_size=256,
        tau=0.005,
        gamma=0.99,
        train_freq=1,
        gradient_steps=1,
        ent_coef='auto',
        target_update_interval=1,
        use_sde=False,
        policy_kwargs=policy_kwargs,
        verbose=1,
        device='cpu'
    )
    
    print("âœ… æ¨¡å—åŒ–é€šç”¨ SAC æ¨¡å‹åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“Š æ¨¡å‹ç‰¹ç‚¹:")
    print(f"   ğŸ§© æ¨¡å—åŒ–è®¾è®¡ï¼Œç»„ä»¶å¯å¤ç”¨")
    print(f"   ğŸ¯ åŸºäº ChatGPT-5 å»ºè®®")
    print(f"   ğŸ”§ ç°æˆç»„ä»¶æ‹¼è£…")
    print(f"   ğŸŒ æ”¯æŒä»»æ„å…³èŠ‚æ•°æ‰©å±•")
    print(f"   ğŸ›¡ï¸ å…¨æµç¨‹ Mask ä¿æŠ¤")
    
    print("=" * 70)
    
    # è¯„ä¼°å›è°ƒ
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=f'./modular_universal_{num_joints}joints_best/',
        log_path=f'./modular_universal_{num_joints}joints_logs/',
        eval_freq=5000,
        n_eval_episodes=10,
        deterministic=True,
        render=False
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸ¯ å¼€å§‹æ¨¡å—åŒ–è®­ç»ƒ...")
    print("ğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"   æ€»æ­¥æ•°: {total_timesteps:,}")
    print("   è¯„ä¼°é¢‘ç‡: æ¯ 5,000 æ­¥")
    print("   é¢„æœŸ: å·¥ç¨‹æœ€ç¨³çš„é€šç”¨æ¶æ„")
    print("=" * 70)
    
    start_time = time.time()
    
    model.learn(
        total_timesteps=total_timesteps,
        callback=eval_callback,
        log_interval=10,
        progress_bar=True
    )
    
    training_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ† æ¨¡å—åŒ–è®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸ è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
    print("=" * 70)
    
    # ä¿å­˜æ¨¡å‹
    model_name = f"modular_universal_{num_joints}joints_final"
    model.save(model_name)
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º: {model_name}.zip")
    
    # æœ€ç»ˆè¯„ä¼°
    print("\nğŸ” æœ€ç»ˆè¯„ä¼° (20 episodes)...")
    mean_reward, std_reward = evaluate_policy(
        model, 
        eval_env, 
        n_eval_episodes=20,
        deterministic=True,
        render=False
    )
    
    print(f"ğŸ“Š æ¨¡å—åŒ–é€šç”¨æ¨¡å‹è¯„ä¼°ç»“æœ:")
    print(f"   å¹³å‡å¥–åŠ±: {mean_reward:.2f} Â± {std_reward:.2f}")
    
    # ä¸ä¹‹å‰ç‰ˆæœ¬å¯¹æ¯”
    baseline_reward = -4.86
    original_attention_reward = -5.70
    complex_universal_reward = -10.21
    lightweight_universal_reward = -7.46
    
    print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
    print(f"   Baseline SAC: {baseline_reward:.2f}")
    print(f"   åŸå§‹æ³¨æ„åŠ›: {original_attention_reward:.2f}")
    print(f"   å¤æ‚é€šç”¨ç‰ˆ: {complex_universal_reward:.2f}")
    print(f"   è½»é‡çº§é€šç”¨: {lightweight_universal_reward:.2f}")
    print(f"   æ¨¡å—åŒ–é€šç”¨: {mean_reward:.2f}")
    
    improvement_vs_baseline = mean_reward - baseline_reward
    improvement_vs_original = mean_reward - original_attention_reward
    improvement_vs_complex = mean_reward - complex_universal_reward
    improvement_vs_lightweight = mean_reward - lightweight_universal_reward
    
    print(f"\nğŸ“Š æ”¹è¿›å¹…åº¦:")
    print(f"   vs Baseline: {improvement_vs_baseline:+.2f}")
    print(f"   vs åŸå§‹æ³¨æ„åŠ›: {improvement_vs_original:+.2f}")
    print(f"   vs å¤æ‚é€šç”¨: {improvement_vs_complex:+.2f}")
    print(f"   vs è½»é‡çº§é€šç”¨: {improvement_vs_lightweight:+.2f}")
    
    if improvement_vs_baseline > -1.0:
        print("   ğŸ‰ æ¨¡å—åŒ–é€šç”¨åŒ–æˆåŠŸ!")
    elif improvement_vs_lightweight > 1.0:
        print("   ğŸ‘ ä¼˜äºè½»é‡çº§ç‰ˆæœ¬!")
    else:
        print("   ğŸ“ˆ ä»æœ‰æ”¹è¿›ç©ºé—´")
    
    # æ¼”ç¤º
    print("\nğŸ® æ¼”ç¤ºæ¨¡å—åŒ–é€šç”¨æ¨¡å‹ (10 episodes)...")
    demo_env = gym.make('Reacher-v5', render_mode='human')
    
    episode_rewards = []
    success_count = 0
    
    for episode in range(10):
        obs, info = demo_env.reset()
        episode_reward = 0
        
        while True:
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = demo_env.step(action)
            episode_reward += reward
            
            if terminated or truncated:
                break
        
        episode_rewards.append(episode_reward)
        
        if episode_reward > -5:
            success_count += 1
            print(f"ğŸ¯ Episode {episode+1}: æˆåŠŸ! å¥–åŠ±={episode_reward:.2f}")
        else:
            print(f"ğŸ“Š Episode {episode+1}: å¥–åŠ±={episode_reward:.2f}")
    
    demo_env.close()
    
    demo_success_rate = success_count / 10
    demo_avg_reward = np.mean(episode_rewards)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š æ¨¡å—åŒ–é€šç”¨æ¼”ç¤ºç»Ÿè®¡:")
    print(f"   æˆåŠŸç‡: {demo_success_rate:.1%} ({success_count}/10)")
    print(f"   å¹³å‡å¥–åŠ±: {demo_avg_reward:.2f}")
    print(f"   å¥–åŠ±æ ‡å‡†å·®: {np.std(episode_rewards):.2f}")
    
    # ä¸å„ç‰ˆæœ¬å¯¹æ¯”
    baseline_demo_success = 0.9
    original_demo_success = 0.7
    lightweight_demo_success = 0.3
    
    print(f"\nğŸ“ˆ æ¼”ç¤ºæˆåŠŸç‡å¯¹æ¯”:")
    print(f"   Baseline SAC: {baseline_demo_success:.1%}")
    print(f"   åŸå§‹æ³¨æ„åŠ›: {original_demo_success:.1%}")
    print(f"   è½»é‡çº§é€šç”¨: {lightweight_demo_success:.1%}")
    print(f"   æ¨¡å—åŒ–é€šç”¨: {demo_success_rate:.1%}")
    
    if demo_success_rate >= 0.7:
        print("   ğŸ‰ æ¨¡å—åŒ–é€šç”¨åŒ–å¤§æˆåŠŸ!")
    elif demo_success_rate >= 0.5:
        print("   ğŸ‘ æ¨¡å—åŒ–é€šç”¨åŒ–æˆåŠŸ!")
    elif demo_success_rate >= 0.3:
        print("   ğŸ“ˆ æ¨¡å—åŒ–é€šç”¨åŒ–è‰¯å¥½!")
    else:
        print("   ğŸ“ˆ ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    print(f"\nğŸŒŸ æ¨¡å—åŒ–é€šç”¨æ¶æ„ä¼˜åŠ¿:")
    print(f"   âœ… åŸºäº ChatGPT-5 å»ºè®®è®¾è®¡")
    print(f"   âœ… ç°æˆç»„ä»¶æ‹¼è£…ï¼Œå·¥ç¨‹ç¨³å®š")
    print(f"   âœ… æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºç»´æŠ¤")
    print(f"   âœ… æ”¯æŒä»»æ„å…³èŠ‚æ•°æ‰©å±•")
    print(f"   âœ… å…¨æµç¨‹ Mask ä¿æŠ¤")
    print(f"   âœ… Set/Graph ç¼–ç ç†å¿µ")
    print(f"   âœ… é€å…³èŠ‚é«˜æ–¯å¤´è®¾è®¡")
    
    # æ¸…ç†
    env.close()
    eval_env.close()
    
    return {
        'mean_reward': mean_reward,
        'std_reward': std_reward,
        'training_time': training_time,
        'demo_success_rate': demo_success_rate,
        'demo_avg_reward': demo_avg_reward,
        'improvement_vs_baseline': improvement_vs_baseline,
        'improvement_vs_original': improvement_vs_original,
        'improvement_vs_complex': improvement_vs_complex,
        'improvement_vs_lightweight': improvement_vs_lightweight,
        'num_joints': num_joints,
        'max_joints': max_joints
    }

if __name__ == "__main__":
    print("ğŸŒŸ æ¨¡å—åŒ–é€šç”¨ SAC è®­ç»ƒç³»ç»Ÿ")
    print("ğŸ’¡ åŸºäº ChatGPT-5 å»ºè®®: SAC + Set/Graph ç¼–ç å™¨ + é€å…³èŠ‚é«˜æ–¯å¤´ Ã— J_max + å…¨æµç¨‹ mask")
    print("ğŸ¯ ç›®æ ‡: å·¥ç¨‹æœ€ç¨³çš„é€šç”¨æ¶æ„")
    print()
    
    try:
        result = train_modular_universal_sac(num_joints=2, max_joints=10, total_timesteps=50000)
        
        print(f"\nğŸŠ æ¨¡å—åŒ–é€šç”¨è®­ç»ƒç»“æœæ€»ç»“:")
        print(f"   æœ€ç»ˆè¯„ä¼°å¥–åŠ±: {result['mean_reward']:.2f} Â± {result['std_reward']:.2f}")
        print(f"   è®­ç»ƒæ—¶é—´: {result['training_time']/60:.1f} åˆ†é’Ÿ")
        print(f"   æ¼”ç¤ºæˆåŠŸç‡: {result['demo_success_rate']:.1%}")
        print(f"   æ¼”ç¤ºå¹³å‡å¥–åŠ±: {result['demo_avg_reward']:.2f}")
        print(f"   vs Baseline: {result['improvement_vs_baseline']:+.2f}")
        print(f"   vs åŸå§‹æ³¨æ„åŠ›: {result['improvement_vs_original']:+.2f}")
        print(f"   vs å¤æ‚é€šç”¨: {result['improvement_vs_complex']:+.2f}")
        print(f"   vs è½»é‡çº§é€šç”¨: {result['improvement_vs_lightweight']:+.2f}")
        
        if result['improvement_vs_baseline'] > -1.0:
            print(f"\nğŸ† æ¨¡å—åŒ–é€šç”¨åŒ–å¤§æˆåŠŸ!")
            print("   ChatGPT-5 å»ºè®®çš„æ¶æ„è®¾è®¡éªŒè¯æˆåŠŸ!")
        elif result['improvement_vs_lightweight'] > 1.0:
            print(f"\nğŸ‘ ä¼˜äºè½»é‡çº§ç‰ˆæœ¬!")
            print("   æ¨¡å—åŒ–è®¾è®¡çš„ä¼˜åŠ¿å¾—åˆ°ä½“ç°!")
        else:
            print(f"\nğŸ“ˆ æœ‰æ”¹è¿›ï¼Œä½†ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        print(f"\nâœ… æ¨¡å—åŒ–é€šç”¨æ¶æ„éªŒè¯å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


