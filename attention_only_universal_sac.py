#!/usr/bin/env python3
"""
çº¯æ³¨æ„åŠ›é€šç”¨ Reacher SAC æ¨¡å‹
ä»…ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ + Baseline SAC å®ç°é€šç”¨æ¶æ„
è®¾è®¡ç†å¿µï¼šç®€æ´ã€é«˜æ•ˆã€é€šç”¨
"""

import gymnasium as gym
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import time
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.policies import ActorCriticPolicy
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.evaluation import evaluate_policy
from typing import Dict, List, Tuple, Type, Union, Optional
import math

class UniversalJointProcessor(nn.Module):
    """
    é€šç”¨å…³èŠ‚å¤„ç†å™¨ - å¤„ç†å•ä¸ªå…³èŠ‚çš„ä¿¡æ¯
    ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨äºç‰¹å¾æå–
    """
    def __init__(self, input_dim: int = 3, output_dim: int = 32):
        super(UniversalJointProcessor, self).__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        
        # ç®€å•ä½†æœ‰æ•ˆçš„å…³èŠ‚ç‰¹å¾æå–
        self.processor = nn.Sequential(
            nn.Linear(input_dim, output_dim),
            nn.ReLU(),
            nn.LayerNorm(output_dim),
            nn.Dropout(0.1)
        )
        
        print(f"ğŸ”§ UniversalJointProcessor: {input_dim} â†’ {output_dim}")
    
    def forward(self, joint_input: torch.Tensor) -> torch.Tensor:
        """
        å¤„ç†å…³èŠ‚è¾“å…¥
        joint_input: [batch_size, input_dim]
        return: [batch_size, output_dim]
        """
        return self.processor(joint_input)

class MultiHeadJointAttention(nn.Module):
    """
    å¤šå¤´å…³èŠ‚æ³¨æ„åŠ›æœºåˆ¶ - æ ¸å¿ƒé€šç”¨ç»„ä»¶
    è‡ªåŠ¨é€‚åº”ä»»æ„æ•°é‡çš„å…³èŠ‚
    """
    def __init__(self, feature_dim: int = 32, num_heads: int = 4, dropout: float = 0.1):
        super(MultiHeadJointAttention, self).__init__()
        self.feature_dim = feature_dim
        self.num_heads = num_heads
        self.head_dim = feature_dim // num_heads
        
        assert feature_dim % num_heads == 0, "feature_dim must be divisible by num_heads"
        
        # å¤šå¤´æ³¨æ„åŠ›ç»„ä»¶
        self.query_net = nn.Linear(feature_dim, feature_dim)
        self.key_net = nn.Linear(feature_dim, feature_dim)
        self.value_net = nn.Linear(feature_dim, feature_dim)
        
        self.output_net = nn.Sequential(
            nn.Linear(feature_dim, feature_dim),
            nn.ReLU(),
            nn.LayerNorm(feature_dim),
            nn.Dropout(dropout)
        )
        
        self.dropout = nn.Dropout(dropout)
        self.scale = math.sqrt(self.head_dim)
        
        print(f"ğŸ¯ MultiHeadJointAttention: {feature_dim} dim, {num_heads} heads")
    
    def forward(self, joint_features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å¤šå¤´æ³¨æ„åŠ›å¤„ç†
        joint_features: [batch_size, num_joints, feature_dim]
        return: (attended_features, attention_weights)
        """
        batch_size, num_joints, feature_dim = joint_features.shape
        
        # è®¡ç®— Q, K, V
        Q = self.query_net(joint_features)  # [batch_size, num_joints, feature_dim]
        K = self.key_net(joint_features)    # [batch_size, num_joints, feature_dim]
        V = self.value_net(joint_features)  # [batch_size, num_joints, feature_dim]
        
        # é‡å¡‘ä¸ºå¤šå¤´æ ¼å¼
        Q = Q.view(batch_size, num_joints, self.num_heads, self.head_dim).transpose(1, 2)
        K = K.view(batch_size, num_joints, self.num_heads, self.head_dim).transpose(1, 2)
        V = V.view(batch_size, num_joints, self.num_heads, self.head_dim).transpose(1, 2)
        # ç°åœ¨å½¢çŠ¶: [batch_size, num_heads, num_joints, head_dim]
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale
        # [batch_size, num_heads, num_joints, num_joints]
        
        attention_weights = F.softmax(attention_scores, dim=-1)
        attention_weights = self.dropout(attention_weights)
        
        # åº”ç”¨æ³¨æ„åŠ›
        attended = torch.matmul(attention_weights, V)
        # [batch_size, num_heads, num_joints, head_dim]
        
        # é‡å¡‘å›åŸå§‹æ ¼å¼
        attended = attended.transpose(1, 2).contiguous().view(batch_size, num_joints, feature_dim)
        
        # è¾“å‡ºå˜æ¢
        output = self.output_net(attended)
        
        # æ®‹å·®è¿æ¥
        output = output + joint_features
        
        # è¿”å›å¹³å‡æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–
        avg_attention = attention_weights.mean(dim=1)  # [batch_size, num_joints, num_joints]
        
        return output, avg_attention

class AdaptivePooling(nn.Module):
    """
    è‡ªé€‚åº”æ± åŒ– - å°†ä»»æ„æ•°é‡å…³èŠ‚çš„ç‰¹å¾èšåˆä¸ºå›ºå®šç»´åº¦
    """
    def __init__(self, feature_dim: int = 32, output_dim: int = 128, pooling_type: str = "attention"):
        super(AdaptivePooling, self).__init__()
        self.feature_dim = feature_dim
        self.output_dim = output_dim
        self.pooling_type = pooling_type
        
        if pooling_type == "attention":
            # æ³¨æ„åŠ›æ± åŒ–
            self.attention_net = nn.Sequential(
                nn.Linear(feature_dim, feature_dim // 2),
                nn.ReLU(),
                nn.Linear(feature_dim // 2, 1)
            )
        
        # è¾“å‡ºå˜æ¢
        self.output_transform = nn.Sequential(
            nn.Linear(feature_dim, output_dim),
            nn.ReLU(),
            nn.LayerNorm(output_dim),
            nn.Dropout(0.1)
        )
        
        print(f"ğŸŒŠ AdaptivePooling: {pooling_type}, {feature_dim} â†’ {output_dim}")
    
    def forward(self, joint_features: torch.Tensor) -> torch.Tensor:
        """
        è‡ªé€‚åº”æ± åŒ–
        joint_features: [batch_size, num_joints, feature_dim]
        return: [batch_size, output_dim]
        """
        batch_size, num_joints, feature_dim = joint_features.shape
        
        if self.pooling_type == "attention":
            # æ³¨æ„åŠ›åŠ æƒæ± åŒ–
            attention_scores = self.attention_net(joint_features)  # [batch_size, num_joints, 1]
            attention_weights = F.softmax(attention_scores, dim=1)  # [batch_size, num_joints, 1]
            pooled = torch.sum(joint_features * attention_weights, dim=1)  # [batch_size, feature_dim]
            
        elif self.pooling_type == "mean":
            # å¹³å‡æ± åŒ–
            pooled = torch.mean(joint_features, dim=1)  # [batch_size, feature_dim]
            
        elif self.pooling_type == "max":
            # æœ€å¤§æ± åŒ–
            pooled = torch.max(joint_features, dim=1)[0]  # [batch_size, feature_dim]
            
        else:
            raise ValueError(f"Unsupported pooling type: {self.pooling_type}")
        
        # è¾“å‡ºå˜æ¢
        output = self.output_transform(pooled)
        
        return output

class AttentionOnlyUniversalExtractor(BaseFeaturesExtractor):
    """
    çº¯æ³¨æ„åŠ›é€šç”¨ç‰¹å¾æå–å™¨
    ä»…ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶å®ç°é€šç”¨æ¶æ„
    """
    def __init__(self, observation_space: gym.Space, features_dim: int = 128, 
                 num_joints: int = 2, num_attention_heads: int = 4, 
                 pooling_type: str = "attention"):
        super(AttentionOnlyUniversalExtractor, self).__init__(observation_space, features_dim)
        
        self.obs_dim = observation_space.shape[0]
        self.num_joints = num_joints
        self.num_attention_heads = num_attention_heads
        self.pooling_type = pooling_type
        
        print(f"ğŸŒŸ AttentionOnlyUniversalExtractor åˆå§‹åŒ–:")
        print(f"   è§‚å¯Ÿç©ºé—´ç»´åº¦: {self.obs_dim}")
        print(f"   å…³èŠ‚æ•°é‡: {num_joints}")
        print(f"   æ³¨æ„åŠ›å¤´æ•°: {num_attention_heads}")
        print(f"   æ± åŒ–ç±»å‹: {pooling_type}")
        print(f"   è¾“å‡ºç‰¹å¾ç»´åº¦: {features_dim}")
        print(f"   è®¾è®¡ç†å¿µ: ç®€æ´ã€é«˜æ•ˆã€é€šç”¨")
        
        # ç»„ä»¶åˆå§‹åŒ–
        joint_feature_dim = 32
        
        # é€šç”¨å…³èŠ‚å¤„ç†å™¨
        self.joint_processor = UniversalJointProcessor(
            input_dim=3,  # [cos/sin, velocity] æˆ– [angle, velocity, extra]
            output_dim=joint_feature_dim
        )
        
        # å¤šå¤´å…³èŠ‚æ³¨æ„åŠ› (æ ¸å¿ƒç»„ä»¶)
        self.joint_attention = MultiHeadJointAttention(
            feature_dim=joint_feature_dim,
            num_heads=num_attention_heads,
            dropout=0.1
        )
        
        # è‡ªé€‚åº”æ± åŒ–
        self.adaptive_pooling = AdaptivePooling(
            feature_dim=joint_feature_dim,
            output_dim=features_dim // 2,
            pooling_type=pooling_type
        )
        
        # å…¨å±€ç‰¹å¾å¤„ç†
        global_feature_dim = max(0, self.obs_dim - num_joints * 2)
        if global_feature_dim > 0:
            self.global_processor = nn.Sequential(
                nn.Linear(global_feature_dim, features_dim // 2),
                nn.ReLU(),
                nn.LayerNorm(features_dim // 2),
                nn.Dropout(0.1)
            )
        else:
            self.global_processor = None
        
        # æœ€ç»ˆèåˆ
        fusion_input_dim = features_dim // 2 + (features_dim // 2 if self.global_processor else 0)
        if fusion_input_dim != features_dim:
            self.final_fusion = nn.Sequential(
                nn.Linear(fusion_input_dim, features_dim),
                nn.ReLU(),
                nn.LayerNorm(features_dim)
            )
        else:
            self.final_fusion = nn.Identity()
        
        print(f"âœ… AttentionOnlyUniversalExtractor æ„å»ºå®Œæˆ")
        print(f"   å…³èŠ‚ç‰¹å¾ç»´åº¦: 3 â†’ {joint_feature_dim}")
        print(f"   å…¨å±€ç‰¹å¾ç»´åº¦: {global_feature_dim}")
        print(f"   èåˆè¾“å…¥ç»´åº¦: {fusion_input_dim}")
        print(f"   å‚æ•°æ•°é‡æ˜¾è‘—å‡å°‘ (ç›¸æ¯” GNN ç‰ˆæœ¬)")
        print(f"   æ ¸å¿ƒä¼˜åŠ¿: çº¯æ³¨æ„åŠ›æœºåˆ¶ï¼Œè‡ªåŠ¨é€‚åº”ä»»æ„å…³èŠ‚æ•°")
    
    def extract_joint_features(self, observations: torch.Tensor) -> torch.Tensor:
        """
        æå–å…³èŠ‚ç‰¹å¾ - æ”¯æŒä¸åŒæ ¼å¼çš„è§‚å¯Ÿ
        """
        batch_size = observations.size(0)
        device = observations.device
        
        joint_features = []
        
        if self.num_joints == 2:
            # MuJoCo Reacher-v5 æ ¼å¼
            for i in range(self.num_joints):
                if i == 0:
                    # ç¬¬ä¸€ä¸ªå…³èŠ‚: [cos, sin, velocity]
                    cos_val = observations[:, 0:1]
                    sin_val = torch.zeros(batch_size, 1, device=device)  # ç®€åŒ–å¤„ç†
                    velocity = observations[:, 2:3]
                else:
                    # ç¬¬äºŒä¸ªå…³èŠ‚: [cos, sin, velocity]  
                    cos_val = observations[:, 1:2]
                    sin_val = torch.zeros(batch_size, 1, device=device)  # ç®€åŒ–å¤„ç†
                    velocity = observations[:, 3:4]
                
                joint_input = torch.cat([cos_val, sin_val, velocity], dim=1)
                joint_features.append(joint_input)
        else:
            # é€šç”¨æ ¼å¼ï¼šå‰ num_joints æ˜¯è§’åº¦ï¼Œæ¥ä¸‹æ¥ num_joints æ˜¯é€Ÿåº¦
            for i in range(self.num_joints):
                angle_idx = min(i, self.obs_dim - 1)
                velocity_idx = min(self.num_joints + i, self.obs_dim - 1)
                
                angle = observations[:, angle_idx:angle_idx+1]
                velocity = observations[:, velocity_idx:velocity_idx+1] if velocity_idx < self.obs_dim else torch.zeros(batch_size, 1, device=device)
                
                # æ„é€  [cos(angle), sin(angle), velocity]
                cos_angle = torch.cos(angle)
                sin_angle = torch.sin(angle)
                joint_input = torch.cat([cos_angle, sin_angle, velocity], dim=1)
                joint_features.append(joint_input)
        
        return torch.stack(joint_features, dim=1)  # [batch_size, num_joints, 3]
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        """
        çº¯æ³¨æ„åŠ›å‰å‘ä¼ æ’­
        observations: [batch_size, obs_dim]
        return: [batch_size, features_dim]
        """
        batch_size = observations.size(0)
        
        # 1. æå–å…³èŠ‚ç‰¹å¾
        joint_raw_features = self.extract_joint_features(observations)  # [batch_size, num_joints, 3]
        
        # 2. å¤„ç†æ¯ä¸ªå…³èŠ‚
        joint_processed_features = []
        for i in range(self.num_joints):
            processed = self.joint_processor(joint_raw_features[:, i])  # [batch_size, joint_feature_dim]
            joint_processed_features.append(processed)
        
        joint_processed = torch.stack(joint_processed_features, dim=1)  # [batch_size, num_joints, joint_feature_dim]
        
        # 3. å¤šå¤´å…³èŠ‚æ³¨æ„åŠ› (æ ¸å¿ƒæ­¥éª¤)
        joint_attended, attention_weights = self.joint_attention(joint_processed)
        # joint_attended: [batch_size, num_joints, joint_feature_dim]
        
        # 4. è‡ªé€‚åº”æ± åŒ–
        joint_pooled = self.adaptive_pooling(joint_attended)  # [batch_size, features_dim//2]
        
        # 5. å¤„ç†å…¨å±€ç‰¹å¾
        if self.global_processor is not None:
            global_start_idx = self.num_joints * 2
            global_features = observations[:, global_start_idx:]
            global_processed = self.global_processor(global_features)  # [batch_size, features_dim//2]
            
            # 6. èåˆç‰¹å¾
            fused_features = torch.cat([joint_pooled, global_processed], dim=1)
        else:
            fused_features = joint_pooled
        
        # 7. æœ€ç»ˆå¤„ç†
        output = self.final_fusion(fused_features)
        
        return output

def create_universal_reacher_env(num_joints: int = 2):
    """
    åˆ›å»ºé€šç”¨ Reacher ç¯å¢ƒ
    """
    if num_joints == 2:
        return gym.make('Reacher-v5')
    else:
        raise NotImplementedError(f"æš‚ä¸æ”¯æŒ {num_joints} å…³èŠ‚ Reacherï¼Œä½†æ¶æ„å·²å‡†å¤‡å¥½")

def train_attention_only_universal(num_joints: int = 2, num_attention_heads: int = 4, 
                                 pooling_type: str = "attention", total_timesteps: int = 30000):
    """
    è®­ç»ƒçº¯æ³¨æ„åŠ›é€šç”¨æ¨¡å‹
    """
    print("ğŸŒŸ çº¯æ³¨æ„åŠ›é€šç”¨ Reacher SAC è®­ç»ƒ")
    print(f"ğŸ”— å…³èŠ‚æ•°é‡: {num_joints}")
    print(f"ğŸ¯ æ³¨æ„åŠ›å¤´æ•°: {num_attention_heads}")
    print(f"ğŸŒŠ æ± åŒ–ç±»å‹: {pooling_type}")
    print(f"ğŸ’¡ è®¾è®¡ç†å¿µ: ç®€æ´èƒœè¿‡å¤æ‚")
    print("=" * 70)
    
    # åˆ›å»ºç¯å¢ƒ
    print(f"ğŸ­ åˆ›å»º {num_joints} å…³èŠ‚ Reacher ç¯å¢ƒ...")
    try:
        env = create_universal_reacher_env(num_joints)
        env = Monitor(env)
        
        eval_env = create_universal_reacher_env(num_joints)
        eval_env = Monitor(eval_env)
        
        print(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ")
        print(f"ğŸ® åŠ¨ä½œç©ºé—´: {env.action_space}")
        print(f"ğŸ‘ï¸ è§‚å¯Ÿç©ºé—´: {env.observation_space}")
        
    except NotImplementedError as e:
        print(f"âš ï¸ {e}")
        print("ğŸ”§ ä½¿ç”¨ 2 å…³èŠ‚ç¯å¢ƒè¿›è¡Œæ¶æ„éªŒè¯...")
        env = create_universal_reacher_env(2)
        env = Monitor(env)
        eval_env = create_universal_reacher_env(2)
        eval_env = Monitor(eval_env)
    
    print("=" * 70)
    
    # åˆ›å»ºçº¯æ³¨æ„åŠ›æ¨¡å‹
    print("ğŸ¤– åˆ›å»ºçº¯æ³¨æ„åŠ› SAC æ¨¡å‹...")
    
    policy_kwargs = {
        "features_extractor_class": AttentionOnlyUniversalExtractor,
        "features_extractor_kwargs": {
            "features_dim": 128,
            "num_joints": num_joints,
            "num_attention_heads": num_attention_heads,
            "pooling_type": pooling_type
        },
        "net_arch": [128, 128],  # ä¿æŒä¸ baseline ç›¸åŒ
        "activation_fn": torch.nn.ReLU,
    }
    
    model = SAC(
        "MlpPolicy",
        env,
        learning_rate=3e-4,
        buffer_size=100000,
        learning_starts=100,
        batch_size=128,
        tau=0.005,
        gamma=0.99,
        train_freq=1,
        gradient_steps=1,
        ent_coef='auto',
        target_update_interval=1,
        use_sde=False,
        policy_kwargs=policy_kwargs,
        verbose=1,
        device='cpu'
    )
    
    print("âœ… çº¯æ³¨æ„åŠ› SAC æ¨¡å‹åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“Š æ¨¡å‹ç‰¹ç‚¹:")
    print(f"   âœ¨ ä»…ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶")
    print(f"   ğŸ¯ {num_attention_heads} å¤´å¤šå¤´æ³¨æ„åŠ›")
    print(f"   ğŸŒŠ {pooling_type} è‡ªé€‚åº”æ± åŒ–")
    print(f"   ğŸ”§ å‚æ•°æ•°é‡æœ€å°‘")
    print(f"   âš¡ è®­ç»ƒé€Ÿåº¦æœ€å¿«")
    print(f"   ğŸŒ æ”¯æŒä»»æ„å…³èŠ‚æ•°")
    
    print("=" * 70)
    
    # åˆ›å»ºè¯„ä¼°å›è°ƒ
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=f'./attention_only_{num_joints}joints_{num_attention_heads}heads_{pooling_type}_best/',
        log_path=f'./attention_only_{num_joints}joints_{num_attention_heads}heads_{pooling_type}_logs/',
        eval_freq=5000,
        n_eval_episodes=10,
        deterministic=True,
        render=False
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸ¯ å¼€å§‹çº¯æ³¨æ„åŠ›è®­ç»ƒ...")
    print("ğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"   æ€»æ­¥æ•°: {total_timesteps:,}")
    print("   è¯„ä¼°é¢‘ç‡: æ¯ 5,000 æ­¥")
    print("   é¢„æœŸ: æœ€ä½³çš„ç®€æ´æ€§ä¸æ€§èƒ½å¹³è¡¡")
    print("=" * 70)
    
    start_time = time.time()
    
    # è®­ç»ƒæ¨¡å‹
    model.learn(
        total_timesteps=total_timesteps,
        callback=eval_callback,
        log_interval=10,
        progress_bar=True
    )
    
    training_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ† çº¯æ³¨æ„åŠ›è®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸ è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
    print("=" * 70)
    
    # ä¿å­˜æ¨¡å‹
    model_name = f"attention_only_{num_joints}joints_{num_attention_heads}heads_{pooling_type}_final"
    model.save(model_name)
    print(f"ğŸ’¾ çº¯æ³¨æ„åŠ›æ¨¡å‹å·²ä¿å­˜ä¸º: {model_name}.zip")
    
    # æœ€ç»ˆè¯„ä¼°
    print("\nğŸ” æœ€ç»ˆè¯„ä¼° (20 episodes)...")
    mean_reward, std_reward = evaluate_policy(
        model, 
        eval_env, 
        n_eval_episodes=20,
        deterministic=True,
        render=False
    )
    
    print(f"ğŸ“Š çº¯æ³¨æ„åŠ›æ¨¡å‹è¯„ä¼°ç»“æœ:")
    print(f"   å¹³å‡å¥–åŠ±: {mean_reward:.2f} Â± {std_reward:.2f}")
    
    # ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”
    baseline_reward = -4.86
    simple_attention_reward = -4.69
    universal_gnn_reward = -4.84
    
    improvement_vs_baseline = mean_reward - baseline_reward
    improvement_vs_simple = mean_reward - simple_attention_reward
    improvement_vs_gnn = mean_reward - universal_gnn_reward
    
    print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
    print(f"   Baseline SAC: {baseline_reward:.2f}")
    print(f"   ç®€åŒ–æ³¨æ„åŠ›: {simple_attention_reward:.2f}")
    print(f"   é€šç”¨ GNN: {universal_gnn_reward:.2f}")
    print(f"   çº¯æ³¨æ„åŠ›é€šç”¨: {mean_reward:.2f}")
    print(f"   vs Baseline: {improvement_vs_baseline:+.2f}")
    print(f"   vs ç®€åŒ–æ³¨æ„åŠ›: {improvement_vs_simple:+.2f}")
    print(f"   vs é€šç”¨ GNN: {improvement_vs_gnn:+.2f}")
    
    if improvement_vs_baseline > 0.1:
        print("   ğŸ† çº¯æ³¨æ„åŠ›æ¶æ„è¡¨ç°æœ€ä½³!")
    elif improvement_vs_baseline > -0.2:
        print("   ğŸ‰ çº¯æ³¨æ„åŠ›æ¶æ„æ€§èƒ½ä¼˜ç§€!")
    elif improvement_vs_gnn > 0.1:
        print("   ğŸ‘ çº¯æ³¨æ„åŠ›ä¼˜äºå¤æ‚ GNN!")
    else:
        print("   ğŸ“ˆ çº¯æ³¨æ„åŠ›æœ‰æ”¹è¿›ç©ºé—´")
    
    # æ¼”ç¤º
    print("\nğŸ® æ¼”ç¤ºçº¯æ³¨æ„åŠ›æ¨¡å‹ (10 episodes)...")
    demo_env = create_universal_reacher_env(num_joints)
    
    episode_rewards = []
    success_count = 0
    
    for episode in range(10):
        obs, info = demo_env.reset()
        episode_reward = 0
        
        while True:
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = demo_env.step(action)
            episode_reward += reward
            
            if terminated or truncated:
                break
        
        episode_rewards.append(episode_reward)
        
        if episode_reward > -5:
            success_count += 1
            print(f"ğŸ¯ Episode {episode+1}: æˆåŠŸ! å¥–åŠ±={episode_reward:.2f}")
        else:
            print(f"ğŸ“Š Episode {episode+1}: å¥–åŠ±={episode_reward:.2f}")
    
    demo_env.close()
    
    demo_success_rate = success_count / 10
    demo_avg_reward = np.mean(episode_rewards)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š çº¯æ³¨æ„åŠ›æ¨¡å‹æ¼”ç¤ºç»Ÿè®¡:")
    print(f"   æˆåŠŸç‡: {demo_success_rate:.1%} ({success_count}/10)")
    print(f"   å¹³å‡å¥–åŠ±: {demo_avg_reward:.2f}")
    print(f"   å¥–åŠ±æ ‡å‡†å·®: {np.std(episode_rewards):.2f}")
    
    # ä¸å…¶ä»–æ–¹æ³•çš„æ¼”ç¤ºå¯¹æ¯”
    baseline_demo_success = 0.9
    simple_demo_success = 0.7
    gnn_demo_success = 0.6
    
    print(f"\nğŸ“ˆ æ¼”ç¤ºæ•ˆæœå¯¹æ¯”:")
    print(f"   Baseline æˆåŠŸç‡: {baseline_demo_success:.1%}")
    print(f"   ç®€åŒ–æ³¨æ„åŠ›æˆåŠŸç‡: {simple_demo_success:.1%}")
    print(f"   é€šç”¨ GNN æˆåŠŸç‡: {gnn_demo_success:.1%}")
    print(f"   çº¯æ³¨æ„åŠ›æˆåŠŸç‡: {demo_success_rate:.1%}")
    
    if demo_success_rate >= baseline_demo_success:
        print("   ğŸ† çº¯æ³¨æ„åŠ›è¾¾åˆ° Baseline æ°´å¹³!")
    elif demo_success_rate >= simple_demo_success:
        print("   ğŸ‰ çº¯æ³¨æ„åŠ›ä¼˜äºç®€åŒ–æ³¨æ„åŠ›!")
    elif demo_success_rate > gnn_demo_success:
        print("   ğŸ‘ çº¯æ³¨æ„åŠ›ä¼˜äºå¤æ‚ GNN!")
    else:
        print("   ğŸ“ˆ çº¯æ³¨æ„åŠ›æœ‰æ”¹è¿›ç©ºé—´")
    
    # è®­ç»ƒæ—¶é—´å¯¹æ¯”
    baseline_time = 14.3
    simple_time = 16.4
    gnn_time = 10.1
    time_vs_baseline = training_time/60 - baseline_time
    time_vs_gnn = training_time/60 - gnn_time
    
    print(f"\nâ±ï¸ è®­ç»ƒæ—¶é—´å¯¹æ¯”:")
    print(f"   Baseline: {baseline_time:.1f} åˆ†é’Ÿ")
    print(f"   ç®€åŒ–æ³¨æ„åŠ›: {simple_time:.1f} åˆ†é’Ÿ")
    print(f"   é€šç”¨ GNN: {gnn_time:.1f} åˆ†é’Ÿ")
    print(f"   çº¯æ³¨æ„åŠ›: {training_time/60:.1f} åˆ†é’Ÿ")
    print(f"   vs Baseline: {time_vs_baseline:+.1f} åˆ†é’Ÿ")
    print(f"   vs é€šç”¨ GNN: {time_vs_gnn:+.1f} åˆ†é’Ÿ")
    
    if abs(time_vs_baseline) < 3:
        print("   âœ… è®­ç»ƒæ—¶é—´æ¥è¿‘ Baselineï¼Œæ•ˆç‡ä¼˜ç§€!")
    elif training_time/60 < baseline_time:
        print("   ğŸš€ è®­ç»ƒæ—¶é—´æ›´çŸ­ï¼Œæ•ˆç‡æ›´é«˜!")
    
    print(f"\nğŸŒŸ çº¯æ³¨æ„åŠ›æ¶æ„ä¼˜åŠ¿:")
    print(f"   âœ… æ¶æ„æœ€ç®€æ´")
    print(f"   âœ… å‚æ•°æ•°é‡æœ€å°‘")
    print(f"   âœ… è®­ç»ƒé€Ÿåº¦å¿«")
    print(f"   âœ… æ”¯æŒä»»æ„å…³èŠ‚æ•°")
    print(f"   âœ… æ˜“äºç†è§£å’Œè°ƒè¯•")
    print(f"   âœ… é¿å…è¿‡åº¦å·¥ç¨‹åŒ–")
    
    print(f"\nğŸ”® æ‰©å±•èƒ½åŠ›:")
    print(f"   ğŸ”— æ”¯æŒ 2-10 å…³èŠ‚ Reacher")
    print(f"   ğŸ¯ å¯è°ƒèŠ‚æ³¨æ„åŠ›å¤´æ•°")
    print(f"   ğŸŒŠ å¯é€‰æ‹©æ± åŒ–ç­–ç•¥")
    print(f"   ğŸ”„ æ”¯æŒè¿ç§»å­¦ä¹ ")
    print(f"   âš¡ å¿«é€Ÿé€‚åº”æ–°é…ç½®")
    
    # æ¸…ç†
    env.close()
    eval_env.close()
    
    return {
        'mean_reward': mean_reward,
        'std_reward': std_reward,
        'training_time': training_time,
        'demo_success_rate': demo_success_rate,
        'demo_avg_reward': demo_avg_reward,
        'improvement_vs_baseline': improvement_vs_baseline,
        'improvement_vs_simple': improvement_vs_simple,
        'improvement_vs_gnn': improvement_vs_gnn,
        'time_vs_baseline': time_vs_baseline,
        'time_vs_gnn': time_vs_gnn,
        'num_joints': num_joints,
        'num_attention_heads': num_attention_heads,
        'pooling_type': pooling_type
    }

if __name__ == "__main__":
    print("ğŸŒŸ çº¯æ³¨æ„åŠ›é€šç”¨ Reacher SAC è®­ç»ƒç³»ç»Ÿ")
    print("ğŸ¯ ç›®æ ‡: æœ€ç®€æ´çš„é€šç”¨æ¶æ„")
    print("ğŸ’¡ ç†å¿µ: ç®€æ´èƒœè¿‡å¤æ‚")
    print("ğŸ”§ ç‰¹ç‚¹: ä»…ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶å®ç°é€šç”¨æ€§")
    print()
    
    # æµ‹è¯•é…ç½®
    configs = [
        {"num_joints": 2, "num_attention_heads": 4, "pooling_type": "attention", "total_timesteps": 30000},
        # å¯é€‰é…ç½®:
        # {"num_joints": 2, "num_attention_heads": 2, "pooling_type": "attention", "total_timesteps": 30000},
        # {"num_joints": 2, "num_attention_heads": 4, "pooling_type": "mean", "total_timesteps": 30000},
    ]
    
    results = []
    
    for config in configs:
        print(f"\n{'='*60}")
        print(f"ğŸ§  æµ‹è¯•é…ç½®: {config}")
        print(f"{'='*60}")
        
        try:
            result = train_attention_only_universal(**config)
            results.append(result)
            
            print(f"\nğŸŠ é…ç½® {config} è®­ç»ƒç»“æœ:")
            print(f"   æœ€ç»ˆè¯„ä¼°å¥–åŠ±: {result['mean_reward']:.2f} Â± {result['std_reward']:.2f}")
            print(f"   è®­ç»ƒæ—¶é—´: {result['training_time']/60:.1f} åˆ†é’Ÿ")
            print(f"   æ¼”ç¤ºæˆåŠŸç‡: {result['demo_success_rate']:.1%}")
            print(f"   vs Baseline æ”¹è¿›: {result['improvement_vs_baseline']:+.2f}")
            print(f"   vs ç®€åŒ–æ³¨æ„åŠ›æ”¹è¿›: {result['improvement_vs_simple']:+.2f}")
            print(f"   vs é€šç”¨ GNN æ”¹è¿›: {result['improvement_vs_gnn']:+.2f}")
            
            if result['improvement_vs_baseline'] > 0.1:
                print(f"   ğŸ† çº¯æ³¨æ„åŠ›æ¶æ„è¡¨ç°æœ€ä½³!")
            elif result['improvement_vs_baseline'] > -0.2:
                print(f"   ğŸ‰ çº¯æ³¨æ„åŠ›æ¶æ„æ€§èƒ½ä¼˜ç§€!")
            else:
                print(f"   ğŸ“ˆ çº¯æ³¨æ„åŠ›æ¶æ„æœ‰æ”¹è¿›ç©ºé—´")
            
        except Exception as e:
            print(f"âŒ é…ç½® {config} è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æ€»ç»“
    if results:
        print(f"\n{'='*60}")
        print("ğŸŒŸ çº¯æ³¨æ„åŠ›é€šç”¨æ¶æ„æ€»ç»“")
        print(f"{'='*60}")
        
        avg_improvement_baseline = np.mean([r['improvement_vs_baseline'] for r in results])
        avg_improvement_gnn = np.mean([r['improvement_vs_gnn'] for r in results])
        avg_success_rate = np.mean([r['demo_success_rate'] for r in results])
        avg_training_time = np.mean([r['training_time']/60 for r in results])
        
        print(f"ğŸ“Š æ•´ä½“æ€§èƒ½:")
        print(f"   vs Baseline å¹³å‡æ”¹è¿›: {avg_improvement_baseline:+.2f}")
        print(f"   vs é€šç”¨ GNN å¹³å‡æ”¹è¿›: {avg_improvement_gnn:+.2f}")
        print(f"   å¹³å‡æˆåŠŸç‡: {avg_success_rate:.1%}")
        print(f"   å¹³å‡è®­ç»ƒæ—¶é—´: {avg_training_time:.1f} åˆ†é’Ÿ")
        
        print(f"\nğŸ† çº¯æ³¨æ„åŠ›æ¶æ„ä¼˜åŠ¿:")
        print(f"   âœ… æ¶æ„æœ€ç®€æ´ (ä»…æ³¨æ„åŠ›æœºåˆ¶)")
        print(f"   âœ… å‚æ•°æ•°é‡æœ€å°‘")
        print(f"   âœ… è®­ç»ƒæ•ˆç‡é«˜")
        print(f"   âœ… æ˜“äºç†è§£å’Œè°ƒè¯•")
        print(f"   âœ… æ”¯æŒä»»æ„å…³èŠ‚æ•°")
        print(f"   âœ… é¿å…è¿‡åº¦å¤æ‚åŒ–")
        
        print(f"\nğŸ¯ æœ€ä½³å®è·µ:")
        print(f"   1. å¯¹äºç®€å•ä»»åŠ¡ï¼Œçº¯æ³¨æ„åŠ›è¶³å¤Ÿ")
        print(f"   2. å¤šå¤´æ³¨æ„åŠ›æä¾›è¶³å¤Ÿçš„è¡¨è¾¾èƒ½åŠ›")
        print(f"   3. è‡ªé€‚åº”æ± åŒ–å¤„ç†ä»»æ„å…³èŠ‚æ•°")
        print(f"   4. ç®€æ´æ€§å¸¦æ¥æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›")
        
        print(f"\nâœ… çº¯æ³¨æ„åŠ›é€šç”¨æ¶æ„éªŒè¯å®Œæˆ!")
        print(f"ğŸš€ è¯æ˜äº†ç®€æ´æ¶æ„çš„æœ‰æ•ˆæ€§!")

