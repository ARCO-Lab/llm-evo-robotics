#!/usr/bin/env python3
"""
é€šç”¨ Reacher SAC æ¨¡å‹
æ”¯æŒä»»æ„å…³èŠ‚æ•°é‡çš„ Reacher ä»»åŠ¡
è®¾è®¡ç†å¿µï¼šä¸€ä¸ªæ¨¡å‹ï¼Œå¤šç§é…ç½®
"""

import gymnasium as gym
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import time
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.policies import ActorCriticPolicy
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.evaluation import evaluate_policy
from typing import Dict, List, Tuple, Type, Union, Optional
import math

class UniversalJointEncoder(nn.Module):
    """
    é€šç”¨å…³èŠ‚ç¼–ç å™¨ - å¤„ç†å•ä¸ªå…³èŠ‚çš„ä¿¡æ¯
    æ¯ä¸ªå…³èŠ‚ç‹¬ç«‹ç¼–ç ï¼Œä¿è¯å¯æ‰©å±•æ€§
    """
    def __init__(self, joint_feature_dim: int = 32):
        super(UniversalJointEncoder, self).__init__()
        self.joint_feature_dim = joint_feature_dim
        
        # æ¯ä¸ªå…³èŠ‚çš„æ ‡å‡†è¾“å…¥ï¼š[angle_cos, angle_sin, velocity]
        # å¯¹äºå¤æ‚å…³èŠ‚å¯èƒ½è¿˜æœ‰ [torque, acceleration] ç­‰
        self.encoder = nn.Sequential(
            nn.Linear(3, joint_feature_dim),  # åŸºç¡€ï¼šcos, sin, velocity
            nn.ReLU(),
            nn.LayerNorm(joint_feature_dim),
            nn.Linear(joint_feature_dim, joint_feature_dim),
            nn.ReLU(),
            nn.LayerNorm(joint_feature_dim)
        )
        
        print(f"ğŸ”§ UniversalJointEncoder: 3 â†’ {joint_feature_dim}")
    
    def forward(self, joint_input: torch.Tensor) -> torch.Tensor:
        """
        ç¼–ç å•ä¸ªå…³èŠ‚ä¿¡æ¯
        joint_input: [batch_size, 3] (cos, sin, velocity)
        return: [batch_size, joint_feature_dim]
        """
        return self.encoder(joint_input)

class AdaptiveGraphNetwork(nn.Module):
    """
    è‡ªé€‚åº”å›¾ç½‘ç»œ - æ ¹æ®å…³èŠ‚æ•°é‡åŠ¨æ€æ„å»ºå›¾ç»“æ„
    æ”¯æŒé“¾å¼ã€æ ‘çŠ¶ã€æ˜ŸçŠ¶ç­‰å¤šç§æ‹“æ‰‘ç»“æ„
    """
    def __init__(self, node_dim: int = 32, hidden_dim: int = 64, topology: str = "chain"):
        super(AdaptiveGraphNetwork, self).__init__()
        self.node_dim = node_dim
        self.hidden_dim = hidden_dim
        self.topology = topology
        
        # æ¶ˆæ¯ä¼ é€’ç½‘ç»œ
        self.message_net = nn.Sequential(
            nn.Linear(node_dim * 2, hidden_dim),  # ä¸¤ä¸ªèŠ‚ç‚¹çš„ç‰¹å¾æ‹¼æ¥
            nn.ReLU(),
            nn.Linear(hidden_dim, node_dim),
            nn.ReLU()
        )
        
        # èŠ‚ç‚¹æ›´æ–°ç½‘ç»œ
        self.update_net = nn.Sequential(
            nn.Linear(node_dim * 2, hidden_dim),  # åŸç‰¹å¾ + èšåˆæ¶ˆæ¯
            nn.ReLU(),
            nn.Linear(hidden_dim, node_dim)
        )
        
        # æ®‹å·®è¿æ¥æƒé‡
        self.residual_weight = nn.Parameter(torch.tensor(0.5))
        
        print(f"ğŸ”— AdaptiveGraphNetwork: {topology} topology, {node_dim}â†’{hidden_dim}â†’{node_dim}")
    
    def build_adjacency(self, num_joints: int, device: torch.device) -> torch.Tensor:
        """
        æ ¹æ®å…³èŠ‚æ•°é‡å’Œæ‹“æ‰‘ç±»å‹æ„å»ºé‚»æ¥çŸ©é˜µ
        """
        adj = torch.zeros(num_joints, num_joints, device=device)
        
        if self.topology == "chain":
            # é“¾å¼ç»“æ„ï¼šæ¯ä¸ªå…³èŠ‚è¿æ¥åˆ°ç›¸é‚»å…³èŠ‚
            for i in range(num_joints - 1):
                adj[i, i + 1] = 1.0
                adj[i + 1, i] = 1.0  # æ— å‘å›¾
        
        elif self.topology == "star":
            # æ˜ŸçŠ¶ç»“æ„ï¼šç¬¬ä¸€ä¸ªå…³èŠ‚è¿æ¥åˆ°æ‰€æœ‰å…¶ä»–å…³èŠ‚
            for i in range(1, num_joints):
                adj[0, i] = 1.0
                adj[i, 0] = 1.0
        
        elif self.topology == "full":
            # å…¨è¿æ¥ï¼šæ¯ä¸ªå…³èŠ‚è¿æ¥åˆ°æ‰€æœ‰å…¶ä»–å…³èŠ‚
            adj = torch.ones(num_joints, num_joints, device=device)
            adj.fill_diagonal_(0)  # ä¸è‡ªè¿æ¥
        
        return adj
    
    def forward(self, joint_features: torch.Tensor, num_joints: int) -> torch.Tensor:
        """
        å›¾ç½‘ç»œå‰å‘ä¼ æ’­
        joint_features: [batch_size, num_joints, node_dim]
        return: [batch_size, num_joints, node_dim]
        """
        batch_size, _, node_dim = joint_features.shape
        device = joint_features.device
        
        # æ„å»ºé‚»æ¥çŸ©é˜µ
        adj = self.build_adjacency(num_joints, device)
        
        # æ¶ˆæ¯ä¼ é€’
        messages = torch.zeros_like(joint_features)
        
        for i in range(num_joints):
            for j in range(num_joints):
                if adj[i, j] > 0:
                    # è®¡ç®—ä»èŠ‚ç‚¹ j åˆ°èŠ‚ç‚¹ i çš„æ¶ˆæ¯
                    edge_input = torch.cat([joint_features[:, i], joint_features[:, j]], dim=1)
                    message = self.message_net(edge_input)
                    messages[:, i] += message * adj[i, j]
        
        # èŠ‚ç‚¹æ›´æ–°
        updated_features = torch.zeros_like(joint_features)
        for i in range(num_joints):
            update_input = torch.cat([joint_features[:, i], messages[:, i]], dim=1)
            updated_features[:, i] = self.update_net(update_input)
        
        # æ®‹å·®è¿æ¥
        output = self.residual_weight * updated_features + (1 - self.residual_weight) * joint_features
        
        return output

class UniversalAttentionPool(nn.Module):
    """
    é€šç”¨æ³¨æ„åŠ›æ± åŒ– - å°†ä»»æ„æ•°é‡çš„å…³èŠ‚ç‰¹å¾èšåˆä¸ºå›ºå®šç»´åº¦
    """
    def __init__(self, feature_dim: int = 32, output_dim: int = 128):
        super(UniversalAttentionPool, self).__init__()
        self.feature_dim = feature_dim
        self.output_dim = output_dim
        
        # æ³¨æ„åŠ›è®¡ç®—
        self.attention_net = nn.Sequential(
            nn.Linear(feature_dim, feature_dim // 2),
            nn.ReLU(),
            nn.Linear(feature_dim // 2, 1)
        )
        
        # ç‰¹å¾å˜æ¢
        self.transform_net = nn.Sequential(
            nn.Linear(feature_dim, output_dim),
            nn.ReLU(),
            nn.LayerNorm(output_dim)
        )
        
        print(f"ğŸ¯ UniversalAttentionPool: {feature_dim} â†’ {output_dim} (ä»»æ„å…³èŠ‚æ•°)")
    
    def forward(self, joint_features: torch.Tensor) -> torch.Tensor:
        """
        æ³¨æ„åŠ›æ± åŒ–
        joint_features: [batch_size, num_joints, feature_dim]
        return: [batch_size, output_dim]
        """
        batch_size, num_joints, feature_dim = joint_features.shape
        
        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        attention_scores = self.attention_net(joint_features)  # [batch_size, num_joints, 1]
        attention_weights = F.softmax(attention_scores, dim=1)  # [batch_size, num_joints, 1]
        
        # åŠ æƒèšåˆ
        weighted_features = joint_features * attention_weights  # [batch_size, num_joints, feature_dim]
        pooled_features = torch.sum(weighted_features, dim=1)  # [batch_size, feature_dim]
        
        # ç‰¹å¾å˜æ¢
        output = self.transform_net(pooled_features)  # [batch_size, output_dim]
        
        return output

class UniversalActionHead(nn.Module):
    """
    é€šç”¨åŠ¨ä½œå¤´ - ç”Ÿæˆä»»æ„æ•°é‡å…³èŠ‚çš„åŠ¨ä½œ
    """
    def __init__(self, input_dim: int = 128, joint_action_dim: int = 1, max_joints: int = 10):
        super(UniversalActionHead, self).__init__()
        self.input_dim = input_dim
        self.joint_action_dim = joint_action_dim
        self.max_joints = max_joints
        
        # å…±äº«ç‰¹å¾å¤„ç†
        self.shared_net = nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.ReLU(),
            nn.LayerNorm(input_dim),
            nn.Dropout(0.1)
        )
        
        # ä¸ºæ¯ä¸ªå¯èƒ½çš„å…³èŠ‚åˆ›å»ºåŠ¨ä½œå¤´
        self.joint_heads = nn.ModuleList([
            nn.Sequential(
                nn.Linear(input_dim, input_dim // 2),
                nn.ReLU(),
                nn.Linear(input_dim // 2, joint_action_dim)
            ) for _ in range(max_joints)
        ])
        
        print(f"ğŸ® UniversalActionHead: {input_dim} â†’ {max_joints} joints Ã— {joint_action_dim} actions")
    
    def forward(self, features: torch.Tensor, num_joints: int) -> torch.Tensor:
        """
        ç”ŸæˆæŒ‡å®šæ•°é‡å…³èŠ‚çš„åŠ¨ä½œ
        features: [batch_size, input_dim]
        num_joints: å®é™…å…³èŠ‚æ•°é‡
        return: [batch_size, num_joints * joint_action_dim]
        """
        batch_size = features.size(0)
        
        # å…±äº«ç‰¹å¾å¤„ç†
        shared_features = self.shared_net(features)
        
        # ç”Ÿæˆæ¯ä¸ªå…³èŠ‚çš„åŠ¨ä½œ
        joint_actions = []
        for i in range(num_joints):
            action = self.joint_heads[i](shared_features)  # [batch_size, joint_action_dim]
            joint_actions.append(action)
        
        # æ‹¼æ¥æ‰€æœ‰å…³èŠ‚çš„åŠ¨ä½œ
        actions = torch.cat(joint_actions, dim=1)  # [batch_size, num_joints * joint_action_dim]
        
        return actions

class UniversalReacherExtractor(BaseFeaturesExtractor):
    """
    é€šç”¨ Reacher ç‰¹å¾æå–å™¨
    æ”¯æŒä»»æ„å…³èŠ‚æ•°é‡çš„ Reacher ä»»åŠ¡
    """
    def __init__(self, observation_space: gym.Space, features_dim: int = 128, 
                 num_joints: int = 2, topology: str = "chain"):
        super(UniversalReacherExtractor, self).__init__(observation_space, features_dim)
        
        self.obs_dim = observation_space.shape[0]
        self.num_joints = num_joints
        self.topology = topology
        
        print(f"ğŸŒŸ UniversalReacherExtractor åˆå§‹åŒ–:")
        print(f"   è§‚å¯Ÿç©ºé—´ç»´åº¦: {self.obs_dim}")
        print(f"   å…³èŠ‚æ•°é‡: {num_joints}")
        print(f"   å›¾æ‹“æ‰‘: {topology}")
        print(f"   è¾“å‡ºç‰¹å¾ç»´åº¦: {features_dim}")
        
        # ç»„ä»¶åˆå§‹åŒ–
        joint_feature_dim = 32
        
        # é€šç”¨å…³èŠ‚ç¼–ç å™¨
        self.joint_encoder = UniversalJointEncoder(joint_feature_dim)
        
        # è‡ªé€‚åº”å›¾ç½‘ç»œ
        self.graph_network = AdaptiveGraphNetwork(
            node_dim=joint_feature_dim,
            hidden_dim=64,
            topology=topology
        )
        
        # é€šç”¨æ³¨æ„åŠ›æ± åŒ–
        self.attention_pool = UniversalAttentionPool(
            feature_dim=joint_feature_dim,
            output_dim=features_dim // 2
        )
        
        # å…¨å±€ç‰¹å¾å¤„ç†ï¼ˆæœ«ç«¯ä½ç½®ã€ç›®æ ‡ä½ç½®ç­‰ï¼‰
        # å‡è®¾æ ¼å¼ï¼š[joint_info, end_effector_pos, target_pos, distance_vector]
        global_feature_dim = self.obs_dim - num_joints * 2  # å‡å»å…³èŠ‚è§’åº¦å’Œé€Ÿåº¦
        if global_feature_dim > 0:
            self.global_encoder = nn.Sequential(
                nn.Linear(global_feature_dim, features_dim // 2),
                nn.ReLU(),
                nn.LayerNorm(features_dim // 2)
            )
        else:
            self.global_encoder = None
        
        # æœ€ç»ˆèåˆ
        fusion_input_dim = features_dim // 2 + (features_dim // 2 if self.global_encoder else 0)
        self.fusion_net = nn.Sequential(
            nn.Linear(fusion_input_dim, features_dim),
            nn.ReLU(),
            nn.LayerNorm(features_dim),
            nn.Dropout(0.1)
        )
        
        print(f"âœ… UniversalReacherExtractor æ„å»ºå®Œæˆ")
        print(f"   å…³èŠ‚ç‰¹å¾ç»´åº¦: {joint_feature_dim}")
        print(f"   å…¨å±€ç‰¹å¾ç»´åº¦: {global_feature_dim}")
        print(f"   èåˆè¾“å…¥ç»´åº¦: {fusion_input_dim}")
        print(f"   æ”¯æŒä»»æ„å…³èŠ‚æ•°é‡æ‰©å±•")
    
    def extract_joint_features(self, observations: torch.Tensor) -> torch.Tensor:
        """
        ä»è§‚å¯Ÿä¸­æå–å…³èŠ‚ç‰¹å¾
        æ”¯æŒä¸åŒçš„è§‚å¯Ÿæ ¼å¼
        """
        batch_size = observations.size(0)
        
        if self.num_joints == 2:
            # MuJoCo Reacher-v5 æ ¼å¼
            # [0:2] - cos/sin of joint angles
            # [2:4] - joint velocities
            joint_features = []
            for i in range(self.num_joints):
                cos_sin = observations[:, i:i+1] if i < 2 else torch.zeros(batch_size, 1, device=observations.device)
                velocity = observations[:, 2+i:2+i+1] if 2+i < self.obs_dim else torch.zeros(batch_size, 1, device=observations.device)
                
                # æ„é€  [cos, sin, velocity] æˆ– [angle, 0, velocity]
                if i == 0:
                    joint_input = torch.cat([observations[:, 0:1], torch.zeros(batch_size, 1, device=observations.device), observations[:, 2:3]], dim=1)
                else:
                    joint_input = torch.cat([observations[:, 1:2], torch.zeros(batch_size, 1, device=observations.device), observations[:, 3:4]], dim=1)
                
                joint_features.append(joint_input)
        else:
            # é€šç”¨æ ¼å¼ï¼šå‡è®¾å‰ num_joints æ˜¯è§’åº¦ï¼Œæ¥ä¸‹æ¥ num_joints æ˜¯é€Ÿåº¦
            joint_features = []
            for i in range(self.num_joints):
                angle = observations[:, i:i+1] if i < self.obs_dim else torch.zeros(batch_size, 1, device=observations.device)
                velocity = observations[:, self.num_joints+i:self.num_joints+i+1] if self.num_joints+i < self.obs_dim else torch.zeros(batch_size, 1, device=observations.device)
                
                # æ„é€  [cos(angle), sin(angle), velocity]
                cos_angle = torch.cos(angle)
                sin_angle = torch.sin(angle)
                joint_input = torch.cat([cos_angle, sin_angle, velocity], dim=1)
                joint_features.append(joint_input)
        
        return torch.stack(joint_features, dim=1)  # [batch_size, num_joints, 3]
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        """
        é€šç”¨å‰å‘ä¼ æ’­
        observations: [batch_size, obs_dim]
        return: [batch_size, features_dim]
        """
        batch_size = observations.size(0)
        
        # 1. æå–å…³èŠ‚ç‰¹å¾
        joint_raw_features = self.extract_joint_features(observations)  # [batch_size, num_joints, 3]
        
        # 2. ç¼–ç æ¯ä¸ªå…³èŠ‚
        joint_encoded_features = []
        for i in range(self.num_joints):
            encoded = self.joint_encoder(joint_raw_features[:, i])  # [batch_size, joint_feature_dim]
            joint_encoded_features.append(encoded)
        
        joint_encoded = torch.stack(joint_encoded_features, dim=1)  # [batch_size, num_joints, joint_feature_dim]
        
        # 3. å›¾ç½‘ç»œå¤„ç†
        joint_graph_features = self.graph_network(joint_encoded, self.num_joints)
        
        # 4. æ³¨æ„åŠ›æ± åŒ–
        joint_pooled = self.attention_pool(joint_graph_features)  # [batch_size, features_dim//2]
        
        # 5. å¤„ç†å…¨å±€ç‰¹å¾
        if self.global_encoder is not None:
            global_start_idx = self.num_joints * 2
            global_features = observations[:, global_start_idx:]
            global_encoded = self.global_encoder(global_features)  # [batch_size, features_dim//2]
            
            # 6. èåˆç‰¹å¾
            fused_features = torch.cat([joint_pooled, global_encoded], dim=1)
        else:
            fused_features = joint_pooled
        
        # 7. æœ€ç»ˆå¤„ç†
        output = self.fusion_net(fused_features)
        
        return output

def create_universal_reacher_env(num_joints: int = 2):
    """
    åˆ›å»ºé€šç”¨ Reacher ç¯å¢ƒ
    ç›®å‰æ”¯æŒæ ‡å‡† MuJoCo Reacherï¼Œæœªæ¥å¯æ‰©å±•
    """
    if num_joints == 2:
        return gym.make('Reacher-v5')
    else:
        # æœªæ¥å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å¤šå…³èŠ‚ Reacher ç¯å¢ƒ
        raise NotImplementedError(f"æš‚ä¸æ”¯æŒ {num_joints} å…³èŠ‚ Reacherï¼Œä½†æ¶æ„å·²å‡†å¤‡å¥½")

def train_universal_reacher(num_joints: int = 2, topology: str = "chain", total_timesteps: int = 30000):
    """
    è®­ç»ƒé€šç”¨ Reacher æ¨¡å‹
    """
    print("ğŸŒŸ é€šç”¨ Reacher SAC è®­ç»ƒ")
    print(f"ğŸ”— å…³èŠ‚æ•°é‡: {num_joints}")
    print(f"ğŸ•¸ï¸ å›¾æ‹“æ‰‘: {topology}")
    print(f"ğŸ¯ è®¾è®¡ç†å¿µ: ä¸€ä¸ªæ¶æ„ï¼Œæ”¯æŒä»»æ„å…³èŠ‚æ•°")
    print("=" * 70)
    
    # åˆ›å»ºç¯å¢ƒ
    print(f"ğŸ­ åˆ›å»º {num_joints} å…³èŠ‚ Reacher ç¯å¢ƒ...")
    try:
        env = create_universal_reacher_env(num_joints)
        env = Monitor(env)
        
        eval_env = create_universal_reacher_env(num_joints)
        eval_env = Monitor(eval_env)
        
        print(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ")
        print(f"ğŸ® åŠ¨ä½œç©ºé—´: {env.action_space}")
        print(f"ğŸ‘ï¸ è§‚å¯Ÿç©ºé—´: {env.observation_space}")
        
    except NotImplementedError as e:
        print(f"âš ï¸ {e}")
        print("ğŸ”§ ä½¿ç”¨ 2 å…³èŠ‚ç¯å¢ƒè¿›è¡Œæ¶æ„éªŒè¯...")
        env = create_universal_reacher_env(2)
        env = Monitor(env)
        eval_env = create_universal_reacher_env(2)
        eval_env = Monitor(eval_env)
    
    print("=" * 70)
    
    # åˆ›å»ºé€šç”¨æ¨¡å‹
    print("ğŸ¤– åˆ›å»ºé€šç”¨ SAC æ¨¡å‹...")
    
    policy_kwargs = {
        "features_extractor_class": UniversalReacherExtractor,
        "features_extractor_kwargs": {
            "features_dim": 128,
            "num_joints": num_joints,
            "topology": topology
        },
        "net_arch": [128, 128],
        "activation_fn": torch.nn.ReLU,
    }
    
    model = SAC(
        "MlpPolicy",
        env,
        learning_rate=3e-4,
        buffer_size=100000,
        learning_starts=100,
        batch_size=128,
        tau=0.005,
        gamma=0.99,
        train_freq=1,
        gradient_steps=1,
        ent_coef='auto',
        target_update_interval=1,
        use_sde=False,
        policy_kwargs=policy_kwargs,
        verbose=1,
        device='cpu'
    )
    
    print("âœ… é€šç”¨ SAC æ¨¡å‹åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“Š æ¨¡å‹ç‰¹ç‚¹:")
    print(f"   âœ¨ æ”¯æŒä»»æ„å…³èŠ‚æ•°é‡")
    print(f"   ğŸ”— è‡ªé€‚åº”å›¾ç½‘ç»œæ‹“æ‰‘")
    print(f"   ğŸ¯ é€šç”¨æ³¨æ„åŠ›æ± åŒ–")
    print(f"   ğŸ® å¯æ‰©å±•åŠ¨ä½œç”Ÿæˆ")
    print(f"   ğŸ”„ ä¸€æ¬¡è®­ç»ƒï¼Œå¤šç§é…ç½®")
    
    print("=" * 70)
    
    # åˆ›å»ºè¯„ä¼°å›è°ƒ
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=f'./universal_reacher_{num_joints}joints_{topology}_best/',
        log_path=f'./universal_reacher_{num_joints}joints_{topology}_logs/',
        eval_freq=5000,
        n_eval_episodes=10,
        deterministic=True,
        render=False
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸ¯ å¼€å§‹é€šç”¨æ¨¡å‹è®­ç»ƒ...")
    print("ğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"   æ€»æ­¥æ•°: {total_timesteps:,}")
    print("   è¯„ä¼°é¢‘ç‡: æ¯ 5,000 æ­¥")
    print("   é¢„æœŸ: éªŒè¯é€šç”¨æ¶æ„çš„æœ‰æ•ˆæ€§")
    print("=" * 70)
    
    start_time = time.time()
    
    # è®­ç»ƒæ¨¡å‹
    model.learn(
        total_timesteps=total_timesteps,
        callback=eval_callback,
        log_interval=10,
        progress_bar=True
    )
    
    training_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ† é€šç”¨æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸ è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
    print("=" * 70)
    
    # ä¿å­˜æ¨¡å‹
    model_name = f"universal_reacher_{num_joints}joints_{topology}_final"
    model.save(model_name)
    print(f"ğŸ’¾ é€šç”¨æ¨¡å‹å·²ä¿å­˜ä¸º: {model_name}.zip")
    
    # æœ€ç»ˆè¯„ä¼°
    print("\nğŸ” æœ€ç»ˆè¯„ä¼° (20 episodes)...")
    mean_reward, std_reward = evaluate_policy(
        model, 
        eval_env, 
        n_eval_episodes=20,
        deterministic=True,
        render=False
    )
    
    print(f"ğŸ“Š é€šç”¨æ¨¡å‹è¯„ä¼°ç»“æœ:")
    print(f"   å¹³å‡å¥–åŠ±: {mean_reward:.2f} Â± {std_reward:.2f}")
    
    # ä¸åŸºå‡†å¯¹æ¯”
    baseline_reward = -4.86
    improvement = mean_reward - baseline_reward
    
    print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
    print(f"   Baseline SAC: {baseline_reward:.2f}")
    print(f"   é€šç”¨æ¨¡å‹: {mean_reward:.2f}")
    print(f"   æ”¹è¿›: {improvement:+.2f}")
    
    if improvement > -0.5:
        print("   ğŸ‰ é€šç”¨æ¶æ„æ€§èƒ½ä¼˜ç§€!")
    elif improvement > -1.0:
        print("   ğŸ‘ é€šç”¨æ¶æ„æ€§èƒ½è‰¯å¥½!")
    else:
        print("   âš ï¸ é€šç”¨æ¶æ„éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    # æ¼”ç¤º
    print("\nğŸ® æ¼”ç¤ºé€šç”¨æ¨¡å‹ (10 episodes)...")
    demo_env = create_universal_reacher_env(num_joints)
    
    episode_rewards = []
    success_count = 0
    
    for episode in range(10):
        obs, info = demo_env.reset()
        episode_reward = 0
        
        while True:
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = demo_env.step(action)
            episode_reward += reward
            
            if terminated or truncated:
                break
        
        episode_rewards.append(episode_reward)
        
        if episode_reward > -5:
            success_count += 1
            print(f"ğŸ¯ Episode {episode+1}: æˆåŠŸ! å¥–åŠ±={episode_reward:.2f}")
        else:
            print(f"ğŸ“Š Episode {episode+1}: å¥–åŠ±={episode_reward:.2f}")
    
    demo_env.close()
    
    demo_success_rate = success_count / 10
    demo_avg_reward = np.mean(episode_rewards)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š é€šç”¨æ¨¡å‹æ¼”ç¤ºç»Ÿè®¡:")
    print(f"   æˆåŠŸç‡: {demo_success_rate:.1%} ({success_count}/10)")
    print(f"   å¹³å‡å¥–åŠ±: {demo_avg_reward:.2f}")
    print(f"   å¥–åŠ±æ ‡å‡†å·®: {np.std(episode_rewards):.2f}")
    
    print(f"\nğŸŒŸ é€šç”¨æ¶æ„ç‰¹ç‚¹:")
    print(f"   âœ… æ”¯æŒ {num_joints} å…³èŠ‚é…ç½®")
    print(f"   âœ… ä½¿ç”¨ {topology} å›¾æ‹“æ‰‘")
    print(f"   âœ… å¯æ‰©å±•åˆ°æ›´å¤šå…³èŠ‚")
    print(f"   âœ… ä¸€æ¬¡è®­ç»ƒï¼Œå¤šç§åº”ç”¨")
    
    print(f"\nğŸ”® æœªæ¥æ‰©å±•èƒ½åŠ›:")
    print(f"   ğŸ”— æ”¯æŒ 3-10 å…³èŠ‚ Reacher")
    print(f"   ğŸ•¸ï¸ æ”¯æŒä¸åŒå›¾æ‹“æ‰‘ (chain/star/full)")
    print(f"   ğŸ¯ æ”¯æŒè¿ç§»å­¦ä¹ ")
    print(f"   ğŸ”„ æ”¯æŒåœ¨çº¿é€‚åº”")
    
    # æ¸…ç†
    env.close()
    eval_env.close()
    
    return {
        'mean_reward': mean_reward,
        'std_reward': std_reward,
        'training_time': training_time,
        'demo_success_rate': demo_success_rate,
        'demo_avg_reward': demo_avg_reward,
        'improvement': improvement,
        'num_joints': num_joints,
        'topology': topology
    }

if __name__ == "__main__":
    print("ğŸŒŸ é€šç”¨ Reacher SAC è®­ç»ƒç³»ç»Ÿ")
    print("ğŸ¯ ç›®æ ‡: ä¸€ä¸ªæ¨¡å‹ï¼Œæ”¯æŒä»»æ„å…³èŠ‚æ•°é‡")
    print("ğŸ”§ ç‰¹ç‚¹: å¯æ‰©å±•ã€å¯é…ç½®ã€å¯è¿ç§»")
    print()
    
    # æµ‹è¯•é…ç½®
    configs = [
        {"num_joints": 2, "topology": "chain", "total_timesteps": 30000},
        # æœªæ¥å¯ä»¥æµ‹è¯•æ›´å¤šé…ç½®:
        # {"num_joints": 3, "topology": "chain", "total_timesteps": 50000},
        # {"num_joints": 2, "topology": "star", "total_timesteps": 30000},
    ]
    
    results = []
    
    for config in configs:
        print(f"\n{'='*60}")
        print(f"ğŸ§  æµ‹è¯•é…ç½®: {config}")
        print(f"{'='*60}")
        
        try:
            result = train_universal_reacher(**config)
            results.append(result)
            
            print(f"\nğŸŠ é…ç½® {config} è®­ç»ƒç»“æœ:")
            print(f"   æœ€ç»ˆè¯„ä¼°å¥–åŠ±: {result['mean_reward']:.2f} Â± {result['std_reward']:.2f}")
            print(f"   è®­ç»ƒæ—¶é—´: {result['training_time']/60:.1f} åˆ†é’Ÿ")
            print(f"   æ¼”ç¤ºæˆåŠŸç‡: {result['demo_success_rate']:.1%}")
            print(f"   vs Baseline æ”¹è¿›: {result['improvement']:+.2f}")
            
            if result['improvement'] > -0.5:
                print(f"   ğŸ† é€šç”¨æ¶æ„è¡¨ç°ä¼˜ç§€!")
            elif result['improvement'] > -1.0:
                print(f"   ğŸ‘ é€šç”¨æ¶æ„è¡¨ç°è‰¯å¥½!")
            else:
                print(f"   ğŸ“ˆ é€šç”¨æ¶æ„æœ‰æ”¹è¿›ç©ºé—´")
            
        except Exception as e:
            print(f"âŒ é…ç½® {config} è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æ€»ç»“
    if results:
        print(f"\n{'='*60}")
        print("ğŸŒŸ é€šç”¨ Reacher æ¶æ„æ€»ç»“")
        print(f"{'='*60}")
        
        avg_improvement = np.mean([r['improvement'] for r in results])
        avg_success_rate = np.mean([r['demo_success_rate'] for r in results])
        
        print(f"ğŸ“Š æ•´ä½“æ€§èƒ½:")
        print(f"   å¹³å‡æ”¹è¿›: {avg_improvement:+.2f}")
        print(f"   å¹³å‡æˆåŠŸç‡: {avg_success_rate:.1%}")
        
        print(f"\nğŸ¯ æ¶æ„ä¼˜åŠ¿:")
        print(f"   âœ… ç»Ÿä¸€æ¶æ„å¤„ç†ä¸åŒå…³èŠ‚æ•°")
        print(f"   âœ… å¯é…ç½®å›¾ç½‘ç»œæ‹“æ‰‘")
        print(f"   âœ… è‡ªé€‚åº”ç‰¹å¾æå–")
        print(f"   âœ… ä¸ºå¤šå…³èŠ‚æ‰©å±•åšå¥½å‡†å¤‡")
        
        print(f"\nğŸ”® ä¸‹ä¸€æ­¥:")
        print(f"   1. å®ç°çœŸæ­£çš„å¤šå…³èŠ‚ Reacher ç¯å¢ƒ")
        print(f"   2. æµ‹è¯• 3-5 å…³èŠ‚é…ç½®")
        print(f"   3. éªŒè¯è·¨å…³èŠ‚æ•°è¿ç§»å­¦ä¹ ")
        print(f"   4. é›†æˆåˆ° MAP-Elites æ¡†æ¶")
        
        print(f"\nâœ… é€šç”¨æ¶æ„éªŒè¯å®Œæˆ!")
        print(f"ğŸš€ å·²å‡†å¤‡å¥½å¤„ç†ä»»æ„å…³èŠ‚æ•°é‡çš„ Reacher ä»»åŠ¡!")
