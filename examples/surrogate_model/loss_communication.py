#!/usr/bin/env python3
"""
æŸå¤±é€šä¿¡æ¨¡å—
ç”¨äºåœ¨è®­ç»ƒè¿›ç¨‹å’ŒæŸå¤±è®°å½•å™¨ä¹‹é—´è¿›è¡Œå®æ—¶é€šä¿¡
"""

import os
import json
import time
import tempfile
import fcntl
from typing import Dict, Any
from pathlib import Path

class LossCommunicator:
    """æŸå¤±é€šä¿¡å™¨ - ç”¨äºè¿›ç¨‹é—´æŸå¤±æ•°æ®ä¼ é€’"""
    
    def __init__(self, experiment_name: str):
        self.experiment_name = experiment_name
        self.comm_dir = Path(tempfile.gettempdir()) / f"loss_comm_{experiment_name}"
        self.comm_dir.mkdir(exist_ok=True)
        
        # é€šä¿¡æ–‡ä»¶è·¯å¾„
        self.loss_file = self.comm_dir / "losses.jsonl"
        self.status_file = self.comm_dir / "status.json"
        
        # åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶
        self._write_status("initialized")
        
    def send_loss(self, network: str, step: int, losses: Dict[str, float], timestamp: float = None):
        """å‘é€æŸå¤±æ•°æ®åˆ°è®°å½•å™¨"""
        if timestamp is None:
            timestamp = time.time()
            
        loss_data = {
            'network': network,
            'step': step,
            'timestamp': timestamp,
            'losses': losses
        }
        
        # åŸå­å†™å…¥æŸå¤±æ•°æ®
        try:
            with open(self.loss_file, 'a') as f:
                # æ–‡ä»¶é”ç¡®ä¿åŸå­å†™å…¥
                fcntl.flock(f.fileno(), fcntl.LOCK_EX)
                f.write(json.dumps(loss_data) + '\n')
                fcntl.flock(f.fileno(), fcntl.LOCK_UN)
        except Exception as e:
            print(f"âš ï¸ å‘é€æŸå¤±æ•°æ®å¤±è´¥: {e}")
    
    def receive_losses(self):
        """æ¥æ”¶æŸå¤±æ•°æ®ï¼ˆæŸå¤±è®°å½•å™¨è°ƒç”¨ï¼‰"""
        if not self.loss_file.exists():
            return []
            
        losses = []
        try:
            with open(self.loss_file, 'r') as f:
                fcntl.flock(f.fileno(), fcntl.LOCK_SH)
                for line in f:
                    line = line.strip()
                    if line:
                        try:
                            loss_data = json.loads(line)
                            losses.append(loss_data)
                        except json.JSONDecodeError:
                            continue
                fcntl.flock(f.fileno(), fcntl.LOCK_UN)
                            
            # è¯»å–åæ¸…ç©ºæ–‡ä»¶
            if losses:
                self.loss_file.write_text("")
                
        except Exception as e:
            print(f"âš ï¸ æ¥æ”¶æŸå¤±æ•°æ®å¤±è´¥: {e}")
            
        return losses
    
    def _write_status(self, status: str):
        """å†™å…¥çŠ¶æ€ä¿¡æ¯"""
        status_data = {
            'status': status,
            'timestamp': time.time(),
            'experiment': self.experiment_name
        }
        
        try:
            with open(self.status_file, 'w') as f:
                json.dump(status_data, f)
        except Exception as e:
            print(f"âš ï¸ å†™å…¥çŠ¶æ€å¤±è´¥: {e}")
    
    def cleanup(self):
        """æ¸…ç†é€šä¿¡æ–‡ä»¶"""
        try:
            if self.loss_file.exists():
                self.loss_file.unlink()
            if self.status_file.exists():
                self.status_file.unlink()
            if self.comm_dir.exists():
                self.comm_dir.rmdir()
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†é€šä¿¡æ–‡ä»¶å¤±è´¥: {e}")


class RealTimeLossCollector:
    """å®æ—¶æŸå¤±æ”¶é›†å™¨ - åœ¨æŸå¤±è®°å½•å™¨è¿›ç¨‹ä¸­è¿è¡Œ"""
    
    def __init__(self, experiment_name: str, loss_logger_interface):
        self.experiment_name = experiment_name
        self.communicator = LossCommunicator(experiment_name)
        self.loss_logger = loss_logger_interface
        self.running = False
        
    def start_collecting(self):
        """å¼€å§‹æ”¶é›†æŸå¤±æ•°æ®"""
        self.running = True
        print(f"ğŸ”„ å¼€å§‹å®æ—¶æ”¶é›†æŸå¤±æ•°æ®: {self.experiment_name}")
        
        while self.running:
            try:
                # æ¥æ”¶æ–°çš„æŸå¤±æ•°æ®
                new_losses = self.communicator.receive_losses()
                
                # è®°å½•åˆ°æŸå¤±è®°å½•å™¨
                for loss_data in new_losses:
                    network = loss_data['network']
                    step = loss_data['step']
                    timestamp = loss_data['timestamp']
                    losses = loss_data['losses']
                    
                    # è°ƒç”¨æŸå¤±è®°å½•å™¨
                    from loss_logger_interface import log_network_loss
                    log_network_loss(network, step, losses, timestamp)
                
                if new_losses:
                    print(f"ğŸ“Š æ”¶é›†åˆ° {len(new_losses)} æ¡æŸå¤±æ•°æ®")
                
                # çŸ­æš‚ä¼‘çœ é¿å…è¿‡åº¦å ç”¨CPU
                time.sleep(0.1)
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"âŒ æ”¶é›†æŸå¤±æ•°æ®æ—¶å‡ºé”™: {e}")
                time.sleep(1)
        
        print("ğŸ›‘ åœæ­¢æ”¶é›†æŸå¤±æ•°æ®")
        self.communicator.cleanup()
    
    def stop_collecting(self):
        """åœæ­¢æ”¶é›†"""
        self.running = False


# ä¾¿æ·å‡½æ•°
def send_training_loss(experiment_name: str, network: str, step: int, losses: Dict[str, float]):
    """å‘é€è®­ç»ƒæŸå¤±çš„ä¾¿æ·å‡½æ•°"""
    communicator = LossCommunicator(experiment_name)
    communicator.send_loss(network, step, losses)


if __name__ == "__main__":
    # æµ‹è¯•é€šä¿¡
    experiment = "test_comm"
    
    # æ¨¡æ‹Ÿå‘é€ç«¯
    comm = LossCommunicator(experiment)
    
    # å‘é€ä¸€äº›æµ‹è¯•æ•°æ®
    for i in range(10):
        comm.send_loss('ppo', i, {'actor_loss': 1.0 - i*0.1, 'critic_loss': 0.8 - i*0.05})
        time.sleep(0.1)
    
    # æ¨¡æ‹Ÿæ¥æ”¶ç«¯
    received = comm.receive_losses()
    print(f"æ¥æ”¶åˆ° {len(received)} æ¡æ•°æ®")
    for data in received:
        print(f"  {data}")
    
    comm.cleanup()
    print("âœ… é€šä¿¡æµ‹è¯•å®Œæˆ")
