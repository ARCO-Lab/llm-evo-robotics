#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæ¨¡å‹è¯„ä¼°è„šæœ¬
åŠŸèƒ½ï¼š
- å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ï¼šæˆåŠŸç‡ã€å¹³å‡å¥–åŠ±ã€æœ€å°è·ç¦»ã€è·¯å¾„æ•ˆç‡ç­‰
- å¤šä¸ªæµ‹è¯•åœºæ™¯ï¼šä¸åŒèµ·å§‹ä½ç½®ã€ä¸åŒç›®æ ‡ä½ç½®
- å¯è§†åŒ–é€‰é¡¹ï¼šæ˜¾ç¤ºè½¨è¿¹ã€ä¿å­˜ç»“æœå›¾è¡¨
- æ€§èƒ½åˆ†æï¼šåŠ¨ä½œåˆ†å¸ƒã€è§’åº¦ä½¿ç”¨æƒ…å†µç­‰

ä½¿ç”¨æ–¹å¼: 
python evaluate_model.py --model-path ./trained_models/reacher2d/test/*/best_models/final_model_step_19999.pth --episodes 20
"""

import sys
import os
import torch
import numpy as np
import argparse
import time
import matplotlib.pyplot as plt
from collections import defaultdict
import json

# æ·»åŠ è·¯å¾„
base_dir = os.path.join(os.path.dirname(__file__), '../../')
sys.path.append(base_dir)
sys.path.insert(0, os.path.join(base_dir, 'examples/2d_reacher/envs'))
sys.path.insert(0, os.path.join(base_dir, 'examples/surrogate_model/attn_model'))
sys.path.insert(0, os.path.join(base_dir, 'examples/surrogate_model/sac'))
sys.path.insert(0, os.path.join(base_dir, 'examples/2d_reacher/utils'))

from reacher2d_env import Reacher2DEnv
from attn_model import AttnModel
from sac_model import AttentionSACWithBuffer
from reacher2d_gnn_encoder import Reacher2D_GNN_Encoder


class ModelEvaluator:
    def __init__(self, model_path, config_path=None):
        self.model_path = model_path
        self.config_path = config_path or "/home/xli149/Documents/repos/RoboGrammar/examples/2d_reacher/configs/reacher_with_zigzag_obstacles.yaml"
        
        # ç¯å¢ƒé…ç½®
        self.env_params = {
            'num_links': 4,
            'link_lengths': [80, 80, 80, 60],
            'render_mode': None,  # é»˜è®¤ä¸æ¸²æŸ“ï¼Œå¯åœ¨è¯„ä¼°æ—¶å¼€å¯
            'config_path': self.config_path
        }
        
        # åˆå§‹åŒ–ç¯å¢ƒå’Œæ¨¡å‹
        self.env = None
        self.sac = None
        self.gnn_embed = None
        self.model_info = {}
        
        self._setup_model()
    
    def _setup_model(self):
        """è®¾ç½®æ¨¡å‹å’Œç¯å¢ƒ"""
        # åˆ›å»ºç¯å¢ƒ
        self.env = Reacher2DEnv(**self.env_params)
        num_joints = self.env.action_space.shape[0]
        
        # åˆ›å»ºGNNç¼–ç å™¨
        reacher2d_encoder = Reacher2D_GNN_Encoder(max_nodes=20, num_joints=num_joints)
        self.gnn_embed = reacher2d_encoder.get_gnn_embeds(
            num_links=num_joints, 
            link_lengths=self.env_params['link_lengths']
        )
        
        # åˆ›å»ºSACæ¨¡å‹
        attn_model = AttnModel(128, 128, 130, 4)
        self.sac = AttentionSACWithBuffer(attn_model, num_joints, env_type='reacher2d')
        
        # åŠ è½½æ¨¡å‹
        if os.path.exists(self.model_path):
            model_data = torch.load(self.model_path, map_location='cpu')
            self.sac.actor.load_state_dict(model_data['actor_state_dict'])
            
            # æå–æ¨¡å‹ä¿¡æ¯
            self.model_info = {
                'step': model_data.get('step', 'N/A'),
                'success_rate': model_data.get('success_rate', 'N/A'),
                'min_distance': model_data.get('min_distance', 'N/A'),
                'timestamp': model_data.get('timestamp', 'N/A'),
                'final_success_rate': model_data.get('final_success_rate', 'N/A'),
                'final_min_distance': model_data.get('final_min_distance', 'N/A'),
                'training_completed': model_data.get('training_completed', False)
            }
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
            for key, value in self.model_info.items():
                print(f"   {key}: {value}")
        else:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
    
    def evaluate_basic_performance(self, num_episodes=20, max_steps=1000, goal_threshold=50.0, render=False):
        """åŸºæœ¬æ€§èƒ½è¯„ä¼°"""
        print(f"\nğŸ¯ å¼€å§‹åŸºæœ¬æ€§èƒ½è¯„ä¼° ({num_episodes} episodes)")
        
        if render:
            self.env_params['render_mode'] = 'human'
            self.env = Reacher2DEnv(**self.env_params)
        
        results = {
            'episodes': [],
            'success_count': 0,
            'total_rewards': [],
            'min_distances': [],
            'step_counts': [],
            'action_stats': defaultdict(list),
            'trajectories': []
        }
        
        for episode in range(num_episodes):
            obs = self.env.reset()
            episode_reward = 0
            step_count = 0
            min_distance_this_episode = float('inf')
            trajectory = []
            episode_actions = []
            
            print(f"  Episode {episode + 1}/{num_episodes}", end="")
            
            while step_count < max_steps:
                # è·å–åŠ¨ä½œ
                action = self.sac.get_action(
                    torch.from_numpy(obs).float(),
                    self.gnn_embed.squeeze(0),
                    num_joints=self.env.action_space.shape[0],
                    deterministic=True
                )
                
                # è®°å½•è½¨è¿¹
                end_pos = self.env._get_end_effector_position()
                trajectory.append(end_pos.copy())
                episode_actions.append(action.cpu().numpy().copy())
                
                # æ‰§è¡ŒåŠ¨ä½œ
                obs, reward, done, info = self.env.step(action.cpu().numpy())
                episode_reward += reward
                step_count += 1
                
                # è®¡ç®—è·ç¦»
                goal_pos = self.env.goal_pos
                distance = np.linalg.norm(np.array(end_pos) - goal_pos)
                min_distance_this_episode = min(min_distance_this_episode, distance)
                
                if render:
                    self.env.render()
                    time.sleep(0.01)  # æ§åˆ¶æ¸²æŸ“é€Ÿåº¦
                
                # æ£€æŸ¥æˆåŠŸ
                if distance <= goal_threshold:
                    results['success_count'] += 1
                    print(f" âœ… æˆåŠŸ! (è·ç¦»: {distance:.1f}px, æ­¥éª¤: {step_count})")
                    break
                    
                if done:
                    break
            
            if min_distance_this_episode > goal_threshold:
                print(f" âŒ å¤±è´¥ (æœ€å°è·ç¦»: {min_distance_this_episode:.1f}px)")
            
            # è®°å½•ç»“æœ
            results['episodes'].append({
                'episode': episode + 1,
                'reward': episode_reward,
                'min_distance': min_distance_this_episode,
                'steps': step_count,
                'success': min_distance_this_episode <= goal_threshold
            })
            
            results['total_rewards'].append(episode_reward)
            results['min_distances'].append(min_distance_this_episode)
            results['step_counts'].append(step_count)
            results['trajectories'].append(trajectory)
            
            # åŠ¨ä½œç»Ÿè®¡
            episode_actions = np.array(episode_actions)
            for i in range(episode_actions.shape[1]):
                results['action_stats'][f'joint_{i+1}'].extend(episode_actions[:, i])
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        success_rate = results['success_count'] / num_episodes
        avg_reward = np.mean(results['total_rewards'])
        avg_min_distance = np.mean(results['min_distances'])
        avg_steps = np.mean(results['step_counts'])
        
        results['summary'] = {
            'success_rate': success_rate,
            'avg_reward': avg_reward,
            'avg_min_distance': avg_min_distance,
            'avg_steps': avg_steps,
            'goal_threshold': goal_threshold
        }
        
        return results
    
    def evaluate_robustness(self, num_tests=10):
        """é²æ£’æ€§è¯„ä¼°ï¼šæµ‹è¯•ä¸åŒåˆå§‹æ¡ä»¶"""
        print(f"\nğŸ”„ å¼€å§‹é²æ£’æ€§è¯„ä¼° ({num_tests} æµ‹è¯•)")
        
        results = []
        
        # æµ‹è¯•ä¸åŒçš„åˆå§‹è§’åº¦é…ç½®
        initial_angles = [
            [0, 0, 0, 0],           # æ°´å¹³
            [45, -45, 45, -45],     # ä¹‹å­—å½¢
            [90, 0, -90, 0],        # äº¤æ›¿
            [-45, -45, -45, -45],   # å…¨å‘ä¸‹
            [30, 60, -30, -60],     # æ¸å˜
        ]
        
        for test_idx, angles in enumerate(initial_angles):
            if test_idx >= num_tests:
                break
                
            print(f"  æµ‹è¯• {test_idx + 1}: åˆå§‹è§’åº¦ {angles}")
            
            # è®¾ç½®åˆå§‹è§’åº¦
            obs = self.env.reset()
            for i, angle in enumerate(angles):
                if i < len(self.env.bodies):
                    self.env.bodies[i].angle = np.radians(angle)
            
            # è¿è¡Œä¸€ä¸ªepisode
            episode_reward = 0
            step_count = 0
            max_steps = 500
            
            while step_count < max_steps:
                action = self.sac.get_action(
                    torch.from_numpy(obs).float(),
                    self.gnn_embed.squeeze(0),
                    num_joints=self.env.action_space.shape[0],
                    deterministic=True
                )
                
                obs, reward, done, info = self.env.step(action.cpu().numpy())
                episode_reward += reward
                step_count += 1
                
                end_pos = self.env._get_end_effector_position()
                distance = np.linalg.norm(np.array(end_pos) - self.env.goal_pos)
                
                if distance <= 50.0:
                    print(f"    âœ… æˆåŠŸåˆ°è¾¾ç›®æ ‡ (æ­¥éª¤: {step_count})")
                    break
                    
                if done:
                    break
            
            results.append({
                'test': test_idx + 1,
                'initial_angles': angles,
                'final_reward': episode_reward,
                'steps': step_count,
                'success': distance <= 50.0
            })
        
        return results
    
    def analyze_actions(self, num_episodes=5):
        """åŠ¨ä½œåˆ†æï¼šåˆ†ææ¨¡å‹çš„åŠ¨ä½œæ¨¡å¼"""
        print(f"\nğŸ“Š å¼€å§‹åŠ¨ä½œåˆ†æ ({num_episodes} episodes)")
        
        all_actions = []
        all_observations = []
        
        for episode in range(num_episodes):
            obs = self.env.reset()
            episode_actions = []
            episode_obs = []
            
            for step in range(200):  # åˆ†æå‰200æ­¥
                action = self.sac.get_action(
                    torch.from_numpy(obs).float(),
                    self.gnn_embed.squeeze(0),
                    num_joints=self.env.action_space.shape[0],
                    deterministic=True
                )
                
                episode_actions.append(action.cpu().numpy())
                episode_obs.append(obs.copy())
                
                obs, reward, done, info = self.env.step(action.cpu().numpy())
                
                if done:
                    break
            
            all_actions.extend(episode_actions)
            all_observations.extend(episode_obs)
        
        # åˆ†æåŠ¨ä½œç»Ÿè®¡
        all_actions = np.array(all_actions)
        analysis = {
            'action_means': np.mean(all_actions, axis=0),
            'action_stds': np.std(all_actions, axis=0),
            'action_mins': np.min(all_actions, axis=0),
            'action_maxs': np.max(all_actions, axis=0),
            'action_ranges': np.max(all_actions, axis=0) - np.min(all_actions, axis=0)
        }
        
        return analysis
    
    def save_results(self, results, output_dir="evaluation_results"):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜JSONç»“æœ
        json_file = os.path.join(output_dir, "evaluation_results.json")
        with open(json_file, 'w') as f:
            # å¤„ç†numpyç±»å‹
            def convert_numpy(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                return obj
            
            # é€’å½’è½¬æ¢numpyç±»å‹
            def recursive_convert(obj):
                if isinstance(obj, dict):
                    return {k: recursive_convert(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [recursive_convert(v) for v in obj]
                else:
                    return convert_numpy(obj)
            
            json.dump(recursive_convert(results), f, indent=2)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {json_file}")
        
        return json_file
    
    def print_summary(self, results):
        """æ‰“å°è¯„ä¼°æ€»ç»“"""
        print(f"\n{'='*60}")
        print(f"ğŸ† æ¨¡å‹è¯„ä¼°æ€»ç»“")
        print(f"{'='*60}")
        
        if 'summary' in results:
            summary = results['summary']
            print(f"ğŸ“Š åŸºæœ¬æ€§èƒ½:")
            print(f"   æˆåŠŸç‡: {summary['success_rate']:.1%}")
            print(f"   å¹³å‡å¥–åŠ±: {summary['avg_reward']:.2f}")
            print(f"   å¹³å‡æœ€å°è·ç¦»: {summary['avg_min_distance']:.1f} pixels")
            print(f"   å¹³å‡æ­¥éª¤æ•°: {summary['avg_steps']:.1f}")
            print(f"   ç›®æ ‡é˜ˆå€¼: {summary['goal_threshold']:.1f} pixels")
        
        print(f"\nğŸ¤– æ¨¡å‹ä¿¡æ¯:")
        for key, value in self.model_info.items():
            print(f"   {key}: {value}")
        
        print(f"{'='*60}")

    def close(self):
        """æ¸…ç†èµ„æº"""
        if self.env:
            self.env.close()


def main():
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆæ¨¡å‹è¯„ä¼°è„šæœ¬")
    parser.add_argument('--model-path', type=str, required=True,
                        help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--episodes', type=int, default=20,
                        help='åŸºæœ¬è¯„ä¼°çš„episodeæ•°é‡')
    parser.add_argument('--render', action='store_true',
                        help='æ˜¯å¦æ˜¾ç¤ºæ¸²æŸ“')
    parser.add_argument('--robustness-tests', type=int, default=5,
                        help='é²æ£’æ€§æµ‹è¯•æ•°é‡')
    parser.add_argument('--output-dir', type=str, default='evaluation_results',
                        help='ç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--goal-threshold', type=float, default=50.0,
                        help='ç›®æ ‡æˆåŠŸé˜ˆå€¼(åƒç´ )')
    
    args = parser.parse_args()
    
    print(f"ğŸ§ª å¼€å§‹è¯„ä¼°æ¨¡å‹: {args.model_path}")
    print(f"ğŸ“Š è¯„ä¼°é…ç½®:")
    print(f"   Episodes: {args.episodes}")
    print(f"   ç›®æ ‡é˜ˆå€¼: {args.goal_threshold} pixels")
    print(f"   é²æ£’æ€§æµ‹è¯•: {args.robustness_tests}")
    print(f"   æ¸²æŸ“: {'æ˜¯' if args.render else 'å¦'}")
    
    try:
        # åˆ›å»ºè¯„ä¼°å™¨
        evaluator = ModelEvaluator(args.model_path)
        
        # åŸºæœ¬æ€§èƒ½è¯„ä¼°
        basic_results = evaluator.evaluate_basic_performance(
            num_episodes=args.episodes,
            goal_threshold=args.goal_threshold,
            render=args.render
        )
        
        # é²æ£’æ€§è¯„ä¼°
        robustness_results = evaluator.evaluate_robustness(args.robustness_tests)
        
        # åŠ¨ä½œåˆ†æ
        action_analysis = evaluator.analyze_actions(num_episodes=5)
        
        # æ±‡æ€»ç»“æœ
        full_results = {
            'model_info': evaluator.model_info,
            'basic_performance': basic_results,
            'robustness': robustness_results,
            'action_analysis': action_analysis,
            'evaluation_config': {
                'episodes': args.episodes,
                'goal_threshold': args.goal_threshold,
                'robustness_tests': args.robustness_tests
            }
        }
        
        # æ‰“å°æ€»ç»“
        evaluator.print_summary(basic_results)
        
        # ä¿å­˜ç»“æœ
        output_file = evaluator.save_results(full_results, args.output_dir)
        
        print(f"\nğŸ“‹ è¯¦ç»†åˆ†æ:")
        print(f"   é²æ£’æ€§æµ‹è¯•æˆåŠŸç‡: {sum(1 for r in robustness_results if r['success']) / len(robustness_results):.1%}")
        print(f"   åŠ¨ä½œèŒƒå›´åˆ†æ: joint1: {action_analysis['action_ranges'][0]:.2f}, joint2: {action_analysis['action_ranges'][1]:.2f}")
        print(f"   è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ¸…ç†
        evaluator.close()
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise e


if __name__ == "__main__":
    main() 