#!/usr/bin/env python3
"""
æŸå¤±è®°å½•å™¨æ¥å£ - ç®€åŒ–ç‰ˆ
ç”¨äºåœ¨MAP-Elitesè®­ç»ƒä»£ç ä¸­å¿«é€Ÿé›†æˆç½‘ç»œæŸå¤±è®°å½•åŠŸèƒ½
"""

import os
import sys
import time
from network_loss_logger import init_network_loss_logger, log_network_loss, cleanup_network_loss_logger, get_network_loss_logger

class LossLoggerInterface:
    """æŸå¤±è®°å½•å™¨æ¥å£ - ç®€åŒ–ä½¿ç”¨"""
    
    _instance = None
    
    def __init__(self, experiment_name=None, log_dir="network_loss_logs", 
                 networks=['attention', 'ppo', 'gnn'], update_interval=10.0, auto_start=True):
        """
        åˆå§‹åŒ–æŸå¤±è®°å½•å™¨æ¥å£ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
        
        Args:
            experiment_name: å®éªŒåç§°
            log_dir: æ—¥å¿—ç›®å½•
            networks: ç›‘æ§çš„ç½‘ç»œåˆ—è¡¨
            update_interval: å›¾è¡¨æ›´æ–°é—´éš”
            auto_start: æ˜¯å¦è‡ªåŠ¨å¯åŠ¨
        """
        if LossLoggerInterface._instance is not None:
            print("âš ï¸  LossLoggerInterfaceå·²åˆå§‹åŒ–ï¼Œä½¿ç”¨ç°æœ‰å®ä¾‹")
            # å¤åˆ¶ç°æœ‰å®ä¾‹çš„å±æ€§
            existing = LossLoggerInterface._instance
            self.logger = existing.logger
            self.experiment_name = existing.experiment_name
            self.log_dir = existing.log_dir
            self.networks = existing.networks
            self.update_interval = existing.update_interval
            return
            
        LossLoggerInterface._instance = self
        
        self.logger = None
        self.experiment_name = experiment_name
        self.log_dir = log_dir
        self.networks = networks
        self.update_interval = update_interval
        
        if auto_start:
            self.start()
        
        print(f"ğŸ¯ LossLoggerInterfaceå·²åˆå§‹åŒ–")
    
    def start(self):
        """å¯åŠ¨æŸå¤±è®°å½•å™¨"""
        if self.logger is not None:
            print("âš ï¸  æŸå¤±è®°å½•å™¨å·²å¯åŠ¨")
            return
            
        self.logger = init_network_loss_logger(
            experiment_name=self.experiment_name,
            log_dir=self.log_dir,
            networks=self.networks,
            update_interval=self.update_interval
        )
        
        print(f"âœ… æŸå¤±è®°å½•å™¨å·²å¯åŠ¨ - å®éªŒ: {self.logger.experiment_name}")
        return self.logger
    
    def stop(self):
        """åœæ­¢æŸå¤±è®°å½•å™¨"""
        if self.logger is not None:
            cleanup_network_loss_logger()
            self.logger = None
            print("ğŸ›‘ æŸå¤±è®°å½•å™¨å·²åœæ­¢")
    
    @classmethod
    def get_instance(cls, **kwargs):
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            cls._instance = cls(**kwargs)
        return cls._instance
    
    def log_attention_loss(self, step, attention_loss_dict, timestamp=None):
        """è®°å½•attentionç½‘ç»œæŸå¤±"""
        log_network_loss('attention', step, attention_loss_dict, timestamp)
    
    def log_ppo_loss(self, step, ppo_loss_dict, timestamp=None):
        """è®°å½•PPOç½‘ç»œæŸå¤±"""
        log_network_loss('ppo', step, ppo_loss_dict, timestamp)
    
    def log_gnn_loss(self, step, gnn_loss_dict, timestamp=None):
        """è®°å½•GNNç½‘ç»œæŸå¤±"""
        log_network_loss('gnn', step, gnn_loss_dict, timestamp)
    
    def log_custom_loss(self, network_name, step, loss_dict, timestamp=None):
        """è®°å½•è‡ªå®šä¹‰ç½‘ç»œæŸå¤±"""
        log_network_loss(network_name, step, loss_dict, timestamp)
    
    def get_log_dir(self):
        """è·å–æ—¥å¿—ç›®å½•"""
        if self.logger:
            return self.logger.experiment_dir
        return None
    
    def is_alive(self):
        """æ£€æŸ¥è®°å½•å™¨æ˜¯å¦è¿˜åœ¨è¿è¡Œ"""
        if self.logger:
            return self.logger.is_alive()
        return False


# ä¾¿æ·å‡½æ•° - å…¨å±€æ¥å£
def start_loss_logging(experiment_name=None, **kwargs):
    """å¯åŠ¨æŸå¤±è®°å½•çš„ä¾¿æ·å‡½æ•°"""
    interface = LossLoggerInterface.get_instance(experiment_name=experiment_name, **kwargs)
    return interface

def stop_loss_logging():
    """åœæ­¢æŸå¤±è®°å½•çš„ä¾¿æ·å‡½æ•°"""
    interface = LossLoggerInterface.get_instance(auto_start=False)
    interface.stop()

def log_attention_loss(step, loss_dict, timestamp=None):
    """è®°å½•attentionæŸå¤±çš„ä¾¿æ·å‡½æ•°"""
    log_network_loss('attention', step, loss_dict, timestamp)

def log_ppo_loss(step, loss_dict, timestamp=None):
    """è®°å½•PPOæŸå¤±çš„ä¾¿æ·å‡½æ•°"""
    log_network_loss('ppo', step, loss_dict, timestamp)

def log_gnn_loss(step, loss_dict, timestamp=None):
    """è®°å½•GNNæŸå¤±çš„ä¾¿æ·å‡½æ•°"""
    log_network_loss('gnn', step, loss_dict, timestamp)

def log_custom_network_loss(network_name, step, loss_dict, timestamp=None):
    """è®°å½•è‡ªå®šä¹‰ç½‘ç»œæŸå¤±çš„ä¾¿æ·å‡½æ•°"""
    log_network_loss(network_name, step, loss_dict, timestamp)

def get_loss_log_directory():
    """è·å–æŸå¤±æ—¥å¿—ç›®å½•çš„ä¾¿æ·å‡½æ•°"""
    interface = LossLoggerInterface.get_instance(auto_start=False)
    return interface.get_log_dir()

def is_loss_logger_alive():
    """æ£€æŸ¥æŸå¤±è®°å½•å™¨æ˜¯å¦è¿˜åœ¨è¿è¡Œ"""
    interface = LossLoggerInterface.get_instance(auto_start=False)
    return interface.is_alive()


# è£…é¥°å™¨ - è‡ªåŠ¨è®°å½•å‡½æ•°çš„æŸå¤±
def auto_log_loss(network_name, step_param='step'):
    """
    è£…é¥°å™¨ï¼šè‡ªåŠ¨è®°å½•å‡½æ•°è¿”å›çš„æŸå¤±å€¼
    
    Args:
        network_name: ç½‘ç»œåç§°
        step_param: æ­¥æ•°å‚æ•°å
    
    Usage:
        @auto_log_loss('ppo', 'training_step')
        def train_ppo(training_step, ...):
            # è®­ç»ƒé€»è¾‘
            return {'actor_loss': 0.5, 'critic_loss': 0.3}
    """
    def decorator(func):
        def wrapper(*args, **kwargs):
            result = func(*args, **kwargs)
            
            # å°è¯•è·å–æ­¥æ•°
            step = None
            if step_param in kwargs:
                step = kwargs[step_param]
            else:
                # å°è¯•ä»ä½ç½®å‚æ•°è·å–ï¼ˆå‡è®¾æ˜¯ç¬¬ä¸€ä¸ªå‚æ•°ï¼‰
                if args:
                    step = args[0]
            
            # å¦‚æœè¿”å›å€¼æ˜¯å­—å…¸ï¼Œè®°å½•ä¸ºæŸå¤±
            if isinstance(result, dict) and step is not None:
                log_network_loss(network_name, step, result)
            
            return result
        return wrapper
    return decorator


# ä¸Šä¸‹æ–‡ç®¡ç†å™¨
class LossLoggingContext:
    """æŸå¤±è®°å½•ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, experiment_name=None, **kwargs):
        self.experiment_name = experiment_name
        self.kwargs = kwargs
        self.interface = None
    
    def __enter__(self):
        self.interface = start_loss_logging(self.experiment_name, **self.kwargs)
        return self.interface
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        stop_loss_logging()


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•æŸå¤±è®°å½•å™¨æ¥å£")
    
    # æ–¹æ³•1: ç›´æ¥ä½¿ç”¨ä¾¿æ·å‡½æ•°
    print("\n=== æ–¹æ³•1: ä¾¿æ·å‡½æ•° ===")
    logger_interface = start_loss_logging(
        experiment_name="test_interface",
        networks=['attention', 'ppo', 'gnn', 'custom']
    )
    
    for step in range(50):
        log_attention_loss(step, {'attention_loss': 2.0 - step*0.01})
        log_ppo_loss(step, {'actor_loss': 1.5 - step*0.008, 'critic_loss': 1.2 - step*0.006})
        log_gnn_loss(step, {'gnn_loss': 2.5 - step*0.012})
        log_custom_network_loss('custom', step, {'custom_loss': 1.0 - step*0.005})
        
        if step % 10 == 0:
            print(f"Step {step} - æ—¥å¿—ç›®å½•: {get_loss_log_directory()}")
        
        time.sleep(0.05)
    
    stop_loss_logging()
    
    # æ–¹æ³•2: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    print("\n=== æ–¹æ³•2: ä¸Šä¸‹æ–‡ç®¡ç†å™¨ ===")
    with LossLoggingContext(experiment_name="test_context") as logger:
        for step in range(30):
            log_attention_loss(step, {'attention_loss': 1.8 - step*0.01})
            if step % 10 == 0:
                print(f"Context Step {step}")
            time.sleep(0.05)
    
    # æ–¹æ³•3: ä½¿ç”¨è£…é¥°å™¨
    print("\n=== æ–¹æ³•3: è£…é¥°å™¨ ===")
    start_loss_logging(experiment_name="test_decorator")
    
    @auto_log_loss('ppo')
    def mock_ppo_training(step):
        # æ¨¡æ‹ŸPPOè®­ç»ƒ
        return {
            'actor_loss': max(0.01, 1.5 - step*0.01),
            'critic_loss': max(0.01, 1.2 - step*0.008)
        }
    
    for step in range(20):
        mock_ppo_training(step)
        if step % 5 == 0:
            print(f"Decorator Step {step}")
        time.sleep(0.05)
    
    stop_loss_logging()
    
    print("âœ… æµ‹è¯•å®Œæˆ")
