#!/usr/bin/env python3
"""
æµ‹è¯•å¸¦è·¯æ ‡ç‚¹çš„è®­ç»ƒå¯è§†åŒ–
"""

import sys
import os
base_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../')
sys.path.append(base_dir)

sys.path.insert(0, os.path.join(base_dir, 'examples/2d_reacher/envs'))
sys.path.insert(0, os.path.join(base_dir, 'examples/surrogate_model'))

from reacher2d_env import Reacher2DEnv
from waypoint_navigator import WaypointNavigator
import numpy as np
import time
import torch

def test_waypoint_training_visualization():
    """æµ‹è¯•å¸¦è·¯æ ‡ç‚¹çš„è®­ç»ƒå¯è§†åŒ–"""
    
    print("ğŸ® æµ‹è¯•å¸¦è·¯æ ‡ç‚¹çš„è®­ç»ƒå¯è§†åŒ–")
    print("="*50)
    
    # åˆ›å»ºç¯å¢ƒ
    env_params = {
        'num_links': 4,
        'link_lengths': [80, 80, 80, 60],
        'render_mode': 'human',  # å¼€å¯æ¸²æŸ“
        'config_path': '/home/xli149/Documents/repos/test_robo/examples/2d_reacher/configs/reacher_with_zigzag_obstacles.yaml',
        'debug_level': 'SILENT'
    }
    
    env = Reacher2DEnv(**env_params)
    
    # æ·»åŠ è·¯æ ‡ç‚¹ç³»ç»Ÿ
    start_pos = env.anchor_point
    goal_pos = env.goal_pos
    env.waypoint_navigator = WaypointNavigator(start_pos, goal_pos)
    
    print(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ")
    print(f"   èµ·ç‚¹: {start_pos}")
    print(f"   ç»ˆç‚¹: {goal_pos}")
    print(f"   è·¯æ ‡æ•°: {len(env.waypoint_navigator.waypoints)}")
    print(f"   æœºå™¨äººå…³èŠ‚æ•°: {env.action_space.shape[0]}")
    
    print(f"\nğŸ—ºï¸ è·¯æ ‡ç‚¹åˆ—è¡¨:")
    for i, wp in enumerate(env.waypoint_navigator.waypoints):
        print(f"   è·¯æ ‡{i}: {wp.position} (å¥–åŠ±: {wp.reward})")
    
    print(f"\nğŸ¯ å¼€å§‹æµ‹è¯•...")
    print(f"åº”è¯¥èƒ½çœ‹åˆ°:")
    print(f"   ğŸŸ¡ é»„è‰²é—ªçƒåœ†åœˆ = å½“å‰ç›®æ ‡è·¯æ ‡ç‚¹")
    print(f"   ğŸ”µ è“è‰²åœ†åœˆ = æœªè®¿é—®è·¯æ ‡ç‚¹")
    print(f"   ğŸŸ¢ ç»¿è‰²åœ†åœˆ = å·²è®¿é—®è·¯æ ‡ç‚¹")
    print(f"   ğŸ“Š å·¦ä¸Šè§’é¢æ¿ = å¯¼èˆªè¿›åº¦ä¿¡æ¯")
    print(f"   ğŸ›¤ï¸ å½©è‰²è·¯å¾„çº¿ = å®ŒæˆçŠ¶æ€è·¯å¾„")
    
    # æµ‹è¯•è·¯æ ‡ç‚¹ç³»ç»Ÿçš„å¥–åŠ±å‡½æ•°
    def compute_waypoint_reward(env, action):
        """è®¡ç®—å¸¦è·¯æ ‡ç‚¹çš„å¥–åŠ±"""
        # æ‰§è¡ŒåŸå§‹ç¯å¢ƒstep
        obs, base_reward, done, info = env.step(action)
        
        # è·å–å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®
        end_pos = np.array(env._get_end_effector_position())
        
        # æ›´æ–°è·¯æ ‡ç‚¹å¯¼èˆªå™¨å¹¶è·å–å¥–åŠ±
        waypoint_reward, waypoint_info = env.waypoint_navigator.update(end_pos)
        
        # ç»„åˆå¥–åŠ±
        total_reward = base_reward + waypoint_reward
        
        # æ›´æ–°info
        info.update(waypoint_info)
        info['base_reward'] = base_reward
        info['waypoint_reward'] = waypoint_reward
        info['total_reward'] = total_reward
        
        return obs, total_reward, done, info
    
    # è¿è¡Œæµ‹è¯•
    obs = env.reset()
    total_episodes = 0
    step_count = 0
    
    for episode in range(3):  # æµ‹è¯•3ä¸ªepisode
        print(f"\nğŸ¬ Episode {episode + 1}/3")
        
        obs = env.reset()
        env.waypoint_navigator.reset()  # é‡ç½®è·¯æ ‡ç‚¹ç³»ç»Ÿ
        
        episode_reward = 0
        episode_waypoint_reward = 0
        
        for step in range(500):  # æ¯ä¸ªepisodeæœ€å¤š500æ­¥
            # æ¸²æŸ“ç¯å¢ƒ
            env.render()
            
            # ç”ŸæˆéšæœºåŠ¨ä½œï¼ˆå®é™…è®­ç»ƒä¸­è¿™é‡Œæ˜¯policyç½‘ç»œï¼‰
            action = env.action_space.sample() * 0.3  # å‡å°åŠ¨ä½œå¹…åº¦
            
            # æ‰§è¡ŒåŠ¨ä½œå¹¶è·å¾—è·¯æ ‡ç‚¹å¥–åŠ±
            obs, reward, done, info = compute_waypoint_reward(env, action)
            
            episode_reward += info['total_reward']
            episode_waypoint_reward += info.get('waypoint_reward', 0)
            step_count += 1
            
            # æ¯10æ­¥è¾“å‡ºä¸€æ¬¡ä¿¡æ¯
            if step % 10 == 0:
                end_pos = env._get_end_effector_position()
                current_target = env.waypoint_navigator.get_current_target()
                distance = np.linalg.norm(np.array(end_pos) - current_target)
                
                print(f"  æ­¥éª¤ {step}: è·ç¦»ç›®æ ‡ {distance:.1f}px, "
                      f"è·¯æ ‡å¥–åŠ± {info.get('waypoint_reward', 0):+.2f}, "
                      f"è¿›åº¦ {info.get('completion_progress', 0)*100:.1f}%")
            
            # æ£€æŸ¥è·¯æ ‡ç‚¹å®Œæˆ
            if info.get('waypoint_reached', False):
                print(f"    ğŸ¯ åˆ°è¾¾è·¯æ ‡ç‚¹! è·å¾—å¥–åŠ±: +{info.get('waypoint_reward', 0)}")
            
            # æ£€æŸ¥episodeç»“æŸ
            if done or info.get('completion_progress', 0) >= 1.0:
                print(f"  ğŸ Episodeç»“æŸ: æ€»æ­¥æ•° {step+1}")
                print(f"     æ€»å¥–åŠ±: {episode_reward:.2f}")
                print(f"     è·¯æ ‡å¥–åŠ±: {episode_waypoint_reward:.2f}")
                print(f"     å®Œæˆè¿›åº¦: {info.get('completion_progress', 0)*100:.1f}%")
                break
            
            # æ§åˆ¶å¸§ç‡
            time.sleep(0.02)
        
        total_episodes += 1
    
    print(f"\nğŸ† æµ‹è¯•å®Œæˆ!")
    print(f"   æ€»episodes: {total_episodes}")
    print(f"   æ€»æ­¥æ•°: {step_count}")
    print(f"   è·¯æ ‡ç‚¹ç³»ç»Ÿæ­£å¸¸å·¥ä½œï¼")
    
    # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ç”¨æˆ·è§‚å¯Ÿ
    print(f"\nâ±ï¸ ä¿æŒæ¸²æŸ“5ç§’...")
    for i in range(5):
        env.render()
        time.sleep(1)
        print(f"   {5-i}ç§’åå…³é—­...")
    
    env.close()

if __name__ == "__main__":
    test_waypoint_training_visualization()
