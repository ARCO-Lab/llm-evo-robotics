#!/usr/bin/env python3
"""
è®­ç»ƒæŸå¤±è®°å½•å’Œç›‘æ§ç³»ç»Ÿ
åŠŸèƒ½ï¼š
- å®æ—¶è®°å½•å„ç½‘ç»œçš„è®­ç»ƒæŸå¤±
- ç”ŸæˆæŸå¤±æ›²çº¿å›¾è¡¨
- æä¾›æŸå¤±ç»Ÿè®¡åˆ†æ
- æ”¯æŒå¤šç§ä¿å­˜æ ¼å¼(CSV, JSON, PNG)
- æ”¯æŒå®æ—¶ç›‘æ§å’Œé¢„è­¦
"""

import os
import json
import csv
import time
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from collections import defaultdict, deque
from datetime import datetime
import pickle


class TrainingLogger:
    """è®­ç»ƒæŸå¤±è®°å½•å™¨"""
    
    def __init__(self, log_dir="training_logs", experiment_name=None):
        self.log_dir = log_dir
        self.experiment_name = experiment_name or f"experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.experiment_dir = os.path.join(log_dir, self.experiment_name)
        
        # åˆ›å»ºç›®å½•
        os.makedirs(self.experiment_dir, exist_ok=True)
        
        # æŸå¤±å†å²è®°å½•
        self.loss_history = defaultdict(list)
        self.step_history = []
        self.time_history = []
        self.episode_history = []
        
        # å®æ—¶ç»Ÿè®¡
        self.recent_losses = defaultdict(list)  # ğŸ”§ ä¿®å¤: æ”¹ä¸ºæ™®é€šlistï¼Œæ‰‹åŠ¨ç®¡ç†æœ€å¤§é•¿åº¦
        self.max_recent_size = 100  # ğŸ”§ æ·»åŠ : æœ€å¤§ä¿ç•™æ•°é‡
        self.start_time = time.time()
        
        # é…ç½®ä¿¡æ¯
        self.config = {
            'experiment_name': self.experiment_name,
            'start_time': datetime.now().isoformat(),
            'log_dir': self.experiment_dir
        }
        
        print(f"ğŸ“Š TrainingLogger åˆå§‹åŒ–å®Œæˆ")
        print(f"   å®éªŒåç§°: {self.experiment_name}")
        print(f"   æ—¥å¿—ç›®å½•: {self.experiment_dir}")
        
        # ä¿å­˜é…ç½®
        self.save_config()
    
    def log_step(self, step, metrics, episode=None):
        """è®°å½•ä¸€ä¸ªè®­ç»ƒæ­¥éª¤çš„æŸå¤±"""
        current_time = time.time() - self.start_time
        
        # è®°å½•åŸºæœ¬ä¿¡æ¯
        self.step_history.append(step)
        self.time_history.append(current_time)
        if episode is not None:
            self.episode_history.append(episode)
        
        # è®°å½•æ‰€æœ‰æŒ‡æ ‡
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                self.loss_history[key].append(float(value))
                self.recent_losses[key].append(float(value))
                
                # ğŸ”§ æ‰‹åŠ¨ç®¡ç†recent_losseså¤§å°
                if len(self.recent_losses[key]) > self.max_recent_size:
                    self.recent_losses[key] = self.recent_losses[key][-self.max_recent_size:]
        
        # å®šæœŸä¿å­˜
        if step % 100 == 0:
            self.save_logs()
    
    def log_episode(self, episode, episode_metrics):
        """è®°å½•episodeçº§åˆ«çš„æŒ‡æ ‡"""
        for key, value in episode_metrics.items():
            episode_key = f"episode_{key}"
            if isinstance(value, (int, float)):
                self.loss_history[episode_key].append(float(value))
    
    def get_recent_stats(self, metric_name, window=50):
        """è·å–æœ€è¿‘æŒ‡æ ‡çš„ç»Ÿè®¡ä¿¡æ¯"""
        if metric_name not in self.recent_losses:
            return None
        
        recent_values = list(self.recent_losses[metric_name])[-window:]
        if not recent_values:
            return None
        
        return {
            'mean': np.mean(recent_values),
            'std': np.std(recent_values),
            'min': np.min(recent_values),
            'max': np.max(recent_values),
            'count': len(recent_values),
            'trend': self._calculate_trend(recent_values)
        }
    
    def _calculate_trend(self, values, window=20):
        """è®¡ç®—è¶‹åŠ¿ï¼ˆä¸Šå‡/ä¸‹é™/ç¨³å®šï¼‰"""
        if len(values) < window:
            return 'insufficient_data'
        
        recent = values[-window:]
        earlier = values[-2*window:-window] if len(values) >= 2*window else values[:-window]
        
        if len(earlier) == 0:
            return 'insufficient_data'
        
        recent_mean = np.mean(recent)
        earlier_mean = np.mean(earlier)
        
        diff_ratio = (recent_mean - earlier_mean) / abs(earlier_mean) if earlier_mean != 0 else 0
        
        if diff_ratio > 0.05:
            return 'increasing'
        elif diff_ratio < -0.05:
            return 'decreasing'
        else:
            return 'stable'
    
    def print_current_stats(self, step, detailed=False):
        """æ‰“å°å½“å‰çš„ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š Step {step} è®­ç»ƒç»Ÿè®¡ (å®éªŒ: {self.experiment_name})")
        print(f"   è¿è¡Œæ—¶é—´: {self.time_history[-1]/3600:.2f} å°æ—¶")
        
        # ä¸»è¦æŸå¤±æŒ‡æ ‡
        main_metrics = ['critic_loss', 'actor_loss', 'alpha_loss', 'alpha']
        for metric in main_metrics:
            stats = self.get_recent_stats(metric)
            if stats:
                trend_emoji = {'increasing': 'ğŸ“ˆ', 'decreasing': 'ğŸ“‰', 'stable': 'â¡ï¸'}.get(stats['trend'], 'â“')
                print(f"   {metric:12}: {stats['mean']:8.4f} Â± {stats['std']:6.4f} {trend_emoji}")
        
        if detailed:
            # è¯¦ç»†æŒ‡æ ‡
            other_metrics = [k for k in self.loss_history.keys() if k not in main_metrics]
            if other_metrics:
                print(f"   è¯¦ç»†æŒ‡æ ‡:")
                for metric in other_metrics:
                    stats = self.get_recent_stats(metric)
                    if stats:
                        print(f"     {metric:15}: {stats['mean']:8.4f} Â± {stats['std']:6.4f}")
    
    def plot_losses(self, save_path=None, show=True, recent_steps=None):
        """ç»˜åˆ¶æŸå¤±æ›²çº¿"""
        if not self.step_history:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ä»¥ç»˜åˆ¶")
            return
        
        # ç¡®å®šè¦æ˜¾ç¤ºçš„æ­¥æ•°èŒƒå›´
        if recent_steps:
            start_idx = max(0, len(self.step_history) - recent_steps)
            steps = self.step_history[start_idx:]
            plot_data = {k: v[start_idx:] for k, v in self.loss_history.items()}
        else:
            steps = self.step_history
            plot_data = self.loss_history
        
        # åˆ†ç»„ç»˜åˆ¶
        loss_groups = {
            'SAC Losses': ['critic_loss', 'actor_loss', 'alpha_loss'],
            'Q Values': ['q1_mean', 'q2_mean'],
            'Policy Metrics': ['alpha', 'entropy_term', 'q_term'],
            'Episode Metrics': [k for k in plot_data.keys() if k.startswith('episode_')]
        }
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']
        
        for idx, (group_name, metrics) in enumerate(loss_groups.items()):
            if idx >= len(axes):
                break
                
            ax = axes[idx]
            plotted_any = False
            
            for i, metric in enumerate(metrics):
                if metric in plot_data and len(plot_data[metric]) > 0:
                    ax.plot(steps, plot_data[metric], 
                           label=metric, color=colors[i % len(colors)], linewidth=1.5)
                    plotted_any = True
            
            if plotted_any:
                ax.set_title(group_name, fontsize=12, fontweight='bold')
                ax.set_xlabel('Training Step')
                ax.set_ylabel('Value')
                ax.legend(fontsize=8)
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ è¶‹åŠ¿çº¿ï¼ˆå¯¹ä¸»è¦æŸå¤±ï¼‰
                if group_name == 'SAC Losses':
                    for metric in ['critic_loss', 'actor_loss']:
                        if metric in plot_data and len(plot_data[metric]) > 10:
                            # ç®€å•ç§»åŠ¨å¹³å‡
                            values = plot_data[metric]
                            window = min(50, len(values) // 10)
                            if window > 1:
                                smooth = np.convolve(values, np.ones(window)/window, mode='valid')
                                smooth_steps = steps[window-1:]
                                ax.plot(smooth_steps, smooth, '--', alpha=0.7, linewidth=2)
            else:
                ax.text(0.5, 0.5, f'No data for\n{group_name}', 
                       ha='center', va='center', transform=ax.transAxes)
                ax.set_title(group_name)
        
        plt.suptitle(f'Training Progress - {self.experiment_name}', fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        if save_path is None:
            save_path = os.path.join(self.experiment_dir, f'training_curves_step_{steps[-1]}.png')
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ˆ æŸå¤±æ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
        
        if show:
            plt.show()
        else:
            plt.close()
        
        return save_path
    
    def save_logs(self):
        """ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶"""
        # ä¿å­˜ä¸ºCSV
        csv_path = os.path.join(self.experiment_dir, 'training_log.csv')
        with open(csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            
            # å†™å…¥è¡¨å¤´
            headers = ['step', 'time'] + list(self.loss_history.keys())
            if self.episode_history:
                headers.insert(2, 'episode')
            writer.writerow(headers)
            
            # å†™å…¥æ•°æ®
            for i, step in enumerate(self.step_history):
                row = [step, self.time_history[i]]
                if self.episode_history and i < len(self.episode_history):
                    row.append(self.episode_history[i])
                elif self.episode_history:
                    row.append('')
                
                for metric in self.loss_history.keys():
                    if i < len(self.loss_history[metric]):
                        row.append(self.loss_history[metric][i])
                    else:
                        row.append('')
                writer.writerow(row)
        
        # ä¿å­˜ä¸ºJSON
        json_path = os.path.join(self.experiment_dir, 'training_log.json')
        log_data = {
            'config': self.config,
            'steps': self.step_history,
            'times': self.time_history,
            'episodes': self.episode_history,
            'metrics': dict(self.loss_history)
        }
        with open(json_path, 'w') as f:
            json.dump(log_data, f, indent=2)
        
        # ä¿å­˜ä¸ºPickleï¼ˆå®Œæ•´å¯¹è±¡ï¼‰
        pickle_path = os.path.join(self.experiment_dir, 'training_logger.pkl')
        with open(pickle_path, 'wb') as f:
            pickle.dump(self, f)
    
    def save_config(self):
        """ä¿å­˜é…ç½®ä¿¡æ¯"""
        config_path = os.path.join(self.experiment_dir, 'config.json')
        with open(config_path, 'w') as f:
            json.dump(self.config, f, indent=2)
    
    def generate_report(self):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        if not self.step_history:
            print("âŒ æ²¡æœ‰æ•°æ®ç”ŸæˆæŠ¥å‘Š")
            return
        
        report_path = os.path.join(self.experiment_dir, 'training_report.txt')
        
        with open(report_path, 'w') as f:
            f.write(f"Training Report - {self.experiment_name}\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"å®éªŒé…ç½®:\n")
            f.write(f"  å¼€å§‹æ—¶é—´: {self.config['start_time']}\n")
            f.write(f"  æ€»è®­ç»ƒæ­¥æ•°: {self.step_history[-1]}\n")
            f.write(f"  æ€»è®­ç»ƒæ—¶é—´: {self.time_history[-1]/3600:.2f} å°æ—¶\n")
            f.write(f"  å¹³å‡æ­¥æ•°/ç§’: {self.step_history[-1]/self.time_history[-1]:.2f}\n\n")
            
            f.write("æŸå¤±ç»Ÿè®¡:\n")
            for metric_name in ['critic_loss', 'actor_loss', 'alpha_loss', 'alpha']:
                if metric_name in self.loss_history:
                    values = self.loss_history[metric_name]
                    f.write(f"  {metric_name}:\n")
                    f.write(f"    æœ€ç»ˆå€¼: {values[-1]:.6f}\n")
                    f.write(f"    å¹³å‡å€¼: {np.mean(values):.6f}\n")
                    f.write(f"    æ ‡å‡†å·®: {np.std(values):.6f}\n")
                    f.write(f"    æœ€å°å€¼: {np.min(values):.6f}\n")
                    f.write(f"    æœ€å¤§å€¼: {np.max(values):.6f}\n\n")
        
        print(f"ğŸ“‹ è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        return report_path
    
    @classmethod
    def load_logger(cls, experiment_dir):
        """ä»ä¿å­˜çš„æ–‡ä»¶åŠ è½½logger"""
        pickle_path = os.path.join(experiment_dir, 'training_logger.pkl')
        if os.path.exists(pickle_path):
            with open(pickle_path, 'rb') as f:
                return pickle.load(f)
        else:
            print(f"âŒ æœªæ‰¾åˆ°ä¿å­˜çš„logger: {pickle_path}")
            return None


class RealTimeMonitor:
    """å®æ—¶ç›‘æ§ç±»"""
    
    def __init__(self, logger, alert_thresholds=None):
        self.logger = logger
        self.alert_thresholds = alert_thresholds or {
            'critic_loss': {'max': 10.0, 'nan_check': True},
            'actor_loss': {'max': 5.0, 'nan_check': True},
            'alpha_loss': {'max': 2.0, 'nan_check': True},
        }
        self.alert_history = []
    
    def check_alerts(self, step, metrics):
        """æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸æƒ…å†µéœ€è¦è­¦æŠ¥"""
        alerts = []
        
        for metric_name, thresholds in self.alert_thresholds.items():
            if metric_name in metrics:
                value = metrics[metric_name]
                
                # æ£€æŸ¥NaN
                if thresholds.get('nan_check', False) and (np.isnan(value) or np.isinf(value)):
                    alerts.append(f"âš ï¸ {metric_name} å‡ºç° NaN/Inf: {value}")
                
                # æ£€æŸ¥è¶…å‡ºé˜ˆå€¼
                if 'max' in thresholds and value > thresholds['max']:
                    alerts.append(f"âš ï¸ {metric_name} è¶…å‡ºæœ€å¤§é˜ˆå€¼: {value:.4f} > {thresholds['max']}")
                
                if 'min' in thresholds and value < thresholds['min']:
                    alerts.append(f"âš ï¸ {metric_name} ä½äºæœ€å°é˜ˆå€¼: {value:.4f} < {thresholds['min']}")
        
        # æ£€æŸ¥è¶‹åŠ¿å¼‚å¸¸
        for metric_name in ['critic_loss', 'actor_loss']:
            stats = self.logger.get_recent_stats(metric_name, window=50)
            if stats and stats['trend'] == 'increasing' and stats['mean'] > 1.0:
                alerts.append(f"ğŸ“ˆ {metric_name} æŒç»­ä¸Šå‡è¶‹åŠ¿ï¼Œå½“å‰å‡å€¼: {stats['mean']:.4f}")
        
        # è®°å½•å’Œæ˜¾ç¤ºè­¦æŠ¥
        if alerts:
            self.alert_history.extend([(step, alert) for alert in alerts])
            print(f"\nğŸš¨ Step {step} ç›‘æ§è­¦æŠ¥:")
            for alert in alerts:
                print(f"   {alert}")
        
        return alerts


# ç¤ºä¾‹ç”¨æ³•å‡½æ•°
def demo_usage():
    """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨TrainingLogger"""
    
    # åˆ›å»ºlogger
    logger = TrainingLogger(experiment_name="sac_reacher2d_demo")
    monitor = RealTimeMonitor(logger)
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    print("ğŸš€ å¼€å§‹æ¨¡æ‹Ÿè®­ç»ƒ...")
    
    for step in range(1000):
        # æ¨¡æ‹ŸæŸå¤±å€¼
        metrics = {
            'critic_loss': 1.0 + 0.5 * np.exp(-step/200) + np.random.normal(0, 0.1),
            'actor_loss': 0.5 + 0.3 * np.exp(-step/300) + np.random.normal(0, 0.05),
            'alpha_loss': 0.2 + np.random.normal(0, 0.02),
            'alpha': 0.2 + 0.1 * np.sin(step/100),
            'q1_mean': 2.0 + np.random.normal(0, 0.2),
            'q2_mean': 2.1 + np.random.normal(0, 0.2),
            'buffer_size': min(10000, step * 10)
        }
        
        # è®°å½•
        episode = step // 50  # å‡è®¾æ¯50æ­¥ä¸€ä¸ªepisode
        logger.log_step(step, metrics, episode)
        
        # ç›‘æ§
        alerts = monitor.check_alerts(step, metrics)
        
        # å®šæœŸæ‰“å°ç»Ÿè®¡
        if step % 200 == 0 and step > 0:
            logger.print_current_stats(step, detailed=True)
        
        # å®šæœŸä¿å­˜å’Œç»˜å›¾
        if step % 500 == 0 and step > 0:
            logger.plot_losses(recent_steps=500, show=False)
    
    # æœ€ç»ˆæŠ¥å‘Š
    logger.generate_report()
    logger.plot_losses(show=False)
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼ŒæŸ¥çœ‹ç»“æœ: {logger.experiment_dir}")


if __name__ == "__main__":
    demo_usage() 