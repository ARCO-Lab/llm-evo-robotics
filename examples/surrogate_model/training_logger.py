#!/usr/bin/env python3
"""
è®­ç»ƒæŸå¤±è®°å½•å’Œç›‘æ§ç³»ç»Ÿ
åŠŸèƒ½ï¼š
- å®æ—¶è®°å½•å„ç½‘ç»œçš„è®­ç»ƒæŸå¤±
- ç”ŸæˆæŸå¤±æ›²çº¿å›¾è¡¨
- æä¾›æŸå¤±ç»Ÿè®¡åˆ†æ
- æ”¯æŒå¤šç§ä¿å­˜æ ¼å¼(CSV, JSON, PNG)
- æ”¯æŒå®æ—¶ç›‘æ§å’Œé¢„è­¦
"""

import os
import json
import csv
import time
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from collections import defaultdict, deque
from datetime import datetime
import pickle
import sys # Added for sys.version_info


class TrainingLogger:
    """è®­ç»ƒæŸå¤±è®°å½•å™¨"""
    
    def __init__(self, log_dir="training_logs", experiment_name=None, hyperparams=None, env_config=None):
        self.log_dir = log_dir
        self.experiment_name = experiment_name or f"experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.experiment_dir = os.path.join(log_dir, self.experiment_name)
        
        # åˆ›å»ºç›®å½•
        os.makedirs(self.experiment_dir, exist_ok=True)
        
        # æŸå¤±å†å²è®°å½•
        self.loss_history = defaultdict(list)
        self.step_history = []
        self.time_history = []
        self.episode_history = []
        
        # å®æ—¶ç»Ÿè®¡
        self.recent_losses = defaultdict(list)
        self.max_recent_size = 100
        self.start_time = time.time()
        
        # ğŸš€ NEW: å¢å¼ºçš„é…ç½®ä¿¡æ¯
        self.config = {
            'experiment_info': {
                'experiment_name': self.experiment_name,
                'start_time': datetime.now().isoformat(),
                'log_dir': self.experiment_dir,
                'python_version': f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                'platform': os.name
            },
            'hyperparams': hyperparams or {},
            'env_config': env_config or {},
            'training_metrics': {
                'total_steps': 0,
                'total_episodes': 0,
                'training_time_hours': 0,
                'avg_steps_per_second': 0
            }
        }
        
        print(f"ğŸ“Š TrainingLogger åˆå§‹åŒ–å®Œæˆ")
        print(f"   å®éªŒåç§°: {self.experiment_name}")
        print(f"   æ—¥å¿—ç›®å½•: {self.experiment_dir}")
        
        # ä¿å­˜é…ç½®
        self.save_config()
    
    def update_hyperparams(self, hyperparams):
        """æ›´æ–°è¶…å‚æ•°ä¿¡æ¯"""
        self.config['hyperparams'].update(hyperparams)
        self.save_config()
    
    def update_env_config(self, env_config):
        """æ›´æ–°ç¯å¢ƒé…ç½®ä¿¡æ¯"""
        self.config['env_config'].update(env_config)
        self.save_config()
    
    def update_training_metrics(self, metrics):
        """æ›´æ–°è®­ç»ƒæŒ‡æ ‡"""
        self.config['training_metrics'].update(metrics)
        self.save_config()
    
    def log_step(self, step, metrics, episode=None):
        """è®°å½•ä¸€ä¸ªè®­ç»ƒæ­¥éª¤çš„æŸå¤±"""
        current_time = time.time() - self.start_time
        
        # è®°å½•åŸºæœ¬ä¿¡æ¯
        self.step_history.append(step)
        self.time_history.append(current_time)
        if episode is not None:
            self.episode_history.append(episode)
        
        # è®°å½•æ‰€æœ‰æŒ‡æ ‡
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                self.loss_history[key].append(float(value))
                self.recent_losses[key].append(float(value))
                
                # ğŸ”§ æ‰‹åŠ¨ç®¡ç†recent_losseså¤§å°
                if len(self.recent_losses[key]) > self.max_recent_size:
                    self.recent_losses[key] = self.recent_losses[key][-self.max_recent_size:]
        
        # å®šæœŸä¿å­˜
        if step % 100 == 0:
            self.save_logs()
    
    def log_episode(self, episode, episode_metrics):
        """è®°å½•episodeçº§åˆ«çš„æŒ‡æ ‡"""
        for key, value in episode_metrics.items():
            episode_key = f"episode_{key}"
            if isinstance(value, (int, float)):
                self.loss_history[episode_key].append(float(value))
    
    def get_recent_stats(self, metric_name, window=50):
        """è·å–æœ€è¿‘æŒ‡æ ‡çš„ç»Ÿè®¡ä¿¡æ¯"""
        if metric_name not in self.recent_losses:
            return None
        
        recent_values = list(self.recent_losses[metric_name])[-window:]
        if not recent_values:
            return None
        
        return {
            'mean': np.mean(recent_values),
            'std': np.std(recent_values),
            'min': np.min(recent_values),
            'max': np.max(recent_values),
            'count': len(recent_values),
            'trend': self._calculate_trend(recent_values)
        }
    
    def _calculate_trend(self, values, window=20):
        """è®¡ç®—è¶‹åŠ¿ï¼ˆä¸Šå‡/ä¸‹é™/ç¨³å®šï¼‰"""
        if len(values) < window:
            return 'insufficient_data'
        
        recent = values[-window:]
        earlier = values[-2*window:-window] if len(values) >= 2*window else values[:-window]
        
        if len(earlier) == 0:
            return 'insufficient_data'
        
        recent_mean = np.mean(recent)
        earlier_mean = np.mean(earlier)
        
        diff_ratio = (recent_mean - earlier_mean) / abs(earlier_mean) if earlier_mean != 0 else 0
        
        if diff_ratio > 0.05:
            return 'increasing'
        elif diff_ratio < -0.05:
            return 'decreasing'
        else:
            return 'stable'
    
    def print_current_stats(self, step, detailed=False):
        """æ‰“å°å½“å‰çš„ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š Step {step} è®­ç»ƒç»Ÿè®¡ (å®éªŒ: {self.experiment_name})")
        print(f"   è¿è¡Œæ—¶é—´: {self.time_history[-1]/3600:.2f} å°æ—¶")
        
        # ä¸»è¦æŸå¤±æŒ‡æ ‡
        main_metrics = ['critic_loss', 'actor_loss', 'alpha_loss', 'alpha', 'lr']
        for metric in main_metrics:
            stats = self.get_recent_stats(metric)
            if stats:
                trend_emoji = {'increasing': 'ğŸ“ˆ', 'decreasing': 'ğŸ“‰', 'stable': 'â¡ï¸'}.get(stats['trend'], 'â“')
                print(f"   {metric:12}: {stats['mean']:8.4f} Â± {stats['std']:6.4f} {trend_emoji}")
        
        if detailed:
            # è¯¦ç»†æŒ‡æ ‡
            other_metrics = [k for k in self.loss_history.keys() if k not in main_metrics]
            if other_metrics:
                print(f"   è¯¦ç»†æŒ‡æ ‡:")
                for metric in other_metrics:
                    stats = self.get_recent_stats(metric)
                    if stats:
                        print(f"     {metric:15}: {stats['mean']:8.4f} Â± {stats['std']:6.4f}")
    
    def plot_losses(self, save_path=None, show=True, recent_steps=None):
        """ç»˜åˆ¶æŸå¤±æ›²çº¿"""
        if not self.step_history:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ä»¥ç»˜åˆ¶")
            return
        
        # ç¡®å®šè¦æ˜¾ç¤ºçš„æ­¥æ•°èŒƒå›´
        if recent_steps:
            start_idx = max(0, len(self.step_history) - recent_steps)
            steps = self.step_history[start_idx:]
            plot_data = {k: v[start_idx:] for k, v in self.loss_history.items()}
        else:
            steps = self.step_history
            plot_data = self.loss_history
        
        # åˆ†ç»„ç»˜åˆ¶
        loss_groups = {
            'SAC Losses': ['critic_loss', 'actor_loss', 'alpha_loss'],
            'Q Values': ['q1_mean', 'q2_mean'],
            'Policy Metrics': ['alpha', 'entropy_term', 'q_term'],
            'Episode Metrics': [k for k in plot_data.keys() if k.startswith('episode_')]
        }
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']
        
        for idx, (group_name, metrics) in enumerate(loss_groups.items()):
            if idx >= len(axes):
                break
                
            ax = axes[idx]
            plotted_any = False
            
            for i, metric in enumerate(metrics):
                if metric in plot_data and len(plot_data[metric]) > 0:
                    # ç¡®ä¿stepså’Œdataé•¿åº¦åŒ¹é…
                    data = plot_data[metric]
                    if len(steps) != len(data):
                        # å–è¾ƒçŸ­çš„é•¿åº¦
                        min_len = min(len(steps), len(data))
                        steps_to_use = steps[:min_len]
                        data_to_use = data[:min_len]
                    else:
                        steps_to_use = steps
                        data_to_use = data
                    
                    if len(steps_to_use) > 0 and len(data_to_use) > 0:
                        ax.plot(steps_to_use, data_to_use, 
                               label=metric, color=colors[i % len(colors)], linewidth=1.5)
                        plotted_any = True
            
            if plotted_any:
                ax.set_title(group_name, fontsize=12, fontweight='bold')
                ax.set_xlabel('Training Step')
                ax.set_ylabel('Value')
                ax.legend(fontsize=8)
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ è¶‹åŠ¿çº¿ï¼ˆå¯¹ä¸»è¦æŸå¤±ï¼‰
                if group_name == 'SAC Losses':
                    for metric in ['critic_loss', 'actor_loss']:
                        if metric in plot_data and len(plot_data[metric]) > 10:
                            # ç®€å•ç§»åŠ¨å¹³å‡
                            values = plot_data[metric]
                            window = min(50, len(values) // 10)
                            if window > 1:
                                smooth = np.convolve(values, np.ones(window)/window, mode='valid')
                                smooth_steps = steps[window-1:]
                                
                                # ç¡®ä¿smooth_stepså’Œsmoothé•¿åº¦åŒ¹é…
                                if len(smooth_steps) != len(smooth):
                                    min_len = min(len(smooth_steps), len(smooth))
                                    smooth_steps = smooth_steps[:min_len]
                                    smooth = smooth[:min_len]
                                
                                if len(smooth_steps) > 0 and len(smooth) > 0:
                                    ax.plot(smooth_steps, smooth, '--', alpha=0.7, linewidth=2)
            else:
                ax.text(0.5, 0.5, f'No data for\n{group_name}', 
                       ha='center', va='center', transform=ax.transAxes)
                ax.set_title(group_name)
        
        plt.suptitle(f'Training Progress - {self.experiment_name}', fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        if save_path is None:
            save_path = os.path.join(self.experiment_dir, f'training_curves_step_{steps[-1]}.png')
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ˆ æŸå¤±æ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
        
        if show:
            plt.show()
        else:
            plt.close()
        
        return save_path
    
    def save_logs(self):
        """ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶"""
        # ä¿å­˜ä¸ºCSV
        csv_path = os.path.join(self.experiment_dir, 'training_log.csv')
        with open(csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            
            # å†™å…¥è¡¨å¤´
            headers = ['step', 'time'] + list(self.loss_history.keys())
            if self.episode_history:
                headers.insert(2, 'episode')
            writer.writerow(headers)
            
            # å†™å…¥æ•°æ®
            for i, step in enumerate(self.step_history):
                row = [step, self.time_history[i]]
                if self.episode_history and i < len(self.episode_history):
                    row.append(self.episode_history[i])
                elif self.episode_history:
                    row.append('')
                
                for metric in self.loss_history.keys():
                    if i < len(self.loss_history[metric]):
                        row.append(self.loss_history[metric][i])
                    else:
                        row.append('')
                writer.writerow(row)
        
        # ä¿å­˜ä¸ºJSON
        json_path = os.path.join(self.experiment_dir, 'training_log.json')
        log_data = {
            'config': self.config,
            'steps': self.step_history,
            'times': self.time_history,
            'episodes': self.episode_history,
            'metrics': dict(self.loss_history)
        }
        with open(json_path, 'w') as f:
            json.dump(log_data, f, indent=2)
        
        # ä¿å­˜ä¸ºPickleï¼ˆå®Œæ•´å¯¹è±¡ï¼‰
        pickle_path = os.path.join(self.experiment_dir, 'training_logger.pkl')
        with open(pickle_path, 'wb') as f:
            pickle.dump(self, f)
    
    def save_config(self):
        """ä¿å­˜é…ç½®ä¿¡æ¯"""
        config_path = os.path.join(self.experiment_dir, 'config.json')
        with open(config_path, 'w') as f:
            json.dump(self.config, f, indent=2)
    
    def generate_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„è®­ç»ƒæŠ¥å‘Š"""
        if not self.step_history:
            print("âŒ æ²¡æœ‰æ•°æ®ç”ŸæˆæŠ¥å‘Š")
            return
        
        report_path = os.path.join(self.experiment_dir, 'training_report.txt')
        
        with open(report_path, 'w') as f:
            f.write(f"Training Report - {self.experiment_name}\n")
            f.write("=" * 80 + "\n\n")
            
            # ğŸš€ NEW: å®éªŒåŸºæœ¬ä¿¡æ¯
            f.write("ğŸ“‹ å®éªŒåŸºæœ¬ä¿¡æ¯:\n")
            exp_info = self.config.get('experiment_info', {})
            f.write(f"  å®éªŒåç§°: {exp_info.get('experiment_name', 'N/A')}\n")
            f.write(f"  å¼€å§‹æ—¶é—´: {exp_info.get('start_time', 'N/A')}\n")
            f.write(f"  ç»“æŸæ—¶é—´: {datetime.now().isoformat()}\n")
            f.write(f"  Pythonç‰ˆæœ¬: {exp_info.get('python_version', 'N/A')}\n")
            f.write(f"  å¹³å°: {exp_info.get('platform', 'N/A')}\n")
            f.write(f"  æ—¥å¿—ç›®å½•: {exp_info.get('log_dir', 'N/A')}\n\n")
            
            # ğŸš€ NEW: è®­ç»ƒé…ç½®å’Œè¶…å‚æ•°
            f.write("âš™ï¸ è®­ç»ƒè¶…å‚æ•°:\n")
            hyperparams = self.config.get('hyperparams', {})
            if hyperparams:
                # SACç›¸å…³å‚æ•°
                sac_params = {k: v for k, v in hyperparams.items() if k.startswith('sac_') or k in ['lr', 'alpha', 'batch_size', 'buffer_capacity']}
                if sac_params:
                    f.write("  SACç®—æ³•å‚æ•°:\n")
                    for key, value in sac_params.items():
                        f.write(f"    {key}: {value}\n")
                
                # è®­ç»ƒç›¸å…³å‚æ•°
                train_params = {k: v for k, v in hyperparams.items() if k in ['warmup_steps', 'update_frequency', 'num_processes', 'seed']}
                if train_params:
                    f.write("  è®­ç»ƒæµç¨‹å‚æ•°:\n")
                    for key, value in train_params.items():
                        f.write(f"    {key}: {value}\n")
                
                # å…¶ä»–å‚æ•°
                other_params = {k: v for k, v in hyperparams.items() if k not in sac_params and k not in train_params}
                if other_params:
                    f.write("  å…¶ä»–å‚æ•°:\n")
                    for key, value in other_params.items():
                        f.write(f"    {key}: {value}\n")
            else:
                f.write("  æœªè®°å½•è¶…å‚æ•°ä¿¡æ¯\n")
            f.write("\n")
            
            # ğŸš€ NEW: ç¯å¢ƒé…ç½®
            f.write("ğŸŒ ç¯å¢ƒé…ç½®:\n")
            env_config = self.config.get('env_config', {})
            if env_config:
                for key, value in env_config.items():
                    if isinstance(value, (list, tuple)):
                        f.write(f"  {key}: {list(value)}\n")
                    elif isinstance(value, dict):
                        f.write(f"  {key}:\n")
                        for sub_key, sub_value in value.items():
                            f.write(f"    {sub_key}: {sub_value}\n")
                    else:
                        f.write(f"  {key}: {value}\n")
            else:
                f.write("  æœªè®°å½•ç¯å¢ƒé…ç½®ä¿¡æ¯\n")
            f.write("\n")
            
            # ğŸš€ NEW: è®­ç»ƒç»Ÿè®¡æ¦‚è§ˆ
            f.write("ğŸ“Š è®­ç»ƒç»Ÿè®¡æ¦‚è§ˆ:\n")
            total_time_hours = self.time_history[-1] / 3600 if self.time_history else 0
            f.write(f"  æ€»è®­ç»ƒæ­¥æ•°: {self.step_history[-1] if self.step_history else 0}\n")
            f.write(f"  æ€»è®­ç»ƒæ—¶é—´: {total_time_hours:.2f} å°æ—¶\n")
            f.write(f"  å¹³å‡è®­ç»ƒé€Ÿåº¦: {self.step_history[-1]/self.time_history[-1]:.2f} æ­¥/ç§’\n")
            
            if self.episode_history:
                f.write(f"  æ€»Episodeæ•°: {max(self.episode_history) if self.episode_history else 0}\n")
                f.write(f"  å¹³å‡Episodeé•¿åº¦: {self.step_history[-1]/max(self.episode_history):.1f} æ­¥\n")
            f.write("\n")
            
            # ğŸš€ ENHANCED: æŸå¤±ç»Ÿè®¡åˆ†æ
            f.write("ğŸ“ˆ è®­ç»ƒæŸå¤±åˆ†æ:\n")
            loss_metrics = ['critic_loss', 'actor_loss', 'alpha_loss', 'alpha']
            
            for metric_name in loss_metrics:
                if metric_name in self.loss_history:
                    values = self.loss_history[metric_name]
                    f.write(f"  {metric_name}:\n")
                    f.write(f"    æœ€ç»ˆå€¼: {values[-1]:.6f}\n")
                    f.write(f"    å¹³å‡å€¼: {np.mean(values):.6f}\n")
                    f.write(f"    æ ‡å‡†å·®: {np.std(values):.6f}\n")
                    f.write(f"    æœ€å°å€¼: {np.min(values):.6f}\n")
                    f.write(f"    æœ€å¤§å€¼: {np.max(values):.6f}\n")
                    
                    # è¶‹åŠ¿åˆ†æ
                    if len(values) > 100:
                        recent_values = values[-100:]
                        early_values = values[:100]
                        trend = np.mean(recent_values) - np.mean(early_values)
                        f.write(f"    è¶‹åŠ¿(è¿‘æœŸvsæ—©æœŸ): {trend:+.6f}\n")
                    f.write("\n")
            
            # ğŸš€ NEW: Qå€¼ç»Ÿè®¡
            q_metrics = ['q1_mean', 'q2_mean', 'buffer_size', 'learning_rate']
            f.write("ğŸ¯ è®­ç»ƒç»†èŠ‚ç»Ÿè®¡:\n")
            for metric_name in q_metrics:
                if metric_name in self.loss_history:
                    values = self.loss_history[metric_name]
                    f.write(f"  {metric_name}:\n")
                    f.write(f"    æœ€ç»ˆå€¼: {values[-1]:.6f}\n")
                    f.write(f"    å¹³å‡å€¼: {np.mean(values):.6f}\n")
                    if metric_name in ['q1_mean', 'q2_mean']:
                        f.write(f"    æœ€å°å€¼: {np.min(values):.6f}\n")
                        f.write(f"    æœ€å¤§å€¼: {np.max(values):.6f}\n")
                    f.write("\n")
            
            # ğŸš€ NEW: è®­ç»ƒå»ºè®®
            f.write("ğŸ’¡ è®­ç»ƒåˆ†æå»ºè®®:\n")
            if 'critic_loss' in self.loss_history:
                final_critic_loss = self.loss_history['critic_loss'][-1]
                if final_critic_loss < 1.0:
                    f.write("  âœ… Critic Lossè¡¨ç°ä¼˜ç§€ (< 1.0)\n")
                elif final_critic_loss < 2.0:
                    f.write("  ğŸ‘ Critic Lossè¡¨ç°è‰¯å¥½ (< 2.0)\n")
                elif final_critic_loss < 5.0:
                    f.write("  âš ï¸ Critic Lossè¾ƒé«˜ (< 5.0)ï¼Œå»ºè®®æ£€æŸ¥å¥–åŠ±å‡½æ•°\n")
                else:
                    f.write("  âŒ Critic Lossè¿‡é«˜ (>= 5.0)ï¼Œéœ€è¦è°ƒæ•´è¶…å‚æ•°æˆ–å¥–åŠ±å‡½æ•°\n")
            
            if 'actor_loss' in self.loss_history:
                final_actor_loss = self.loss_history['actor_loss'][-1]
                if final_actor_loss < -2.0:
                    f.write("  âœ… Actor Lossè¡¨ç°ä¼˜ç§€ (< -2.0)\n")
                elif final_actor_loss < 0:
                    f.write("  ğŸ‘ Actor Lossè¡¨ç°è‰¯å¥½ (< 0)\n")
                else:
                    f.write("  âš ï¸ Actor Lossä¸ºæ­£å€¼ï¼Œç­–ç•¥å¯èƒ½éœ€è¦æ”¹è¿›\n")
            
            f.write("\n")
            f.write("=" * 80 + "\n")
        
        print(f"ğŸ“‹ è¯¦ç»†è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        return report_path
    
    @classmethod
    def load_logger(cls, experiment_dir):
        """ä»ä¿å­˜çš„æ–‡ä»¶åŠ è½½logger"""
        pickle_path = os.path.join(experiment_dir, 'training_logger.pkl')
        if os.path.exists(pickle_path):
            with open(pickle_path, 'rb') as f:
                return pickle.load(f)
        else:
            print(f"âŒ æœªæ‰¾åˆ°ä¿å­˜çš„logger: {pickle_path}")
            return None


class RealTimeMonitor:
    """å®æ—¶ç›‘æ§ç±»"""
    
    def __init__(self, logger, alert_thresholds=None):
        self.logger = logger
        self.alert_thresholds = alert_thresholds or {
            'critic_loss': {'max': 10.0, 'nan_check': True},
            'actor_loss': {'max': 5.0, 'nan_check': True},
            'alpha_loss': {'max': 2.0, 'nan_check': True},
        }
        self.alert_history = []
    
    def check_alerts(self, step, metrics):
        """æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸æƒ…å†µéœ€è¦è­¦æŠ¥"""
        alerts = []
        
        for metric_name, thresholds in self.alert_thresholds.items():
            if metric_name in metrics:
                value = metrics[metric_name]
                
                # æ£€æŸ¥NaN
                if thresholds.get('nan_check', False) and (np.isnan(value) or np.isinf(value)):
                    alerts.append(f"âš ï¸ {metric_name} å‡ºç° NaN/Inf: {value}")
                
                # æ£€æŸ¥è¶…å‡ºé˜ˆå€¼
                if 'max' in thresholds and value > thresholds['max']:
                    alerts.append(f"âš ï¸ {metric_name} è¶…å‡ºæœ€å¤§é˜ˆå€¼: {value:.4f} > {thresholds['max']}")
                
                if 'min' in thresholds and value < thresholds['min']:
                    alerts.append(f"âš ï¸ {metric_name} ä½äºæœ€å°é˜ˆå€¼: {value:.4f} < {thresholds['min']}")
        
        # æ£€æŸ¥è¶‹åŠ¿å¼‚å¸¸
        for metric_name in ['critic_loss', 'actor_loss']:
            stats = self.logger.get_recent_stats(metric_name, window=50)
            if stats and stats['trend'] == 'increasing' and stats['mean'] > 1.0:
                alerts.append(f"ğŸ“ˆ {metric_name} æŒç»­ä¸Šå‡è¶‹åŠ¿ï¼Œå½“å‰å‡å€¼: {stats['mean']:.4f}")
        
        # è®°å½•å’Œæ˜¾ç¤ºè­¦æŠ¥
        if alerts:
            self.alert_history.extend([(step, alert) for alert in alerts])
            print(f"\nğŸš¨ Step {step} ç›‘æ§è­¦æŠ¥:")
            for alert in alerts:
                print(f"   {alert}")
        
        return alerts


# ç¤ºä¾‹ç”¨æ³•å‡½æ•°
def demo_usage():
    """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨TrainingLogger"""
    
    # åˆ›å»ºlogger
    logger = TrainingLogger(experiment_name="sac_reacher2d_demo")
    monitor = RealTimeMonitor(logger)
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    print("ğŸš€ å¼€å§‹æ¨¡æ‹Ÿè®­ç»ƒ...")
    
    for step in range(1000):
        # æ¨¡æ‹ŸæŸå¤±å€¼
        metrics = {
            'critic_loss': 1.0 + 0.5 * np.exp(-step/200) + np.random.normal(0, 0.1),
            'actor_loss': 0.5 + 0.3 * np.exp(-step/300) + np.random.normal(0, 0.05),
            'alpha_loss': 0.2 + np.random.normal(0, 0.02),
            'alpha': 0.2 + 0.1 * np.sin(step/100),
            'q1_mean': 2.0 + np.random.normal(0, 0.2),
            'q2_mean': 2.1 + np.random.normal(0, 0.2),
            'buffer_size': min(10000, step * 10)
        }
        
        # è®°å½•
        episode = step // 50  # å‡è®¾æ¯50æ­¥ä¸€ä¸ªepisode
        logger.log_step(step, metrics, episode)
        
        # ç›‘æ§
        alerts = monitor.check_alerts(step, metrics)
        
        # å®šæœŸæ‰“å°ç»Ÿè®¡
        # if step % 200 == 0 and step > 0:
        #     logger.print_current_stats(step, detailed=True)
        
        # å®šæœŸä¿å­˜å’Œç»˜å›¾
        if step % 500 == 0 and step > 0:
            logger.plot_losses(recent_steps=500, show=False)
    
    # æœ€ç»ˆæŠ¥å‘Š
    logger.generate_report()
    logger.plot_losses(show=False)
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼ŒæŸ¥çœ‹ç»“æœ: {logger.experiment_dir}")


if __name__ == "__main__":
    demo_usage() 