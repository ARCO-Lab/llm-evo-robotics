#!/usr/bin/env python3
"""
å¤§è§„æ¨¡è®­ç»ƒç›‘æ§å™¨
å®æ—¶ç›‘æ§30ä»£Ã—10ä¸ªä½“Ã—5000æ­¥çš„MAP-Elitesè®­ç»ƒè¿›åº¦å’ŒæŸå¤±è®°å½•
"""

import os
import time
import json
import subprocess
from datetime import datetime, timedelta

def monitor_training_progress():
    """ç›‘æ§è®­ç»ƒè¿›åº¦"""
    experiment_name = "large_scale_30gen_10pop"
    loss_log_dir = f"enhanced_multi_network_logs/{experiment_name}_multi_network_loss"
    map_elites_dir = "map_elites_experiments"
    
    start_time = time.time()
    
    print("ğŸ” å¤§è§„æ¨¡MAP-Elitesè®­ç»ƒç›‘æ§å™¨")
    print("=" * 60)
    print(f"å®éªŒåç§°: {experiment_name}")
    print(f"é…ç½®: 30ä»£ Ã— 10ä¸ªä½“/ä»£ Ã— 5000æ­¥/ä¸ªä½“")
    print(f"é¢„è®¡æ€»è®­ç»ƒæ­¥æ•°: 1,500,000 æ­¥")
    print(f"ç›‘æ§å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    iteration = 0
    
    try:
        while True:
            iteration += 1
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            print(f"\nğŸ“Š ç›‘æ§æŠ¥å‘Š #{iteration} - {datetime.now().strftime('%H:%M:%S')}")
            print(f"è¿è¡Œæ—¶é—´: {timedelta(seconds=int(elapsed_time))}")
            
            # æ£€æŸ¥è®­ç»ƒè¿›ç¨‹
            try:
                result = subprocess.run(['pgrep', '-f', 'enhanced_multi_network_extractor'], 
                                      capture_output=True, text=True)
                if result.returncode == 0:
                    pids = result.stdout.strip().split('\n')
                    print(f"ğŸŸ¢ è®­ç»ƒè¿›ç¨‹çŠ¶æ€: è¿è¡Œä¸­ ({len(pids)} ä¸ªè¿›ç¨‹)")
                else:
                    print("ğŸ”´ è®­ç»ƒè¿›ç¨‹çŠ¶æ€: æœªè¿è¡Œ")
            except:
                print("âš ï¸ æ— æ³•æ£€æŸ¥è®­ç»ƒè¿›ç¨‹çŠ¶æ€")
            
            # æ£€æŸ¥æŸå¤±è®°å½•
            if os.path.exists(loss_log_dir):
                print(f"ğŸ“ æŸå¤±è®°å½•ç›®å½•: {loss_log_dir}")
                
                # ç»Ÿè®¡å„ç½‘ç»œçš„æŸå¤±è®°å½•æ•°
                network_stats = {}
                for network in ['ppo', 'attention', 'gnn', 'sac', 'total']:
                    csv_file = os.path.join(loss_log_dir, f"{network}_losses.csv")
                    if os.path.exists(csv_file):
                        try:
                            with open(csv_file, 'r') as f:
                                lines = f.readlines()
                                record_count = len(lines) - 1  # å‡å»å¤´éƒ¨
                                network_stats[network] = record_count
                        except:
                            network_stats[network] = 0
                    else:
                        network_stats[network] = 0
                
                print("ğŸ“Š æŸå¤±è®°å½•ç»Ÿè®¡:")
                for network, count in network_stats.items():
                    print(f"   {network.upper()}: {count} æ¡è®°å½•")
                
                total_records = sum(network_stats.values())
                print(f"   æ€»è®¡: {total_records} æ¡æŸå¤±è®°å½•")
                
            else:
                print("âš ï¸ æŸå¤±è®°å½•ç›®å½•å°šæœªåˆ›å»º")
            
            # æ£€æŸ¥MAP-Eliteså®éªŒç»“æœ
            if os.path.exists(map_elites_dir):
                try:
                    # ç»Ÿè®¡ä¸ªä½“æ•°é‡
                    individuals = [d for d in os.listdir(map_elites_dir) 
                                 if d.startswith('individual_') and 
                                    os.path.isdir(os.path.join(map_elites_dir, d))]
                    
                    print(f"ğŸ§¬ MAP-Elitesè¿›åº¦:")
                    print(f"   å·²è®­ç»ƒä¸ªä½“æ•°: {len(individuals)}")
                    
                    if len(individuals) > 0:
                        # ä¼°ç®—è¿›åº¦
                        total_expected_individuals = 30 * 10  # 30ä»£ Ã— 10ä¸ªä½“
                        progress_percentage = (len(individuals) / total_expected_individuals) * 100
                        print(f"   æ€»ä½“è¿›åº¦: {progress_percentage:.1f}% ({len(individuals)}/{total_expected_individuals})")
                        
                        # ä¼°ç®—å‰©ä½™æ—¶é—´
                        if len(individuals) > 1 and elapsed_time > 60:
                            avg_time_per_individual = elapsed_time / len(individuals)
                            remaining_individuals = total_expected_individuals - len(individuals)
                            estimated_remaining_time = remaining_individuals * avg_time_per_individual
                            
                            print(f"   å¹³å‡æ¯ä¸ªä½“ç”¨æ—¶: {timedelta(seconds=int(avg_time_per_individual))}")
                            print(f"   é¢„è®¡å‰©ä½™æ—¶é—´: {timedelta(seconds=int(estimated_remaining_time))}")
                            print(f"   é¢„è®¡å®Œæˆæ—¶é—´: {(datetime.now() + timedelta(seconds=estimated_remaining_time)).strftime('%H:%M:%S')}")
                    
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•ç»Ÿè®¡MAP-Elitesè¿›åº¦: {e}")
            else:
                print("âš ï¸ MAP-Eliteså®éªŒç›®å½•å°šæœªåˆ›å»º")
            
            # æ£€æŸ¥ç³»ç»Ÿèµ„æº
            try:
                # æ£€æŸ¥å†…å­˜ä½¿ç”¨
                result = subprocess.run(['free', '-h'], capture_output=True, text=True)
                if result.returncode == 0:
                    lines = result.stdout.strip().split('\n')
                    if len(lines) > 1:
                        mem_line = lines[1].split()
                        if len(mem_line) >= 3:
                            total_mem = mem_line[1]
                            used_mem = mem_line[2]
                            print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {used_mem}/{total_mem}")
            except:
                pass
            
            print("-" * 60)
            
            # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
            time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç›‘æ§è¢«ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç›‘æ§å‡ºé”™: {e}")

def show_final_summary():
    """æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“"""
    experiment_name = "large_scale_30gen_10pop"
    loss_log_dir = f"enhanced_multi_network_logs/{experiment_name}_multi_network_loss"
    
    print("\nğŸ‰ å¤§è§„æ¨¡è®­ç»ƒç›‘æ§æ€»ç»“")
    print("=" * 60)
    
    if os.path.exists(loss_log_dir):
        # æ˜¾ç¤ºæœ€ç»ˆæŸå¤±ç»Ÿè®¡
        stats_file = os.path.join(loss_log_dir, "comprehensive_loss_statistics.json")
        if os.path.exists(stats_file):
            try:
                with open(stats_file, 'r') as f:
                    stats = json.load(f)
                
                print("ğŸ“ˆ æœ€ç»ˆæŸå¤±ç»Ÿè®¡:")
                print(f"   æ€»ç½‘ç»œæ•°: {stats['experiment_info']['total_networks']}")
                print(f"   æ€»è®°å½•æ•°: {stats['experiment_info']['total_records']}")
                
                for network, network_stats in stats['network_stats'].items():
                    print(f"\nğŸ“Š {network.upper()} ç½‘ç»œ:")
                    print(f"   è®°å½•æ•°: {network_stats['total_records']}")
                    
                    for metric, metric_stats in network_stats['metrics'].items():
                        if 'loss' in metric.lower():
                            trend_icon = "ğŸ“‰" if metric_stats['trend'] == 'decreasing' else "ğŸ“ˆ"
                            print(f"   {metric}: {metric_stats['avg']:.3f} (è¶‹åŠ¿: {trend_icon})")
                
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–ç»Ÿè®¡æ–‡ä»¶: {e}")
        
        print(f"\nğŸ“ å®Œæ•´ç»“æœä¿å­˜åœ¨: {loss_log_dir}")
    else:
        print("âš ï¸ æŸå¤±è®°å½•ç›®å½•ä¸å­˜åœ¨")

if __name__ == "__main__":
    try:
        monitor_training_progress()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç›‘æ§ç»“æŸ")
    finally:
        show_final_summary()
