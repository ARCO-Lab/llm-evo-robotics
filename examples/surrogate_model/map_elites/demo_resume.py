#!/usr/bin/env python3
"""
æ¼”ç¤ºå…±äº«PPOæ¨¡å‹æ¢å¤åŠŸèƒ½
"""

import os
import sys
import torch
import time
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '../../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from shared_ppo_trainer import SharedPPOTrainer

def create_demo_model():
    """åˆ›å»ºä¸€ä¸ªæ¼”ç¤ºæ¨¡å‹æ–‡ä»¶"""
    print("ğŸ¬ åˆ›å»ºæ¼”ç¤ºæ¨¡å‹æ–‡ä»¶...")
    
    model_config = {
        'observation_dim': 14,
        'action_dim': 3,
        'hidden_dim': 256
    }
    
    training_config = {
        'lr': 2e-4,
        'buffer_size': 5000,
        'min_batch_size': 100,
        'model_path': './map_elites_shared_ppo_results/shared_ppo_model.pth',
        'update_interval': 10
    }
    
    trainer = SharedPPOTrainer(model_config, training_config)
    
    try:
        trainer.start_training()
        print("âœ… è®­ç»ƒå™¨å¯åŠ¨æˆåŠŸ")
        
        # æ·»åŠ ä¸€äº›ç»éªŒæ¥è§¦å‘æ¨¡å‹ä¿å­˜
        for i in range(150):
            fake_experience = {
                'observation': torch.randn(model_config['observation_dim']).numpy(),
                'action': torch.randn(model_config['action_dim']).numpy(),
                'reward': float(torch.randn(1).item()),
                'next_observation': torch.randn(model_config['observation_dim']).numpy(),
                'done': False,
                'worker_id': 0,
                'robot_config': {'num_links': 3, 'link_lengths': [90.0, 90.0, 90.0]}
            }
            trainer.add_experience(fake_experience)
        
        print("â³ ç­‰å¾…æ¨¡å‹è®­ç»ƒå’Œä¿å­˜...")
        time.sleep(8)
        
    finally:
        trainer.stop_training()
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¿å­˜æˆåŠŸ
    if os.path.exists(training_config['model_path']):
        print(f"âœ… æ¼”ç¤ºæ¨¡å‹å·²åˆ›å»º: {training_config['model_path']}")
        return True
    else:
        print(f"âŒ æ¼”ç¤ºæ¨¡å‹åˆ›å»ºå¤±è´¥")
        return False

def demo_resume_functionality():
    """æ¼”ç¤ºæ¢å¤åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ¬ å…±äº«PPOæ¨¡å‹æ¢å¤åŠŸèƒ½æ¼”ç¤º")
    print("="*60)
    
    # ç¬¬1æ­¥ï¼šåˆ›å»ºæ¼”ç¤ºæ¨¡å‹
    print("\nğŸ“ ç¬¬1æ­¥ï¼šåˆ›å»ºåˆå§‹æ¨¡å‹")
    if not create_demo_model():
        print("âŒ æ— æ³•åˆ›å»ºæ¼”ç¤ºæ¨¡å‹ï¼Œé€€å‡º")
        return
    
    # ç¬¬2æ­¥ï¼šæ˜¾ç¤ºå‘½ä»¤ç¤ºä¾‹
    print("\nğŸ“ ç¬¬2æ­¥ï¼šå‘½ä»¤ä½¿ç”¨ç¤ºä¾‹")
    print("ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š")
    print()
    print("ğŸ†• å¼€å§‹æ–°è®­ç»ƒï¼ˆä¼šè¦†ç›–ç°æœ‰æ¨¡å‹ï¼‰:")
    print("   python examples/surrogate_model/map_elites/map_elites_trainer.py --train-shared")
    print()
    print("ğŸ”„ æ¢å¤è®­ç»ƒï¼ˆä»ç°æœ‰æ¨¡å‹ç»§ç»­ï¼‰:")
    print("   python examples/surrogate_model/map_elites/map_elites_trainer.py --train-shared --resume")
    print()
    print("ğŸ¨ æ¢å¤è®­ç»ƒ + ç¦ç”¨å¯è§†åŒ–:")
    print("   python examples/surrogate_model/map_elites/map_elites_trainer.py --train-shared --resume --no-render")
    print()
    print("ğŸ”‡ æ¢å¤è®­ç»ƒ + é™é»˜æ¨¡å¼:")
    print("   python examples/surrogate_model/map_elites/map_elites_trainer.py --train-shared --resume --silent")
    
    # ç¬¬3æ­¥ï¼šæ£€æŸ¥æ¨¡å‹ä¿¡æ¯
    print("\nğŸ“ ç¬¬3æ­¥ï¼šå½“å‰æ¨¡å‹ä¿¡æ¯")
    model_path = './map_elites_shared_ppo_results/shared_ppo_model.pth'
    if os.path.exists(model_path):
        try:
            checkpoint = torch.load(model_path, map_location='cpu')
            print(f"ğŸ“Š æ¨¡å‹æ–‡ä»¶: {model_path}")
            print(f"ğŸ“Š æ›´æ–°æ¬¡æ•°: {checkpoint.get('update_count', 0)}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(model_path)/1024:.1f} KB")
            print(f"ğŸ“Š åŒ…å«ç»„ä»¶: {', '.join(checkpoint.keys())}")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–æ¨¡å‹ä¿¡æ¯: {e}")
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼ä½ ç°åœ¨å¯ä»¥ä½¿ç”¨ --resume å‚æ•°æ¥æ¢å¤è®­ç»ƒäº†ã€‚")

if __name__ == "__main__":
    demo_resume_functionality()
