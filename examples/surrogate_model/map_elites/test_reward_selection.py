#!/usr/bin/env python3
"""
æµ‹è¯•åŸºäºrewardçš„æ¯”ä¾‹é€‰æ‹©
"""

import sys
import os
sys.path.append(os.path.dirname(__file__))

import numpy as np
from map_elites_core import MAPElitesArchive, Individual, RobotGenotype, RobotPhenotype

def test_reward_based_selection():
    """æµ‹è¯•åŸºäºrewardçš„é€‰æ‹©æ˜¯å¦å·¥ä½œ"""
    print("ğŸ§ª æµ‹è¯•åŸºäºrewardçš„æ¯”ä¾‹é€‰æ‹©\n")
    
    # åˆ›å»ºå­˜æ¡£
    archive = MAPElitesArchive()
    
    # æ‰‹åŠ¨åˆ›å»ºä¸€äº›æµ‹è¯•ä¸ªä½“ï¼Œè®¾ç½®ä¸åŒçš„reward
    test_individuals = []
    
    # ä¸ªä½“1: é«˜reward
    ind1 = Individual(
        genotype=RobotGenotype(num_links=3, link_lengths=[50, 50, 50]),
        phenotype=RobotPhenotype(avg_reward=100.0),  # é«˜reward
        fitness=100.0,
        individual_id="high_reward"
    )
    
    # ä¸ªä½“2: ä¸­ç­‰reward  
    ind2 = Individual(
        genotype=RobotGenotype(num_links=4, link_lengths=[40, 40, 40, 40]),
        phenotype=RobotPhenotype(avg_reward=50.0),   # ä¸­ç­‰reward
        fitness=50.0,
        individual_id="medium_reward"
    )
    
    # ä¸ªä½“3: ä½reward
    ind3 = Individual(
        genotype=RobotGenotype(num_links=2, link_lengths=[60, 60]),
        phenotype=RobotPhenotype(avg_reward=10.0),   # ä½reward
        fitness=10.0,
        individual_id="low_reward"
    )
    
    # æ·»åŠ åˆ°å­˜æ¡£ï¼ˆéœ€è¦æ‰‹åŠ¨è®¾ç½®åæ ‡ä»¥é¿å…ç‰¹å¾æå–ï¼‰
    archive.archive[(0, 0, 0, 0, 0)] = ind1
    archive.archive[(1, 1, 1, 1, 1)] = ind2  
    archive.archive[(2, 2, 2, 2, 2)] = ind3
    
    print(f"ğŸ“Š å­˜æ¡£ä¸­æœ‰ {len(archive.archive)} ä¸ªä¸ªä½“:")
    for coords, ind in archive.archive.items():
        print(f"   ä½ç½® {coords}: ID={ind.individual_id}, reward={ind.fitness}")
    
    # è¿›è¡Œå¤šæ¬¡é€‰æ‹©ï¼Œç»Ÿè®¡ç»“æœ
    print(f"\nğŸ¯ è¿›è¡Œ100æ¬¡é€‰æ‹©ï¼Œç»Ÿè®¡é€‰æ‹©é¢‘ç‡:")
    
    selection_counts = {
        "high_reward": 0,
        "medium_reward": 0, 
        "low_reward": 0
    }
    
    num_trials = 100
    for i in range(num_trials):
        selected = archive.get_random_elite()
        if selected:
            selection_counts[selected.individual_id] += 1
    
    print(f"\nğŸ“ˆ é€‰æ‹©ç»“æœç»Ÿè®¡:")
    total_reward = 100 + 50 + 10  # 160
    for ind_id, count in selection_counts.items():
        actual_rate = count / num_trials
        if ind_id == "high_reward":
            expected_rate = (100 + 1) / (160 + 3)  # è°ƒæ•´åçš„æ¦‚ç‡
        elif ind_id == "medium_reward":
            expected_rate = (50 + 1) / (160 + 3)
        else:
            expected_rate = (10 + 1) / (160 + 3)
        
        print(f"   {ind_id}: {count}/{num_trials} = {actual_rate:.2%} "
              f"(é¢„æœŸçº¦ {expected_rate:.2%})")
    
    # éªŒè¯æ˜¯å¦ç¬¦åˆé¢„æœŸ
    high_rate = selection_counts["high_reward"] / num_trials
    low_rate = selection_counts["low_reward"] / num_trials
    
    if high_rate > low_rate:
        print(f"\nâœ… æµ‹è¯•æˆåŠŸï¼é«˜rewardä¸ªä½“çš„é€‰æ‹©é¢‘ç‡ ({high_rate:.2%}) > ä½rewardä¸ªä½“ ({low_rate:.2%})")
        return True
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼é€‰æ‹©é¢‘ç‡ä¸ç¬¦åˆé¢„æœŸ")
        return False

if __name__ == "__main__":
    success = test_reward_based_selection()
    if success:
        print("ğŸ‰ åŸºäºrewardçš„æ¯”ä¾‹é€‰æ‹©æ­£å¸¸å·¥ä½œï¼")
    else:
        print("ğŸ”§ éœ€è¦æ£€æŸ¥å®ç°...")