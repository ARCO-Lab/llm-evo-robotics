import numpy as np
import torch
import os
import pickle
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from collections import defaultdict
import time


@dataclass
class RobotGenotype:
    """æœºå™¨äººåŸºå› å‹ - åŒ…å«æ‰€æœ‰å¯å˜çš„è®¾è®¡å‚æ•°"""
    # ğŸ¤– æœºå™¨äººå½¢æ€å‚æ•°
    num_links: int = 4
    link_lengths: List[float] = None
    
    # ğŸ§  SACè¶…å‚æ•°
    lr: float = 1e-4
    alpha: float = 0.2
    tau: float = 0.005
    gamma: float = 0.99
    batch_size: int = 64
    buffer_capacity: int = 10000
    
    # ğŸ¯ è®­ç»ƒå‚æ•°
    warmup_steps: int = 1000
    target_entropy_factor: float = 0.8
    
    def __post_init__(self):
        if self.link_lengths is None:
            self.link_lengths = [80.0] * self.num_links
        assert len(self.link_lengths) == self.num_links


@dataclass 
class RobotPhenotype:
    """æœºå™¨äººè¡¨å‹ - è¡Œä¸ºç‰¹å¾"""
    # ğŸ¯ æ€§èƒ½ç‰¹å¾
    avg_reward: float = 0.0
    success_rate: float = 0.0
    min_distance_to_goal: float = float('inf')
    
    # ğŸ—ï¸ å½¢æ€ç‰¹å¾
    total_reach: float = 0.0
    complexity_score: float = 0.0
    
    # ğŸ® è¡Œä¸ºç‰¹å¾
    trajectory_smoothness: float = 0.0
    collision_frequency: float = 0.0
    exploration_coverage: float = 0.0  # ä¿®å¤æ‹¼å†™é”™è¯¯: converage -> coverage
    
    # ğŸ§  æ§åˆ¶ç‰¹å¾
    action_variance: float = 0.0
    learning_efficiency: float = 0.0  # ä¿®å¤æ‹¼å†™é”™è¯¯: leanring -> learning


@dataclass
class Individual:
    """MAP-Elitesä¸ªä½“"""
    genotype: RobotGenotype
    phenotype: RobotPhenotype
    fitness: float = 0.0
    generation: int = 0
    parent_id: Optional[str] = None  # ä¿®å¤ç±»å‹é”™è¯¯: int -> str
    individual_id: str = ""
    
    def __post_init__(self):
        if not self.individual_id:
            self.individual_id = f"gen_{self.generation}_{int(time.time() * 1000) % 100000}"


class FeatureExtractor:
    """ä»è®­ç»ƒè¿‡ç¨‹ä¸­æå–è¡Œä¸ºç‰¹å¾"""
    
    def __init__(self):
        pass
    
    def extract_from_training_data(self, training_metrics: Dict, robot_config: Dict) -> RobotPhenotype:
        """ä»è®­ç»ƒæŒ‡æ ‡ä¸­æå–è¡¨å‹ç‰¹å¾"""
        phenotype = RobotPhenotype()
        
        # ğŸ¯ æ€§èƒ½ç‰¹å¾
        phenotype.avg_reward = training_metrics.get('avg_reward', 0.0)
        phenotype.success_rate = training_metrics.get('success_rate', 0.0)
        phenotype.min_distance_to_goal = training_metrics.get('min_distance', float('inf'))
        
        # ğŸ—ï¸ å½¢æ€ç‰¹å¾
        link_lengths = robot_config.get('link_lengths', [80] * 4)
        phenotype.total_reach = sum(link_lengths)
        phenotype.complexity_score = len(link_lengths) + np.var(link_lengths) / 100.0
        
        # ğŸ® è¡Œä¸ºç‰¹å¾
        phenotype.trajectory_smoothness = training_metrics.get('trajectory_smoothness', 0.0)
        phenotype.collision_frequency = training_metrics.get('collision_rate', 0.0)
        phenotype.exploration_coverage = training_metrics.get('exploration_area', 0.0)
        
        # ğŸ§  æ§åˆ¶ç‰¹å¾
        phenotype.action_variance = training_metrics.get('action_variance', 0.0)
        phenotype.learning_efficiency = training_metrics.get('learning_rate', 0.0)
        
        return phenotype
    
    def discretize_features(self, phenotype: RobotPhenotype) -> Tuple[int, ...]:
        """å°†è¿ç»­ç‰¹å¾ç¦»æ•£åŒ–ä¸ºç½‘æ ¼åæ ‡"""
        # ğŸ¯ å¥–åŠ± (10ä¸ªåŒºé—´)
        reward_bin = min(9, max(0, int((phenotype.avg_reward + 100) / 20)))  # ä¿®å¤è¯­æ³•é”™è¯¯
        
        # ğŸ—ï¸ å¤æ‚åº¦ (5ä¸ªç­‰çº§)
        complexity_bin = min(4, max(0, int(phenotype.complexity_score / 2)))
        
        # ğŸ® å¹³æ»‘åº¦ (5ä¸ªç­‰çº§)
        smoothness_bin = min(4, max(0, int(phenotype.trajectory_smoothness * 5)))
        
        # ğŸ§  ç¢°æ’é¢‘ç‡ (5ä¸ªç­‰çº§)
        collision_bin = min(4, max(0, int(phenotype.collision_frequency * 5)))
        
        # ğŸ“ ä¼¸å±•èŒƒå›´ (6ä¸ªç­‰çº§)
        reach_bin = min(5, max(0, int((phenotype.total_reach - 200) / 50)))
        
        return (reward_bin, complexity_bin, smoothness_bin, collision_bin, reach_bin)


class MAPElitesArchive:
    """MAP-Eliteså­˜æ¡£"""
    
    def __init__(self, feature_dimensions: Tuple[int, ...] = (10, 5, 5, 5, 6), 
                 save_dir: str = "map_elites_archive"):
        self.feature_dimensions = feature_dimensions
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
        # å­˜æ¡£ç½‘æ ¼ï¼šåæ ‡ -> Individual
        self.archive: Dict[Tuple[int, ...], Individual] = {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.generation = 0
        self.total_evaluations = 0
        self.improvement_count = 0
        
        print(f"ğŸ—‚ï¸ MAP-Eliteså­˜æ¡£åˆå§‹åŒ–")
        print(f"ğŸ“ ç½‘æ ¼ç»´åº¦: {feature_dimensions}")
        print(f"ğŸ“Š æ€»å•å…ƒæ•°: {np.prod(feature_dimensions)}")
    
    def add_individual(self, individual: Individual) -> bool:
        """å°è¯•å°†ä¸ªä½“æ·»åŠ åˆ°å­˜æ¡£"""
        # å°†è¡¨å‹ç‰¹å¾ç¦»æ•£åŒ–
        extractor = FeatureExtractor()
        coords = extractor.discretize_features(individual.phenotype)
        
        self.total_evaluations += 1
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ›¿æ¢ç°æœ‰ä¸ªä½“
        if coords not in self.archive or individual.fitness > self.archive[coords].fitness:
            self.archive[coords] = individual  # ä¿®å¤ï¼šå®é™…æ·»åŠ ä¸ªä½“åˆ°å­˜æ¡£
            self.improvement_count += 1
            print(f"ğŸ†• ä¸ªä½“æ·»åŠ åˆ°ä½ç½® {coords}, é€‚åº”åº¦: {individual.fitness:.2f}")
            return True
        
        return False
    
    def get_random_elite(self) -> Optional[Individual]:
        """éšæœºé€‰æ‹©ä¸€ä¸ªç²¾è‹±ä¸ªä½“"""
        if not self.archive:
            return None
        
        # ä¿®å¤ï¼šæ­£ç¡®å¤„ç†å­—å…¸é”®çš„éšæœºé€‰æ‹©
        coords_list = list(self.archive.keys())
        if not coords_list:
            return None
        
        # ä½¿ç”¨random.choiceè€Œä¸æ˜¯np.random.choiceæ¥å¤„ç†å…ƒç»„
        import random
        selected_coords = random.choice(coords_list)
        return self.archive[selected_coords]
    
    def get_best_individual(self) -> Optional[Individual]:
        """è·å–æœ€ä½³ä¸ªä½“"""
        if not self.archive:
            return None
        return max(self.archive.values(), key=lambda x: x.fitness)
    
    def get_statistics(self) -> Dict:
        """è·å–å­˜æ¡£ç»Ÿè®¡ä¿¡æ¯"""
        if not self.archive:
            return {'size': 0, 'coverage': 0.0, 'best_fitness': -float('inf')}  # ä¿®å¤è¯­æ³•é”™è¯¯
        
        fitnesses = [ind.fitness for ind in self.archive.values()]
        coverage = len(self.archive) / np.prod(self.feature_dimensions)  # ä¿®å¤è¯­æ³•é”™è¯¯
        
        return {
            'size': len(self.archive),
            'coverage': coverage,
            'best_fitness': max(fitnesses),
            'avg_fitness': np.mean(fitnesses),
            'std_fitness': np.std(fitnesses) if len(fitnesses) > 1 else 0.0,
            'total_evaluations': self.total_evaluations,
            'improvement_rate': self.improvement_count / max(1, self.total_evaluations)
        }
    
    def save_archive(self, filename: Optional[str] = None):
        """ä¿å­˜å­˜æ¡£"""
        if filename is None:
            filename = f"archive_gen_{self.generation}.pkl"
        
        filepath = os.path.join(self.save_dir, filename)
        archive_data = {
            'archive': self.archive,
            'feature_dimensions': self.feature_dimensions,
            'generation': self.generation,
            'total_evaluations': self.total_evaluations,
            'improvement_count': self.improvement_count
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(archive_data, f)
        print(f"ğŸ’¾ å­˜æ¡£å·²ä¿å­˜: {filepath}")


class RobotMutator:  # ä¿®å¤ç±»åæ‹¼å†™é”™è¯¯: RobotMulator -> RobotMutator
    """æœºå™¨äººåŸºå› å‹å˜å¼‚å™¨"""
    
    def __init__(self, mutation_rates: Dict[str, float] = None):
        self.mutation_rates = mutation_rates or {
            'link_length': 0.1,    # é“¾èŠ‚é•¿åº¦å˜å¼‚æ¦‚ç‡
            'num_links': 0.05,     # é“¾èŠ‚æ•°é‡å˜å¼‚æ¦‚ç‡  
            'sac_params': 0.3,     # SACè¶…å‚æ•°å˜å¼‚æ¦‚ç‡
            'training_params': 0.2  # è®­ç»ƒå‚æ•°å˜å¼‚æ¦‚ç‡
        }
    
    def mutate(self, parent: RobotGenotype) -> RobotGenotype:
        """å¯¹åŸºå› å‹è¿›è¡Œå˜å¼‚"""
        # æ·±æ‹·è´çˆ¶ä»£
        mutant = RobotGenotype(
            num_links=parent.num_links,
            link_lengths=parent.link_lengths.copy(),
            lr=parent.lr,
            alpha=parent.alpha,
            tau=parent.tau,
            gamma=parent.gamma,
            batch_size=parent.batch_size,
            buffer_capacity=parent.buffer_capacity,
            warmup_steps=parent.warmup_steps,
            target_entropy_factor=parent.target_entropy_factor
        )
        
        # ğŸ¤– å½¢æ€å˜å¼‚
        if np.random.random() < self.mutation_rates['link_length']:
            # éšæœºä¿®æ”¹ä¸€ä¸ªé“¾èŠ‚é•¿åº¦
            idx = np.random.randint(len(mutant.link_lengths))
            mutant.link_lengths[idx] *= np.random.uniform(0.8, 1.2)
            mutant.link_lengths[idx] = max(20, min(120, mutant.link_lengths[idx]))
        
        if np.random.random() < self.mutation_rates['num_links']:
            # å¢åŠ æˆ–å‡å°‘é“¾èŠ‚æ•°é‡
            if np.random.random() < 0.5 and mutant.num_links > 2:
                # å‡å°‘é“¾èŠ‚
                mutant.num_links -= 1
                mutant.link_lengths = mutant.link_lengths[:-1]
            elif mutant.num_links < 6:
                # å¢åŠ é“¾èŠ‚
                mutant.num_links += 1
                new_length = np.random.uniform(40, 80)
                mutant.link_lengths.append(new_length)
        
        # ğŸ§  SACå‚æ•°å˜å¼‚
        # if np.random.random() < self.mutation_rates['sac_params']:
        #     # å­¦ä¹ ç‡å˜å¼‚
        #     mutant.lr *= np.random.lognormal(0, 0.3)
        #     mutant.lr = np.clip(mutant.lr, 1e-6, 1e-3)
            
        #     # Alphaå˜å¼‚
        #     mutant.alpha += np.random.normal(0, 0.1)
        #     mutant.alpha = np.clip(mutant.alpha, 0.01, 2.0)
            
        #     # Tauå˜å¼‚
        #     mutant.tau *= np.random.uniform(0.8, 1.2)
        #     mutant.tau = np.clip(mutant.tau, 0.001, 0.01)
        
        # # ğŸ¯ è®­ç»ƒå‚æ•°å˜å¼‚
        # if np.random.random() < self.mutation_rates['training_params']:
        #     # Batch sizeå˜å¼‚ (åœ¨2çš„å¹‚ä¸­é€‰æ‹©)
        #     batch_sizes = [32, 64, 128, 256]
        #     mutant.batch_size = np.random.choice(batch_sizes)
            
        #     # Warmup stepså˜å¼‚
        #     mutant.warmup_steps = int(mutant.warmup_steps * np.random.uniform(0.5, 2.0))
        #     mutant.warmup_steps = max(100, min(5000, mutant.warmup_steps))
        
        return mutant  # ä¿®å¤ï¼šå–æ¶ˆæ³¨é‡Šå¹¶ä¿®æ­£ç¼©è¿›
    
    def random_genotype(self) -> RobotGenotype:  # ä¿®å¤ç¼©è¿›é”™è¯¯
        """ç”ŸæˆéšæœºåŸºå› å‹"""
        num_links = np.random.randint(3, 7)
        link_lengths = [np.random.uniform(40, 100) for _ in range(num_links)]
        
        return RobotGenotype(
            num_links=num_links,
            link_lengths=link_lengths,
            lr=10 ** np.random.uniform(-6, -3),  # 1e-6 åˆ° 1e-3
            alpha=np.random.uniform(0.1, 1.0),
            tau=np.random.uniform(0.001, 0.01),
            gamma=np.random.uniform(0.95, 0.999),
            batch_size=np.random.choice([32, 64, 128, 256]),
            buffer_capacity=np.random.choice([5000, 10000, 20000]),
            warmup_steps=np.random.randint(500, 3000),
            target_entropy_factor=np.random.uniform(0.5, 1.2)
        )


# ğŸ§ª æµ‹è¯•å‡½æ•°
def test_map_elites_core():
    """æµ‹è¯•MAP-Elitesæ ¸å¿ƒç»„ä»¶"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•MAP-Elitesæ ¸å¿ƒç»„ä»¶\n")
    
    # 1. æµ‹è¯•åŸºå› å‹å’Œè¡¨å‹åˆ›å»º
    print("ğŸ“Š æµ‹è¯•1: åŸºå› å‹å’Œè¡¨å‹åˆ›å»º")
    genotype = RobotGenotype(num_links=4, link_lengths=[80, 60, 40, 30])
    phenotype = RobotPhenotype(avg_reward=50.0, success_rate=0.8, total_reach=210)
    print(f"âœ… åŸºå› å‹: {genotype.num_links}é“¾èŠ‚, é•¿åº¦={genotype.link_lengths}")
    print(f"âœ… è¡¨å‹: å¥–åŠ±={phenotype.avg_reward}, æˆåŠŸç‡={phenotype.success_rate}\n")
    
    # 2. æµ‹è¯•ä¸ªä½“åˆ›å»º
    print("ğŸ“Š æµ‹è¯•2: ä¸ªä½“åˆ›å»º")
    individual = Individual(genotype=genotype, phenotype=phenotype, fitness=50.0)
    print(f"âœ… ä¸ªä½“ID: {individual.individual_id}")
    print(f"âœ… é€‚åº”åº¦: {individual.fitness}\n")
    
    # 3. æµ‹è¯•ç‰¹å¾æå–å™¨
    print("ğŸ“Š æµ‹è¯•3: ç‰¹å¾æå–å™¨")
    extractor = FeatureExtractor()
    
    # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
    training_metrics = {
        'avg_reward': 45.0,
        'success_rate': 0.75,
        'min_distance': 25.0,
        'trajectory_smoothness': 0.6,
        'collision_rate': 0.1,
        'exploration_area': 300.0,
        'action_variance': 0.3,
        'learning_rate': 0.8
    }
    
    robot_config = {
        'num_links': 4,
        'link_lengths': [80, 60, 40, 30]
    }
    
    extracted_phenotype = extractor.extract_from_training_data(training_metrics, robot_config)
    print(f"âœ… æå–çš„è¡¨å‹: å¥–åŠ±={extracted_phenotype.avg_reward}, ä¼¸å±•={extracted_phenotype.total_reach}")
    
    # ç‰¹å¾ç¦»æ•£åŒ–
    coords = extractor.discretize_features(extracted_phenotype)
    print(f"âœ… ç¦»æ•£åŒ–åæ ‡: {coords}\n")
    
    # 4. æµ‹è¯•å­˜æ¡£
    print("ğŸ“Š æµ‹è¯•4: MAP-Eliteså­˜æ¡£")
    archive = MAPElitesArchive()
    
    # æ·»åŠ ä¸ªä½“åˆ°å­˜æ¡£
    test_individual = Individual(
        genotype=genotype, 
        phenotype=extracted_phenotype, 
        fitness=extracted_phenotype.avg_reward
    )
    
    success = archive.add_individual(test_individual)
    print(f"âœ… ä¸ªä½“æ·»åŠ æˆåŠŸ: {success}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = archive.get_statistics()
    print(f"âœ… å­˜æ¡£ç»Ÿè®¡: {stats}\n")
    
    # 5. æµ‹è¯•å˜å¼‚å™¨
    print("ğŸ“Š æµ‹è¯•5: å˜å¼‚å™¨")
    mutator = RobotMutator()
    
    # ç”ŸæˆéšæœºåŸºå› å‹
    random_genotype = mutator.random_genotype()
    print(f"âœ… éšæœºåŸºå› å‹: {random_genotype.num_links}é“¾èŠ‚, lr={random_genotype.lr:.2e}")
    
    # å˜å¼‚åŸºå› å‹
    mutant_genotype = mutator.mutate(genotype)
    print(f"âœ… å˜å¼‚åŸºå› å‹: {mutant_genotype.num_links}é“¾èŠ‚, é•¿åº¦={[f'{x:.1f}' for x in mutant_genotype.link_lengths]}")
    
    # 6. æµ‹è¯•å¤šä¸ªä¸ªä½“
    print("\nğŸ“Š æµ‹è¯•6: å¤šä¸ªä¸ªä½“å­˜æ¡£")
    for i in range(5):
        rand_genotype = mutator.random_genotype()
        rand_phenotype = RobotPhenotype(
            avg_reward=np.random.uniform(-50, 100),
            success_rate=np.random.uniform(0, 1),
            total_reach=sum(rand_genotype.link_lengths)
        )
        rand_individual = Individual(
            genotype=rand_genotype,
            phenotype=rand_phenotype,
            fitness=rand_phenotype.avg_reward,
            generation=1
        )
        archive.add_individual(rand_individual)
    
    final_stats = archive.get_statistics()
    print(f"âœ… æœ€ç»ˆå­˜æ¡£ç»Ÿè®¡: {final_stats}")
    
    # æµ‹è¯•éšæœºç²¾è‹±é€‰æ‹©
    print("\nğŸ“Š æµ‹è¯•7: éšæœºç²¾è‹±é€‰æ‹©")
    for i in range(3):
        elite = archive.get_random_elite()
        if elite:
            print(f"   éšæœºç²¾è‹±{i+1}: ID={elite.individual_id}, é€‚åº”åº¦={elite.fitness:.2f}")
        else:
            print(f"   éšæœºç²¾è‹±{i+1}: æ— ç²¾è‹±ä¸ªä½“")
    
    # è·å–æœ€ä½³ä¸ªä½“
    best = archive.get_best_individual()
    if best:
        print(f"âœ… æœ€ä½³ä¸ªä½“: ID={best.individual_id}, é€‚åº”åº¦={best.fitness:.2f}")
    
    # 7. æµ‹è¯•å­˜æ¡£ä¿å­˜
    print("\nğŸ“Š æµ‹è¯•8: å­˜æ¡£ä¿å­˜")
    archive.save_archive("test_archive.pkl")
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    test_map_elites_core()