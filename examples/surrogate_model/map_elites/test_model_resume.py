#!/usr/bin/env python3
"""
æµ‹è¯•å…±äº«PPOæ¨¡å‹çš„ä¿å­˜å’Œæ¢å¤åŠŸèƒ½
"""

import os
import sys
import torch
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '../../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from shared_ppo_trainer import SharedPPOTrainer

def test_model_resume():
    """æµ‹è¯•æ¨¡å‹æ¢å¤åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å…±äº«PPOæ¨¡å‹çš„ä¿å­˜å’Œæ¢å¤åŠŸèƒ½")
    print("=" * 60)
    
    # é…ç½®
    model_config = {
        'observation_dim': 14,
        'action_dim': 3,
        'hidden_dim': 256
    }
    
    training_config = {
        'lr': 2e-4,
        'buffer_size': 5000,
        'min_batch_size': 100,
        'model_path': './test_resume_model.pth',
        'update_interval': 10
    }
    
    print(f"ğŸ“Š é…ç½®ä¿¡æ¯:")
    print(f"   æ¨¡å‹è·¯å¾„: {training_config['model_path']}")
    print(f"   è§‚å¯Ÿç»´åº¦: {model_config['observation_dim']}")
    print(f"   åŠ¨ä½œç»´åº¦: {model_config['action_dim']}")
    
    # ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºæ–°æ¨¡å‹å¹¶è®­ç»ƒä¸€æ®µæ—¶é—´
    print(f"\nğŸš€ ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºæ–°æ¨¡å‹")
    
    # åˆ é™¤å·²æœ‰çš„æ¨¡å‹æ–‡ä»¶
    if os.path.exists(training_config['model_path']):
        os.remove(training_config['model_path'])
        print(f"ğŸ—‘ï¸ åˆ é™¤å·²æœ‰æ¨¡å‹æ–‡ä»¶")
    
    trainer1 = SharedPPOTrainer(model_config, training_config)
    
    try:
        trainer1.start_training()
        print(f"âœ… ç¬¬ä¸€ä¸ªè®­ç»ƒå™¨å¯åŠ¨æˆåŠŸ")
        
        # æ·»åŠ ä¸€äº›è™šæ‹Ÿç»éªŒ
        print(f"ğŸ“ æ·»åŠ è™šæ‹Ÿç»éªŒ...")
        for i in range(200):  # æ·»åŠ 200ä¸ªç»éªŒ
            fake_experience = {
                'observation': torch.randn(model_config['observation_dim']).numpy(),
                'action': torch.randn(model_config['action_dim']).numpy(),
                'reward': float(torch.randn(1).item()),
                'next_observation': torch.randn(model_config['observation_dim']).numpy(),
                'done': False,
                'worker_id': 0,
                'robot_config': {'num_links': 3, 'link_lengths': [90.0, 90.0, 90.0]}
            }
            trainer1.add_experience(fake_experience)
        
        print(f"â³ ç­‰å¾…æ¨¡å‹è®­ç»ƒå’Œä¿å­˜...")
        time.sleep(8)  # ç­‰å¾…è®­ç»ƒè¿›ç¨‹å¤„ç†ç»éªŒå¹¶ä¿å­˜æ¨¡å‹
        
    finally:
        trainer1.stop_training()
        print(f"ğŸ›‘ ç¬¬ä¸€ä¸ªè®­ç»ƒå™¨å·²åœæ­¢")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¢«ä¿å­˜
    if os.path.exists(training_config['model_path']):
        print(f"âœ… æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜: {training_config['model_path']}")
        
        # æ£€æŸ¥æ¨¡å‹å†…å®¹
        try:
            checkpoint = torch.load(training_config['model_path'], map_location='cpu')
            print(f"ğŸ“Š æ¨¡å‹æ£€æŸ¥ç‚¹ä¿¡æ¯:")
            print(f"   åŒ…å«é”®: {list(checkpoint.keys())}")
            if 'update_count' in checkpoint:
                print(f"   æ›´æ–°æ¬¡æ•°: {checkpoint['update_count']}")
            print(f"   Actorå‚æ•°æ•°é‡: {len(checkpoint['actor'])}")
            print(f"   Criticå‚æ•°æ•°é‡: {len(checkpoint['critic'])}")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–æ¨¡å‹æ–‡ä»¶: {e}")
    else:
        print(f"âŒ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {training_config['model_path']}")
        return False
    
    # ç¬¬äºŒé˜¶æ®µï¼šåŠ è½½å·²æœ‰æ¨¡å‹å¹¶ç»§ç»­è®­ç»ƒ
    print(f"\nğŸ”„ ç¬¬äºŒé˜¶æ®µï¼šåŠ è½½å·²æœ‰æ¨¡å‹ç»§ç»­è®­ç»ƒ")
    
    trainer2 = SharedPPOTrainer(model_config, training_config)
    
    try:
        trainer2.start_training()
        print(f"âœ… ç¬¬äºŒä¸ªè®­ç»ƒå™¨å¯åŠ¨æˆåŠŸï¼ˆåº”è¯¥åŠ è½½äº†å·²æœ‰æ¨¡å‹ï¼‰")
        
        # å†æ·»åŠ ä¸€äº›ç»éªŒ
        print(f"ğŸ“ æ·»åŠ æ›´å¤šè™šæ‹Ÿç»éªŒ...")
        for i in range(100):  # å†æ·»åŠ 100ä¸ªç»éªŒ
            fake_experience = {
                'observation': torch.randn(model_config['observation_dim']).numpy(),
                'action': torch.randn(model_config['action_dim']).numpy(),
                'reward': float(torch.randn(1).item()),
                'next_observation': torch.randn(model_config['observation_dim']).numpy(),
                'done': False,
                'worker_id': 1,
                'robot_config': {'num_links': 4, 'link_lengths': [80.0, 80.0, 80.0, 80.0]}
            }
            trainer2.add_experience(fake_experience)
        
        print(f"â³ ç­‰å¾…æ¨¡å‹ç»§ç»­è®­ç»ƒ...")
        time.sleep(5)
        
    finally:
        trainer2.stop_training()
        print(f"ğŸ›‘ ç¬¬äºŒä¸ªè®­ç»ƒå™¨å·²åœæ­¢")
    
    # æœ€ç»ˆæ£€æŸ¥
    if os.path.exists(training_config['model_path']):
        try:
            final_checkpoint = torch.load(training_config['model_path'], map_location='cpu')
            final_update_count = final_checkpoint.get('update_count', 0)
            print(f"ğŸ‰ æœ€ç»ˆæ¨¡å‹æ›´æ–°æ¬¡æ•°: {final_update_count}")
            print(f"âœ… æ¨¡å‹æ¢å¤åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼")
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            os.remove(training_config['model_path'])
            print(f"ğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶")
            
            return True
        except Exception as e:
            print(f"âŒ è¯»å–æœ€ç»ˆæ¨¡å‹å¤±è´¥: {e}")
            return False
    else:
        print(f"âŒ æœ€ç»ˆæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°")
        return False

if __name__ == "__main__":
    success = test_model_resume()
    if success:
        print(f"\nğŸ‰ æ¨¡å‹æ¢å¤åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâŒ æ¨¡å‹æ¢å¤åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼")
