import sys
import os
import numpy as np
import torch
from typing import Dict, Any, Optional
import time

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥ç°æœ‰æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from map_elites_core import Individual, RobotGenotype, RobotPhenotype, FeatureExtractor

# ğŸ†• å¯¼å…¥æ–°çš„é—ä¼ ç®—æ³•fitnessè¯„ä¼°å™¨
from genetic_fitness_evaluator import GeneticFitnessEvaluator
from fitness_manager import FitnessManager
# å¯¼å…¥çœŸå®è®­ç»ƒæ¥å£
try:
    from enhanced_train_interface import MAPElitesTrainingInterface
    REAL_TRAINING_AVAILABLE = True
except ImportError:
    print("âš ï¸  çœŸå®è®­ç»ƒæ¥å£ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ")
    REAL_TRAINING_AVAILABLE = False


class MAPElitesTrainingAdapter:
    """MAP-Elitesä¸SACè®­ç»ƒçš„é€‚é…å™¨ - é›†æˆé—ä¼ ç®—æ³•Fitnessè¯„ä¼°ç³»ç»Ÿ"""
    
    def __init__(self, base_args, base_save_dir: str = "./map_elites_experiments", 
                 use_real_training: bool = True,
                 enable_rendering: bool = False,  # ğŸ†• æ§åˆ¶æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–
                 silent_mode: bool = True,        # ğŸ†• æ§åˆ¶æ˜¯å¦é™é»˜
                 use_genetic_fitness: bool = True, # ğŸ†• æ§åˆ¶æ˜¯å¦ä½¿ç”¨æ–°fitnessç³»ç»Ÿ
                 shared_ppo_trainer=None):        # ğŸ†• å…±äº«PPOè®­ç»ƒå™¨
        self.base_args = base_args
        self.base_save_dir = base_save_dir
        self.use_real_training = use_real_training and REAL_TRAINING_AVAILABLE
        self.enable_rendering = enable_rendering
        self.silent_mode = silent_mode
        self.use_genetic_fitness = use_genetic_fitness
        self.shared_ppo_trainer = shared_ppo_trainer  # ğŸ†• ä¿å­˜å…±äº«PPOè®­ç»ƒå™¨å¼•ç”¨
        
        os.makedirs(base_save_dir, exist_ok=True)
        
        # ğŸ†• åˆå§‹åŒ–fitnessè¯„ä¼°ç³»ç»Ÿ
        if self.use_genetic_fitness:
            try:
                self.fitness_evaluator = GeneticFitnessEvaluator()
                print("ğŸ¯ ä½¿ç”¨é—ä¼ ç®—æ³•åˆ†å±‚Fitnessè¯„ä¼°ç³»ç»Ÿ")
            except Exception as e:
                print(f"âš ï¸  é—ä¼ ç®—æ³•Fitnessè¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                print("ğŸ”„ å›é€€åˆ°ä¼ ç»ŸFitnessè¯„ä¼°")
                self.fitness_evaluator = None
                self.use_genetic_fitness = False
        else:
            self.fitness_evaluator = None
            print("ğŸ¯ ä½¿ç”¨ä¼ ç»Ÿå¹³å‡å¥–åŠ±Fitnessè¯„ä¼°")
        
        # ç‰¹å¾æå–å™¨
        self.feature_extractor = FeatureExtractor()
        
        # ğŸ”§ ä¼˜åŒ–ï¼šå¯é…ç½®çš„è®­ç»ƒæ¥å£
        if self.use_real_training:
            self.training_interface = MAPElitesTrainingInterface(
                silent_mode=silent_mode,
                enable_rendering=enable_rendering
            )
            print(f"ğŸ”§ MAP-Elitesè®­ç»ƒé€‚é…å™¨å·²åˆå§‹åŒ– (ä½¿ç”¨enhanced_train.py)")
            print(f"   ğŸ¨ æ¸²æŸ“: {'å¯ç”¨' if enable_rendering else 'ç¦ç”¨'}")
            print(f"   ğŸ”‡ é™é»˜: {'å¯ç”¨' if silent_mode else 'ç¦ç”¨'}")
        else:
            print("ğŸ”§ MAP-Elitesè®­ç»ƒé€‚é…å™¨å·²åˆå§‹åŒ– (ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ)")


        self.fitness_manager = FitnessManager(
            use_genetic_fitness=use_genetic_fitness,
            primary_strategy='episodes' if use_real_training else 'genetic'
        )


    def evaluate_individual(self, individual: Individual, training_steps: int = 5000) -> Individual:
        """è¯„ä¼°å•ä¸ªä¸ªä½“ - ä½¿ç”¨ç»Ÿä¸€çš„FitnessManager"""
        print(f"\nğŸ§¬ è¯„ä¼°ä¸ªä½“ {individual.individual_id}")
        print(f"ğŸ¤– åŸºå› å‹: num_links={individual.genotype.num_links}, "
            f"link_lengths={[f'{x:.1f}' for x in individual.genotype.link_lengths]}")
        print(f"ğŸ§  SACå‚æ•°: lr={individual.genotype.lr:.2e}, alpha={individual.genotype.alpha:.3f}")
        print(f"   æ€»é•¿åº¦: {sum(individual.genotype.link_lengths):.1f}px")
        
        # 1. æ ¹æ®åŸºå› å‹åˆ›å»ºè®­ç»ƒå‚æ•°
        training_args = self._genotype_to_training_args(individual.genotype, training_steps)
        
        # 2. è¿è¡Œè®­ç»ƒ
        start_time = time.time()
        if self.use_real_training:
            print(f"   ğŸ¯ ä½¿ç”¨enhanced_train.pyè¿›è¡ŒçœŸå®è®­ç»ƒ ({training_steps} steps)")
            try:
                training_metrics = self.training_interface.train_individual(training_args)
            except Exception as e:
                print(f"   âŒ çœŸå®è®­ç»ƒå¤±è´¥: {e}")
                print(f"   ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿè®­ç»ƒ")
                training_metrics = self._run_simulated_training(training_args)
        else:
            print(f"   ğŸ² ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ ({training_steps} steps)")
            training_metrics = self._run_simulated_training(training_args)
        
        training_time = time.time() - start_time
        
        # 3. æå–è¡¨å‹ç‰¹å¾ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼Œç”¨äºå…¼å®¹æ€§ï¼‰
        robot_config = {
            'num_links': individual.genotype.num_links,
            'link_lengths': individual.genotype.link_lengths,
            'lr': individual.genotype.lr,
            'alpha': individual.genotype.alpha
        }
        
        phenotype = self.feature_extractor.extract_from_training_data(training_metrics, robot_config)
        
        # 4. ğŸ†• ä½¿ç”¨ç»Ÿä¸€çš„FitnessManagerè®¡ç®—fitness
        if not hasattr(self, 'fitness_manager'):
            # å»¶è¿Ÿåˆå§‹åŒ–FitnessManager
            from fitness_manager import FitnessManager
            self.fitness_manager = FitnessManager(
                use_genetic_fitness=self.use_genetic_fitness,
                primary_strategy='episodes' if self.use_real_training else 'genetic'
            )
        
        try:
            # ğŸ¯ å‡†å¤‡å®Œæ•´çš„è®­ç»ƒç»“æœæ•°æ®
            complete_training_data = self._prepare_training_data_for_fitness(
                training_metrics, phenotype, training_time
            )
            
            # ğŸ¯ ä½¿ç”¨FitnessManagerç»Ÿä¸€è®¡ç®—fitness
            fitness_result = self.fitness_manager.calculate_fitness(
                individual=individual, 
                training_results=complete_training_data
            )
            # æ›´æ–°ä¸ªä½“
            individual.phenotype = phenotype
            individual.fitness = fitness_result['fitness']
            individual.fitness_details = fitness_result['details']
            
            # ğŸ¯ ç»Ÿä¸€çš„ç»“æœæ˜¾ç¤º
            print(f"âœ… è¯„ä¼°å®Œæˆ:")
            print(f"   Fitnessæ–¹æ³•: {fitness_result['details']['method']}")
            print(f"   æœ€ç»ˆFitness: {individual.fitness:.3f}")
            print(f"   è¯„ä¼°ç±»åˆ«: {fitness_result['details']['category']}")
            print(f"   è¯„ä¼°ç­–ç•¥: {fitness_result['details']['strategy']}")
            print(f"   åŸå› : {fitness_result['details']['reason']}")
            
            # ğŸ¯ æ˜¾ç¤ºå¯¹æ¯”ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if 'avg_reward' in fitness_result['details']:
                print(f"   ä¼ ç»Ÿfitness (avg_reward): {fitness_result['details']['avg_reward']:.2f}")
            if 'success_rate' in fitness_result['details']:
                print(f"   æˆåŠŸç‡: {fitness_result['details']['success_rate']:.1%}")
            
        except Exception as e:
            print(f"âŒ FitnessManagerè®¡ç®—å¤±è´¥: {e}")
            print(f"ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿå¤‡ç”¨æ–¹æ¡ˆ")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ä¼ ç»Ÿfitness
            individual.phenotype = phenotype
            individual.fitness = phenotype.avg_reward
            individual.fitness_details = {
                'method': 'fallback',
                'category': 'error_recovery',
                'strategy': 'avg_reward_fallback',
                'reason': f'FitnessManagerå¤±è´¥ï¼Œä½¿ç”¨avg_reward: {phenotype.avg_reward:.2f}',
                'error': str(e)
            }
            
            print(f"âœ… å¤‡ç”¨è¯„ä¼°å®Œæˆ:")
            print(f"   Fitness (avg_reward): {individual.fitness:.2f}")
        
        print(f"   è®­ç»ƒè€—æ—¶: {training_time:.1f}s")
        
        return individual

    def _prepare_training_data_for_fitness(self, training_metrics, phenotype, training_time):
        """å‡†å¤‡ç”¨äºfitnessè®¡ç®—çš„å®Œæ•´è®­ç»ƒæ•°æ®"""
        
        # ğŸ¯ æ£€æŸ¥æ˜¯å¦æœ‰episodesç»“æœï¼ˆæ¥è‡ªenhanced_train.pyçš„æ–°æ ¼å¼ï¼‰
        if isinstance(training_metrics, dict) and 'episode_results' in training_metrics:
            # æ–°çš„episodes-basedæ•°æ®æ ¼å¼
            return {
                'episodes_completed': training_metrics.get('episodes_completed', 0),
                'success_rate': training_metrics.get('success_rate', 0.0),
                'avg_best_distance': training_metrics.get('avg_best_distance', float('inf')),
                'learning_progress': training_metrics.get('learning_progress', 0.0),
                'avg_steps_to_best': training_metrics.get('avg_steps_to_best', 120000),
                'total_training_time': training_metrics.get('total_training_time', training_time),
                'episode_details': training_metrics.get('episode_details', []),
                'episode_results': training_metrics['episode_results'],
                # å…¼å®¹æ€§æ•°æ®
                'avg_reward': phenotype.avg_reward,
                'phenotype': phenotype
            }
        
        # ğŸ¯ æ£€æŸ¥æ˜¯å¦æœ‰è¯¦ç»†çš„è®­ç»ƒæŒ‡æ ‡ï¼ˆæ¨¡æ‹Ÿè®­ç»ƒæˆ–æ—§æ ¼å¼ï¼‰
        elif isinstance(training_metrics, dict):
            return {
                'success_rate': training_metrics.get('success_rate', phenotype.success_rate),
                'avg_reward': training_metrics.get('avg_reward', phenotype.avg_reward),
                'max_distance': training_metrics.get('max_distance', 0),
                'efficiency': training_metrics.get('efficiency', 0),
                'near_success_rate': training_metrics.get('near_success_rate', phenotype.success_rate + 0.1),
                'training_time': training_time,
                # åŸå§‹æ•°æ®
                'raw_training_metrics': training_metrics,
                'phenotype': phenotype
            }
        
        # ğŸ¯ æœ€ç®€å•çš„æ•°æ®æ ¼å¼ï¼ˆåªæœ‰phenotypeï¼‰
        else:
            return {
                'avg_reward': phenotype.avg_reward,
                'success_rate': phenotype.success_rate,
                'training_time': training_time,
                'phenotype': phenotype
            }
    
    # def evaluate_individual(self, individual: Individual, training_steps: int = 5000) -> Individual:
    #     """è¯„ä¼°å•ä¸ªä¸ªä½“ - æ”¯æŒæ–°æ—§ä¸¤ç§fitnessè¯„ä¼°ç³»ç»Ÿ"""
    #     print(f"\nğŸ§¬ è¯„ä¼°ä¸ªä½“ {individual.individual_id}")
    #     print(f"ğŸ¤– åŸºå› å‹: num_links={individual.genotype.num_links}, "
    #           f"link_lengths={[f'{x:.1f}' for x in individual.genotype.link_lengths]}")
    #     print(f"ğŸ§  SACå‚æ•°: lr={individual.genotype.lr:.2e}, alpha={individual.genotype.alpha:.3f}")
    #     print(f"   æ€»é•¿åº¦: {sum(individual.genotype.link_lengths):.1f}px")
        
    #     # 1. æ ¹æ®åŸºå› å‹åˆ›å»ºè®­ç»ƒå‚æ•°
    #     training_args = self._genotype_to_training_args(individual.genotype, training_steps)
        
    #     # 2. è¿è¡Œè®­ç»ƒ
    #     start_time = time.time()
    #     if self.use_real_training:
    #         print(f"   ğŸ¯ ä½¿ç”¨enhanced_train.pyè¿›è¡ŒçœŸå®è®­ç»ƒ ({training_steps} steps)")
    #         try:
    #             training_metrics = self.training_interface.train_individual(training_args)
    #         except Exception as e:
    #             print(f"   âŒ çœŸå®è®­ç»ƒå¤±è´¥: {e}")
    #             print(f"   ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿè®­ç»ƒ")
    #             training_metrics = self._run_simulated_training(training_args)
    #     else:
    #         print(f"   ğŸ² ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ ({training_steps} steps)")
    #         training_metrics = self._run_simulated_training(training_args)
        
    #     training_time = time.time() - start_time
        
    #     # 3. æå–è¡¨å‹ç‰¹å¾
    #     robot_config = {
    #         'num_links': individual.genotype.num_links,
    #         'link_lengths': individual.genotype.link_lengths,
    #         'lr': individual.genotype.lr,
    #         'alpha': individual.genotype.alpha
    #     }
        
    #     phenotype = self.feature_extractor.extract_from_training_data(training_metrics, robot_config)
        
    #     # 4. ğŸ†• Fitnessè¯„ä¼° - æ–°æ—§ç³»ç»Ÿé€‰æ‹©
    #     if self.use_genetic_fitness and self.fitness_evaluator:
    #         # ğŸ¯ ä½¿ç”¨æ–°çš„é—ä¼ ç®—æ³•fitnessè¯„ä¼°ç³»ç»Ÿ
    #         training_performance = {
    #             'success_rate': phenotype.success_rate,
    #             'avg_reward': phenotype.avg_reward,
    #             'max_distance_covered': training_metrics.get('max_distance', 0),
    #             'efficiency': training_metrics.get('efficiency', 0),
    #             'near_success_rate': training_metrics.get('near_success_rate', 0)
    #         }
            
    #         try:
    #             fitness_result = self.fitness_evaluator.evaluate_fitness(
    #                 link_lengths=individual.genotype.link_lengths,
    #                 training_performance=training_performance
    #             )
                
    #             # æ›´æ–°ä¸ªä½“
    #             individual.phenotype = phenotype
    #             individual.fitness = fitness_result['fitness']
    #             individual.fitness_details = fitness_result  # ğŸ†• ä¿å­˜è¯¦ç»†åˆ†æ
                
    #             print(f"âœ… è¯„ä¼°å®Œæˆ (æ–°ç³»ç»Ÿ):")
    #             print(f"   æ—§fitness (avg_reward): {phenotype.avg_reward:.2f}")
    #             print(f"   æ–°fitness (åˆ†å±‚è¯„ä¼°): {individual.fitness:.3f}")
    #             print(f"   è¯„ä¼°ç±»åˆ«: {fitness_result['category']}")
    #             print(f"   è¯„ä¼°ç­–ç•¥: {fitness_result['strategy']}")
    #             print(f"   åŸå› : {fitness_result['reason']}")
                
    #         except Exception as e:
    #             print(f"   âš ï¸ æ–°fitnessç³»ç»Ÿè¯„ä¼°å¤±è´¥: {e}")
    #             print(f"   ğŸ”„ å›é€€åˆ°ä¼ ç»Ÿfitnessè¯„ä¼°")
    #             individual.phenotype = phenotype
    #             individual.fitness = phenotype.avg_reward
                
    #     else:
    #         # ğŸ”„ ä½¿ç”¨åŸæœ‰çš„ç®€å•fitnessè¯„ä¼°
    #         individual.phenotype = phenotype
    #         individual.fitness = phenotype.avg_reward
            
    #         print(f"âœ… è¯„ä¼°å®Œæˆ (ä¼ ç»Ÿç³»ç»Ÿ):")
    #         print(f"   Fitness (avg_reward): {individual.fitness:.2f}")
        
    #     print(f"   æˆåŠŸç‡: {phenotype.success_rate:.2f}, è€—æ—¶: {training_time:.1f}s")
        
    #     return individual
    
    def _genotype_to_training_args(self, genotype: RobotGenotype, training_steps: int):
        """å°†åŸºå› å‹è½¬æ¢ä¸ºè®­ç»ƒå‚æ•°"""
        # åˆ›å»ºå‚æ•°å¯¹è±¡
        args = type('Args', (), {})()
        
        # å¤åˆ¶åŸºç¡€å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
        if hasattr(self.base_args, '__dict__'):
            for key, value in vars(self.base_args).items():
                setattr(args, key, value)
        
        # ğŸ¤– è®¾ç½®æœºå™¨äººå½¢æ€å‚æ•°
        args.num_joints = genotype.num_links
        args.link_lengths = genotype.link_lengths
        
        # ğŸ§  è®¾ç½®SACè¶…å‚æ•°
        args.lr = genotype.lr
        args.alpha = genotype.alpha
        args.tau = genotype.tau
        args.gamma = genotype.gamma
        args.batch_size = genotype.batch_size
        args.buffer_capacity = genotype.buffer_capacity
        args.buffer_size = genotype.buffer_capacity  # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ ç¼ºå¤±çš„buffer_sizeå‚æ•°
        args.warmup_steps = genotype.warmup_steps
        args.target_entropy_factor = genotype.target_entropy_factor
        
        # ğŸ¯ è®¾ç½®è®­ç»ƒæ­¥æ•°
        args.total_steps = training_steps
        
        # ğŸ“ è®¾ç½®ä¿å­˜ç›®å½•
        individual_dir = os.path.join(self.base_save_dir, f"individual_{int(time.time() * 1000) % 100000}")
        args.save_dir = individual_dir
        
        # ğŸ”§ è®¾ç½®å…¶ä»–è®­ç»ƒå‚æ•°
        args.update_frequency = getattr(self.base_args, 'update_frequency', 1)
        args.num_processes = 1  # ğŸ”§ å¼ºåˆ¶å•è¿›ç¨‹ï¼Œé¿å…å¤šè¿›ç¨‹é€šä¿¡é—®é¢˜
        args.seed = getattr(self.base_args, 'seed', 42)
        
        # ğŸ”§ æ·»åŠ æ›´å¤šå¿…éœ€å‚æ•°
        args.ppo_epochs = 10
        args.clip_epsilon = 0.2
        args.entropy_coef = 0.01
        args.value_coef = 0.5
        args.max_grad_norm = 0.5
        
        # ğŸ†• æ¸²æŸ“å’Œé™é»˜æ§åˆ¶
        args.render = self.enable_rendering
        args.silent = self.silent_mode
        
        return args
    
    def _run_simulated_training(self, args) -> Dict[str, Any]:
        """è¿è¡Œæ¨¡æ‹Ÿè®­ç»ƒï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰- å¢å¼ºç‰ˆï¼Œæ”¯æŒæ–°fitnessç³»ç»Ÿ"""
        # åŸºäºåŸºå› å‹é¢„æµ‹å¤§è‡´æ€§èƒ½
        num_links = getattr(args, 'num_joints', 4)
        link_lengths = getattr(args, 'link_lengths', [80.0] * num_links)
        
        # ç®€å•çš„å¯å‘å¼è¯„ä¼°
        total_reach = sum(link_lengths)
        complexity_penalty = abs(num_links - 4) * 10  # 4é“¾èŠ‚æœ€ä¼˜
        length_variance_penalty = np.var(link_lengths) / 10 if len(link_lengths) > 1 else 0
        
        # åŸºäºè¶…å‚æ•°çš„æ€§èƒ½é¢„æµ‹
        lr_factor = 1.0 if 1e-5 <= args.lr <= 1e-3 else 0.5
        alpha_factor = 1.0 if 0.1 <= args.alpha <= 0.5 else 0.7
        
        base_reward = min(100, total_reach / 5) - complexity_penalty - length_variance_penalty
        base_reward *= lr_factor * alpha_factor
        
        # æ·»åŠ éšæœºæ€§
        noise = np.random.normal(0, 15)
        final_reward = base_reward + noise
        
        # ğŸ†• ä¸ºæ–°fitnessç³»ç»Ÿæ·»åŠ æ›´å¤šæŒ‡æ ‡
        success_rate = max(0, min(1, (final_reward + 50) / 150))
        
        # åŸºäºæœºå™¨äººé•¿åº¦ä¼°ç®—æœ€å¤§è·ç¦»è¦†ç›–
        max_distance = total_reach * success_rate * np.random.uniform(0.6, 0.9)
        
        # ä¼°ç®—æ•ˆç‡ï¼ˆåŸºäºæˆåŠŸç‡å’Œå¤æ‚åº¦ï¼‰
        efficiency = success_rate * (1.0 - complexity_penalty / 50) * np.random.uniform(0.7, 1.0)
        efficiency = max(0, min(1, efficiency))
        
        # ä¼°ç®—æ¥è¿‘æˆåŠŸç‡ï¼ˆé€šå¸¸æ¯”æˆåŠŸç‡é«˜ä¸€äº›ï¼‰
        near_success_rate = min(1.0, success_rate + np.random.uniform(0.1, 0.3))
        
        return {
            'avg_reward': final_reward,
            'success_rate': success_rate,
            'min_distance': max(10, 200 - final_reward * 2),
            'trajectory_smoothness': np.random.uniform(0.3, 0.8),
            'collision_rate': np.random.uniform(0.0, 0.3),
            'exploration_area': np.random.uniform(100, 500),
            'action_variance': np.random.uniform(0.1, 0.5),
            'learning_rate': np.random.uniform(0.1, 0.9),
            'final_critic_loss': np.random.uniform(0.1, 5.0),
            'final_actor_loss': np.random.uniform(0.1, 2.0),
            'training_stability': np.random.uniform(0.3, 0.9),
            # ğŸ†• æ–°fitnessç³»ç»Ÿéœ€è¦çš„æŒ‡æ ‡
            'max_distance': max_distance,
            'efficiency': efficiency,
            'near_success_rate': near_success_rate
        }


# ğŸ§ª æµ‹è¯•å‡½æ•°
def test_training_adapter():
    """æµ‹è¯•è®­ç»ƒé€‚é…å™¨ - åŒ…æ‹¬æ–°æ—§fitnessç³»ç»Ÿ"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•MAP-Elitesè®­ç»ƒé€‚é…å™¨ (æ–°æ—§fitnessç³»ç»Ÿå¯¹æ¯”)\n")
    
    # 1. åˆ›å»ºæ¨¡æ‹Ÿçš„åŸºç¡€å‚æ•°
    print("ğŸ“Š æµ‹è¯•1: åˆ›å»ºåŸºç¡€å‚æ•°")
    import argparse
    base_args = argparse.Namespace()
    base_args.env_type = 'reacher2d'
    base_args.num_processes = 1
    base_args.seed = 42
    base_args.save_dir = './test_map_elites_results'
    base_args.lr = 1e-4
    base_args.alpha = 0.2
    base_args.tau = 0.005
    base_args.gamma = 0.99
    base_args.update_frequency = 1
    print(f"âœ… åŸºç¡€å‚æ•°åˆ›å»ºå®Œæˆ: {base_args.env_type}")
    
    # 2. æµ‹è¯•æ–°æ—§ä¸¤ç§fitnessç³»ç»Ÿ
    fitness_modes = [
        (False, "ä¼ ç»ŸFitness (avg_reward)"),
        (True, "é—ä¼ ç®—æ³•åˆ†å±‚Fitness")
    ]
    
    from map_elites_core import RobotGenotype, RobotPhenotype, Individual
    
    # åˆ›å»ºæµ‹è¯•ä¸ªä½“
    test_genotypes = [
        RobotGenotype(num_links=2, link_lengths=[40, 40], lr=2e-4, alpha=0.25),    # çŸ­æœºå™¨äºº
        RobotGenotype(num_links=3, link_lengths=[60, 60, 60], lr=2e-4, alpha=0.25), # ä¸­ç­‰æœºå™¨äºº  
        RobotGenotype(num_links=4, link_lengths=[80, 80, 80, 80], lr=2e-4, alpha=0.25) # é•¿æœºå™¨äºº
    ]
    
    results = []
    
    for use_genetic, mode_name in fitness_modes:
        print(f"\n{'='*50}")
        print(f"ğŸ“Š æµ‹è¯•æ¨¡å¼: {mode_name}")
        print(f"{'='*50}")
        
        try:
            adapter = MAPElitesTrainingAdapter(
                base_args, 
                "./test_adapter_results", 
                use_real_training=False,  # ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒè¿›è¡Œå¿«é€Ÿæµ‹è¯•
                use_genetic_fitness=use_genetic
            )
            
            mode_results = []
            
            for i, genotype in enumerate(test_genotypes):
                print(f"\nğŸ¤– æµ‹è¯•æœºå™¨äºº {i+1}: {genotype.num_links}é“¾èŠ‚, æ€»é•¿{sum(genotype.link_lengths):.1f}px")
                
                individual = Individual(
                    genotype=genotype,
                    phenotype=RobotPhenotype()
                )
                
                # è¯„ä¼°ä¸ªä½“
                start_time = time.time()
                evaluated = adapter.evaluate_individual(individual, training_steps=100)
                end_time = time.time()
                
                result = {
                    'genotype': genotype,
                    'fitness': evaluated.fitness,
                    'success_rate': evaluated.phenotype.success_rate,
                    'total_reach': evaluated.phenotype.total_reach,
                    'evaluation_time': end_time - start_time,
                    'fitness_details': getattr(evaluated, 'fitness_details', None)
                }
                
                mode_results.append(result)
                
                print(f"   é€‚åº”åº¦: {evaluated.fitness:.3f}")
                print(f"   æˆåŠŸç‡: {evaluated.phenotype.success_rate:.2f}")
                if hasattr(evaluated, 'fitness_details') and evaluated.fitness_details:
                    print(f"   ç±»åˆ«: {evaluated.fitness_details['category']}")
                    print(f"   ç­–ç•¥: {evaluated.fitness_details['strategy']}")
            
            results.append((mode_name, mode_results))
            
        except Exception as e:
            print(f"âŒ {mode_name} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # 3. å¯¹æ¯”åˆ†æ
    if len(results) >= 2:
        print(f"\n{'='*60}")
        print("ğŸ“Š æ–°æ—§Fitnessç³»ç»Ÿå¯¹æ¯”åˆ†æ")
        print(f"{'='*60}")
        
        print("æœºå™¨äººé…ç½® | ä¼ ç»ŸFitness | æ–°Fitness | æ–°ç³»ç»Ÿç±»åˆ«")
        print("-" * 55)
        
        for i in range(len(test_genotypes)):
            genotype = test_genotypes[i]
            old_result = results[0][1][i]  # ä¼ ç»Ÿç³»ç»Ÿç»“æœ
            new_result = results[1][1][i]  # æ–°ç³»ç»Ÿç»“æœ
            
            config = f"{genotype.num_links}é“¾èŠ‚,{sum(genotype.link_lengths):.0f}px"
            old_fitness = old_result['fitness']
            new_fitness = new_result['fitness']
            category = new_result['fitness_details']['category'] if new_result['fitness_details'] else 'N/A'
            
            print(f"{config:12} | {old_fitness:10.2f} | {new_fitness:9.3f} | {category}")
    
    print(f"\nâœ… è®­ç»ƒé€‚é…å™¨æµ‹è¯•å®Œæˆ!")
    if len(results) >= 2:
        print(f"ğŸ¯ æ–°çš„é—ä¼ ç®—æ³•Fitnessç³»ç»Ÿå·²æˆåŠŸé›†æˆ!")


if __name__ == "__main__":
    test_training_adapter()