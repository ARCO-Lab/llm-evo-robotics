#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆè®­ç»ƒè„šæœ¬ - ç¦ç”¨æ¸²æŸ“ï¼Œä¸“æ³¨è®­ç»ƒç¨³å®šæ€§
"""

import sys
import os
base_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../')
sys.path.append(base_dir)

# åŸºç¡€å¯¼å…¥
sys.path.insert(0, os.path.join(base_dir, 'examples/2d_reacher/envs'))
sys.path.insert(0, os.path.join(base_dir, 'examples/surrogate_model/gnn_encoder'))
sys.path.insert(0, os.path.join(base_dir, 'examples/surrogate_model/sac'))

from reacher2d_env import Reacher2DEnv
from sac_model import AttentionSACWithBuffer
from gnn_encoder import GNN_Encoder
import numpy as np
import torch
import time

def main():
    print("ğŸš€ å¯åŠ¨ç®€åŒ–ç‰ˆè®­ç»ƒï¼ˆæ— æ¸²æŸ“ï¼‰")
    print("="*50)
    
    # ç¯å¢ƒå‚æ•°
    env_params = {
        'num_links': 4,
        'link_lengths': [80, 80, 80, 60],
        'render_mode': None,  # ç¦ç”¨æ¸²æŸ“
        'config_path': '/home/xli149/Documents/repos/test_robo/examples/2d_reacher/configs/reacher_with_zigzag_obstacles.yaml',
        'debug_level': 'SILENT'
    }
    
    # åˆ›å»ºç¯å¢ƒ
    print("1ï¸âƒ£ åˆ›å»ºè®­ç»ƒç¯å¢ƒ...")
    env = Reacher2DEnv(**env_params)
    obs = env.reset()
    
    action_dim = 4  # 4ä¸ªå…³èŠ‚
    obs_dim = obs.shape[0] if hasattr(obs, 'shape') else len(obs)
    
    print(f"   è§‚å¯Ÿç»´åº¦: {obs_dim}")
    print(f"   åŠ¨ä½œç»´åº¦: {action_dim}")
    
    # åˆ›å»ºæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆGNNï¼‰
    print("2ï¸âƒ£ åˆ›å»ºæ¨¡å‹...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"   ä½¿ç”¨è®¾å¤‡: {device}")
    
    # ç®€åŒ–çš„GNNç¼–ç å™¨
    class SimpleGNNEncoder:
        def __init__(self, obs_dim):
            self.obs_dim = obs_dim
            
        def encode(self, obs):
            # ç®€å•çš„è§‚å¯Ÿç¼–ç 
            joint_features = obs[:12].reshape(4, 3)  # 4ä¸ªå…³èŠ‚ï¼Œæ¯ä¸ª3ä¸ªç‰¹å¾
            vertex_features = obs[12:].reshape(1, -1)  # å…¶ä»–ç‰¹å¾
            
            joint_q = torch.FloatTensor(joint_features).unsqueeze(0).to(device)
            vertex_k = torch.FloatTensor(vertex_features).to(device)
            vertex_v = torch.FloatTensor(vertex_features).to(device)
            vertex_mask = torch.ones(1, 1).bool().to(device)
            
            return joint_q, vertex_k, vertex_v, vertex_mask
    
    encoder = SimpleGNNEncoder(obs_dim)
    
    # åˆ›å»ºSACæ¨¡å‹
    print("3ï¸âƒ£ åˆ›å»ºSACæ¨¡å‹...")
    sac_model = AttentionSACWithBuffer(
        attn_model=encoder,
        action_dim=action_dim,
        lr=3e-4,
        device=device
    )
    
    # è®­ç»ƒå¾ªç¯
    print("4ï¸âƒ£ å¼€å§‹è®­ç»ƒ...")
    total_steps = 0
    episode_count = 0
    episode_reward = 0
    episode_steps = 0
    
    obs = env.reset()
    
    for step in range(1000):  # çŸ­æœŸæµ‹è¯•
        # è·å–åŠ¨ä½œ
        joint_q, vertex_k, vertex_v, vertex_mask = encoder.encode(obs)
        action = sac_model.get_action(joint_q, vertex_k, vertex_v, vertex_mask, deterministic=False)
        
        # æ‰§è¡ŒåŠ¨ä½œ
        next_obs, reward, done, info = env.step(action)
        
        episode_reward += reward
        episode_steps += 1
        total_steps += 1
        
        # å­˜å‚¨ç»éªŒ
        next_joint_q, next_vertex_k, next_vertex_v, next_vertex_mask = encoder.encode(next_obs)
        sac_model.memory.push(
            joint_q.cpu(), vertex_k.cpu(), vertex_v.cpu(),
            torch.FloatTensor(action),
            torch.FloatTensor([reward]),
            next_joint_q.cpu(), next_vertex_k.cpu(), next_vertex_v.cpu(),
            torch.FloatTensor([float(done)]),
            vertex_mask.cpu()
        )
        
        # æ›´æ–°æ¨¡å‹
        if total_steps > 100 and total_steps % 2 == 0:  # ä»æ­¥æ•°100å¼€å§‹æ›´æ–°
            update_info = sac_model.update()
            if update_info and step % 50 == 0:
                print(f"   Step {step}: Critic Loss = {update_info.get('critic_loss', 'N/A'):.3f}, "
                      f"Actor Loss = {update_info.get('actor_loss', 'N/A'):.3f}")
        
        # Episodeç»“æŸå¤„ç†
        if done or episode_steps >= 500:
            episode_count += 1
            print(f"Episode {episode_count}: å¥–åŠ± = {episode_reward:.2f}, æ­¥æ•° = {episode_steps}")
            
            obs = env.reset()
            episode_reward = 0
            episode_steps = 0
        else:
            obs = next_obs
            
        # æ¯100æ­¥è¾“å‡ºè¿›åº¦
        if step % 100 == 0:
            print(f"Training progress: {step}/1000 steps")
    
    env.close()
    print("\nâœ… ç®€åŒ–ç‰ˆè®­ç»ƒæµ‹è¯•å®Œæˆï¼")
    print("   åŸºç¡€å¥–åŠ±ç³»ç»Ÿå’ŒSACæ¨¡å‹è¿è¡Œæ­£å¸¸")
    print("   å¯ä»¥ç»§ç»­å¼€å‘å®Œæ•´çš„è®­ç»ƒç³»ç»Ÿ")

if __name__ == "__main__":
    main()
