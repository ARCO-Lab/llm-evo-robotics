import torch
import torch.nn as nn
import numpy as np
import os
import sys
# æ·»åŠ è·¯å¾„
base_dir = os.path.join(os.path.dirname(__file__), "../../../")
sys.path.append(base_dir)
sys.path.insert(0, os.path.join(base_dir, "examples/surrogate_model/attn_dataset"))
sys.path.insert(0, os.path.join(base_dir, "examples/surrogate_model/attn_model"))

import torch


from attn_model import AttnModel
from sac_model import AttentionSACWithBuffer

def test_buffer_update_functionality():
    """å®Œæ•´æµ‹è¯•SAC bufferæ›´æ–°åŠŸèƒ½"""
    
    print("="*60)
    print("Testing SAC Buffer Update Functionality")
    print("="*60)
    
    # è®¾ç½®è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    action_dim = 12
    attn_model = AttnModel(128, 128, 130, 4)
    sac = AttentionSACWithBuffer(
        attn_model, 
        action_dim, 
        buffer_capacity=1000,  # è¾ƒå°çš„bufferä¾¿äºæµ‹è¯•
        batch_size=32,         # è¾ƒå°çš„batch size
        device=device
    )
    
    print(f"âœ“ SACæ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"  - Buffer capacity: {sac.memory.capacity}")
    print(f"  - Batch size: {sac.batch_size}")
    print(f"  - Action dim: {action_dim}")
    
    # æµ‹è¯•1: Bufferå­˜å‚¨åŠŸèƒ½
    print("\n" + "-"*40)
    print("Test 1: Buffer Storage")
    print("-"*40)
    
    num_experiences = 100
    for i in range(num_experiences):
        obs = torch.randn(40)
        gnn_embeds = torch.randn(12, 128)
        action = torch.randn(12)
        reward = np.random.normal(0, 1)  # éšæœºå¥–åŠ±
        next_obs = torch.randn(40)
        next_gnn_embeds = torch.randn(12, 128)
        done = (i % 50 == 49)  # æ¯50æ­¥ç»“æŸä¸€ä¸ªepisode
        
        sac.store_experience(obs, gnn_embeds, action, reward, next_obs, next_gnn_embeds, done)
        
        if (i + 1) % 20 == 0:
            print(f"  Stored {i+1} experiences, buffer size: {len(sac.memory)}")
    
    print(f"âœ“ Bufferå­˜å‚¨æµ‹è¯•å®Œæˆï¼Œæœ€ç»ˆbufferå¤§å°: {len(sac.memory)}")
    
    # æµ‹è¯•2: ç½‘ç»œå‚æ•°æ›´æ–°å‰åå¯¹æ¯”
    print("\n" + "-"*40)
    print("Test 2: Parameter Updates")
    print("-"*40)
    
    # è®°å½•æ›´æ–°å‰çš„å‚æ•°
    def get_model_params(model):
        return {name: param.clone().detach() for name, param in model.named_parameters()}
    
    actor_params_before = get_model_params(sac.actor)
    critic1_params_before = get_model_params(sac.critic1)
    critic2_params_before = get_model_params(sac.critic2)
    
    print("âœ“ è®°å½•æ›´æ–°å‰å‚æ•°")
    
    # æ‰§è¡Œå¤šæ¬¡æ›´æ–°
    update_count = 0
    loss_history = {'critic': [], 'actor': [], 'alpha': []}
    
    if sac.memory.can_sample(sac.batch_size):
        for i in range(10):  # æ‰§è¡Œ10æ¬¡æ›´æ–°
            metrics = sac.update()
            if metrics:
                update_count += 1
                loss_history['critic'].append(metrics['critic_loss'])
                loss_history['actor'].append(metrics['actor_loss'])
                loss_history['alpha'].append(metrics['alpha_loss'])
                
                if i % 2 == 0:
                    print(f"  Update {i+1}: Critic Loss: {metrics['critic_loss']:.4f}, "
                          f"Actor Loss: {metrics['actor_loss']:.4f}, "
                          f"Alpha: {metrics['alpha']:.4f}")
    
    print(f"âœ“ å®Œæˆ {update_count} æ¬¡å‚æ•°æ›´æ–°")
    
    # æµ‹è¯•3: éªŒè¯å‚æ•°ç¡®å®å‘ç”Ÿäº†å˜åŒ–
    print("\n" + "-"*40)
    print("Test 3: Parameter Change Verification")
    print("-"*40)
    
    def compare_params(params_before, model, model_name):
        total_params = 0
        changed_params = 0
        max_change = 0
        
        for name, param in model.named_parameters():
            if name in params_before:
                diff = torch.abs(param - params_before[name])
                max_diff = diff.max().item()
                total_params += 1
                
                if max_diff > 1e-8:  # å‚æ•°å˜åŒ–é˜ˆå€¼
                    changed_params += 1
                    max_change = max(max_change, max_diff)
        
        change_ratio = changed_params / total_params if total_params > 0 else 0
        print(f"  {model_name}:")
        print(f"    - Total parameters: {total_params}")
        print(f"    - Changed parameters: {changed_params}")
        print(f"    - Change ratio: {change_ratio:.2%}")
        print(f"    - Max parameter change: {max_change:.6f}")
        
        return change_ratio > 0.5  # è‡³å°‘50%çš„å‚æ•°å‘ç”Ÿå˜åŒ–
    
    actor_changed = compare_params(actor_params_before, sac.actor, "Actor")
    critic1_changed = compare_params(critic1_params_before, sac.critic1, "Critic1")
    critic2_changed = compare_params(critic2_params_before, sac.critic2, "Critic2")
    
    if actor_changed and critic1_changed and critic2_changed:
        print("âœ“ æ‰€æœ‰ç½‘ç»œå‚æ•°éƒ½å‘ç”Ÿäº†æ˜¾è‘—å˜åŒ–")
    else:
        print("âœ— éƒ¨åˆ†ç½‘ç»œå‚æ•°æœªå‘ç”Ÿé¢„æœŸå˜åŒ–")
    
    # æµ‹è¯•4: åŠ¨ä½œè¾“å‡ºä¸€è‡´æ€§æµ‹è¯•
    print("\n" + "-"*40)
    print("Test 4: Action Output Consistency")
    print("-"*40)
    
    test_obs = torch.randn(40)
    test_gnn_embeds = torch.randn(12, 128)
    
    # æµ‹è¯•ç¡®å®šæ€§åŠ¨ä½œ
    action1 = sac.get_action(test_obs, test_gnn_embeds, deterministic=True)
    action2 = sac.get_action(test_obs, test_gnn_embeds, deterministic=True)
    
    deterministic_diff = torch.abs(action1 - action2).max().item()
    print(f"  ç¡®å®šæ€§åŠ¨ä½œå·®å¼‚: {deterministic_diff:.8f}")
    
    if deterministic_diff < 1e-6:
        print("âœ“ ç¡®å®šæ€§åŠ¨ä½œè¾“å‡ºä¸€è‡´")
    else:
        print("âœ— ç¡®å®šæ€§åŠ¨ä½œè¾“å‡ºä¸ä¸€è‡´")
    
    # æµ‹è¯•éšæœºåŠ¨ä½œ
    stochastic_actions = []
    for _ in range(5):
        action = sac.get_action(test_obs, test_gnn_embeds, deterministic=False)
        stochastic_actions.append(action)
    
    # è®¡ç®—éšæœºåŠ¨ä½œçš„æ–¹å·®
    stochastic_actions = torch.stack(stochastic_actions)
    action_variance = torch.var(stochastic_actions, dim=0).mean().item()
    print(f"  éšæœºåŠ¨ä½œæ–¹å·®: {action_variance:.6f}")
    
    if action_variance > 1e-4:
        print("âœ“ éšæœºåŠ¨ä½œå…·æœ‰é€‚å½“çš„éšæœºæ€§")
    else:
        print("âœ— éšæœºåŠ¨ä½œå¯èƒ½è¿‡äºç¡®å®š")
    
    # æµ‹è¯•5: Bufferé‡‡æ ·ä¸€è‡´æ€§
    print("\n" + "-"*40)
    print("Test 5: Buffer Sampling Consistency")
    print("-"*40)
    
    if sac.memory.can_sample(sac.batch_size):
        # é‡‡æ ·ä¸¤æ¬¡ï¼Œæ£€æŸ¥æ˜¯å¦ä¸åŒ
        batch1 = sac.memory.sample(16)  # è¾ƒå°çš„batchä¾¿äºæ¯”è¾ƒ
        batch2 = sac.memory.sample(16)
        
        # æ¯”è¾ƒjoint_qçš„ç¬¬ä¸€ä¸ªæ ·æœ¬
        diff = torch.abs(batch1[0][0] - batch2[0][0]).sum().item()
        print(f"  ä¸¤æ¬¡é‡‡æ ·çš„å·®å¼‚: {diff:.6f}")
        
        if diff > 1e-6:
            print("âœ“ Bufferé‡‡æ ·å…·æœ‰éšæœºæ€§")
        else:
            print("! Bufferé‡‡æ ·å¯èƒ½è¿‡äºç›¸ä¼¼ï¼ˆå¦‚æœbufferå¾ˆå°è¿™æ˜¯æ­£å¸¸çš„ï¼‰")
    
    # æµ‹è¯•6: æŸå¤±è¶‹åŠ¿åˆ†æ
    print("\n" + "-"*40)
    print("Test 6: Loss Trend Analysis")
    print("-"*40)
    
    if len(loss_history['critic']) > 5:
        # ç®€å•çš„è¶‹åŠ¿åˆ†æ
        critic_trend = np.mean(loss_history['critic'][-3:]) - np.mean(loss_history['critic'][:3])
        actor_trend = np.mean(loss_history['actor'][-3:]) - np.mean(loss_history['actor'][:3])
        
        print(f"  Critic lossè¶‹åŠ¿: {critic_trend:+.6f}")
        print(f"  Actor lossè¶‹åŠ¿: {actor_trend:+.6f}")
        print(f"  æœ€ç»ˆAlphaå€¼: {loss_history['alpha'][-1]:.4f}")
        
        # å¯è§†åŒ–æŸå¤±ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # plot_loss_curves(loss_history)
    
    # æµ‹è¯•7: Targetç½‘ç»œæ›´æ–°æµ‹è¯•
    print("\n" + "-"*40)
    print("Test 7: Target Network Update")
    print("-"*40)
    
    # è®°å½•targetç½‘ç»œå‚æ•°
    target_params_before = get_model_params(sac.target_critic1)
    
    # æ‰§è¡Œä¸€æ¬¡æ›´æ–°
    if sac.memory.can_sample(sac.batch_size):
        sac.update()
    
    # æ£€æŸ¥targetç½‘ç»œå‚æ•°å˜åŒ–
    target_changed = compare_params(target_params_before, sac.target_critic1, "Target Critic1")
    
    if target_changed:
        print("âœ“ Targetç½‘ç»œå‚æ•°æ­£ç¡®æ›´æ–°")
    else:
        print("âœ— Targetç½‘ç»œå‚æ•°æœªæ­£ç¡®æ›´æ–°")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("Test Summary")
    print("="*60)
    print(f"âœ“ Bufferå®¹é‡: {len(sac.memory)}/{sac.memory.capacity}")
    print(f"âœ“ æ‰§è¡Œæ›´æ–°æ¬¡æ•°: {update_count}")
    print(f"âœ“ å‚æ•°æ›´æ–°çŠ¶æ€: Actor({actor_changed}), Critic1({critic1_changed}), Critic2({critic2_changed})")
    print(f"âœ“ æœ€ç»ˆlosses: Critic:{loss_history['critic'][-1]:.4f}, Actor:{loss_history['actor'][-1]:.4f}")
    
    return True

def plot_loss_curves(loss_history):
    """å¯è§†åŒ–æŸå¤±æ›²çº¿"""
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    axes[0].plot(loss_history['critic'])
    axes[0].set_title('Critic Loss')
    axes[0].set_xlabel('Update Step')
    axes[0].set_ylabel('Loss')
    
    axes[1].plot(loss_history['actor'])
    axes[1].set_title('Actor Loss')
    axes[1].set_xlabel('Update Step')
    axes[1].set_ylabel('Loss')
    
    axes[2].plot(loss_history['alpha'])
    axes[2].set_title('Alpha Loss')
    axes[2].set_xlabel('Update Step')
    axes[2].set_ylabel('Loss')
    
    plt.tight_layout()
    plt.savefig('sac_training_curves.png')
    plt.show()

def test_memory_efficiency():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æ•ˆç‡"""
    print("\n" + "="*60)
    print("Memory Efficiency Test")
    print("="*60)
    
    import psutil
    import gc
    
    # è·å–åˆå§‹å†…å­˜ä½¿ç”¨
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # åˆ›å»ºSAC
    action_dim = 12
    attn_model = AttnModel(128, 128, 130, 4)
    sac = AttentionSACWithBuffer(attn_model, action_dim, buffer_capacity=10000)
    
    model_memory = process.memory_info().rss / 1024 / 1024 - initial_memory
    print(f"æ¨¡å‹åˆ›å»ºåå†…å­˜ä½¿ç”¨: {model_memory:.2f} MB")
    
    # å¡«å……buffer
    for i in range(5000):
        obs = torch.randn(40)
        gnn_embeds = torch.randn(12, 128)
        action = torch.randn(12)
        reward = np.random.normal(0, 1)
        next_obs = torch.randn(40)
        next_gnn_embeds = torch.randn(12, 128)
        done = (i % 100 == 99)
        
        sac.store_experience(obs, gnn_embeds, action, reward, next_obs, next_gnn_embeds, done)
    
    buffer_memory = process.memory_info().rss / 1024 / 1024 - initial_memory
    print(f"Bufferå¡«å……åå†…å­˜ä½¿ç”¨: {buffer_memory:.2f} MB")
    
    # æ‰§è¡Œè®­ç»ƒ
    for i in range(100):
        if sac.memory.can_sample(sac.batch_size):
            sac.update()
    
    training_memory = process.memory_info().rss / 1024 / 1024 - initial_memory
    print(f"è®­ç»ƒåå†…å­˜ä½¿ç”¨: {training_memory:.2f} MB")
    
    # æ¸…ç†
    del sac
    gc.collect()
    
    final_memory = process.memory_info().rss / 1024 / 1024 - initial_memory
    print(f"æ¸…ç†åå†…å­˜ä½¿ç”¨: {final_memory:.2f} MB")

if __name__ == "__main__":
    try:
        # è¿è¡Œä¸»è¦åŠŸèƒ½æµ‹è¯•
        success = test_buffer_update_functionality()
        
        # è¿è¡Œå†…å­˜æ•ˆç‡æµ‹è¯•
        test_memory_efficiency()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()