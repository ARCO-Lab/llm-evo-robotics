#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„2å…³èŠ‚ReacheræˆåŠŸåˆ¤æ–­é€»è¾‘
"""

import os
import numpy as np
import gymnasium as gym
import torch
import torch.nn as nn
from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
import time

# è®¾ç½®æ¸²æŸ“ç¯å¢ƒå˜é‡
os.environ['MUJOCO_GL'] = 'glfw'
os.environ['MUJOCO_RENDERER'] = 'glfw'

class SpecializedJointExtractor(BaseFeaturesExtractor):
    """ä¸“é—¨é’ˆå¯¹ç‰¹å®šå…³èŠ‚æ•°çš„ç‰¹å¾æå–å™¨"""
    
    def __init__(self, observation_space: gym.Space, features_dim: int = 128):
        super(SpecializedJointExtractor, self).__init__(observation_space, features_dim)
        
        obs_dim = observation_space.shape[0]
        
        print(f"ğŸ”§ SpecializedJointExtractor: {obs_dim}ç»´ -> {features_dim}ç»´")
        
        # é’ˆå¯¹å…·ä½“è§‚å¯Ÿç»´åº¦è®¾è®¡ç½‘ç»œ
        self.net = nn.Sequential(
            nn.Linear(obs_dim, 256),
            nn.ReLU(),
            nn.LayerNorm(256),
            nn.Dropout(0.1),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.LayerNorm(256),
            nn.Dropout(0.1),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.LayerNorm(128),
            nn.Linear(128, features_dim),
            nn.ReLU()
        )
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        return self.net(observations)

# ä¿®å¤åçš„2å…³èŠ‚ç¯å¢ƒåŒ…è£…å™¨
class Fixed2JointReacherWrapper(gym.Wrapper):
    """ä¿®å¤2å…³èŠ‚ReacheråŒ…è£…å™¨ - ä½¿ç”¨ç›¸åŒçš„ç›®æ ‡ç”Ÿæˆç­–ç•¥å¹¶ä¿®å¤æˆåŠŸåˆ¤æ–­"""
    
    def __init__(self, env):
        super().__init__(env)
        self.link_lengths = [0.1, 0.1]
        self.max_episode_steps = 100  # æ¯ä¸ªepisode 100æ­¥
        print("ğŸŒŸ Fixed2JointReacherWrapper åˆå§‹åŒ–")
        print(f"   é“¾é•¿: {self.link_lengths}")
        print(f"   æœ€å¤§å¯è¾¾è·ç¦»: {self.calculate_max_reach():.3f}")
        print(f"   ç›®æ ‡ç”ŸæˆèŒƒå›´: {self.calculate_target_range():.3f}")
    
    def calculate_max_reach(self):
        return sum(self.link_lengths)
    
    def calculate_target_range(self):
        max_reach = self.calculate_max_reach()
        return max_reach * 0.85
    
    def generate_unified_target(self):
        max_target_distance = self.calculate_target_range()
        min_target_distance = 0.05
        
        target_distance = self.np_random.uniform(min_target_distance, max_target_distance)
        target_angle = self.np_random.uniform(-np.pi, np.pi)
        
        target_x = target_distance * np.cos(target_angle)
        target_y = target_distance * np.sin(target_angle)
        
        return target_x, target_y
    
    def reset(self, **kwargs):
        obs, info = self.env.reset(**kwargs)
        
        # åº”ç”¨ç»Ÿä¸€çš„ç›®æ ‡ç”Ÿæˆç­–ç•¥
        target_x, target_y = self.generate_unified_target()
        
        # ğŸ”§ ä¿®å¤ç›®æ ‡æ»šåŠ¨é—®é¢˜ï¼šç¡®ä¿ç›®æ ‡é€Ÿåº¦ä¸º0
        reacher_env = self.env.unwrapped
        qpos = reacher_env.data.qpos.copy()
        qvel = reacher_env.data.qvel.copy()
        
        # è®¾ç½®ç›®æ ‡ä½ç½®
        qpos[-2:] = [target_x, target_y]
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿ç›®æ ‡é€Ÿåº¦ä¸º0
        qvel[-2:] = [0.0, 0.0]
        
        reacher_env.set_state(qpos, qvel)
        
        # è·å–æ–°çš„è§‚å¯Ÿ
        obs = reacher_env._get_obs()
        
        # æ›´æ–°info
        if info is None:
            info = {}
        info.update({
            'max_reach': self.calculate_max_reach(),
            'target_range': self.calculate_target_range(),
            'target_pos': [target_x, target_y]
        })
        
        return obs, info
    
    def step(self, action):
        obs, reward, terminated, truncated, info = self.env.step(action)
        
        # ğŸ”§ é‡æ–°è®¡ç®—æˆåŠŸåˆ¤æ–­ - è¿™æ˜¯å…³é”®ä¿®å¤ï¼
        reacher_env = self.env.unwrapped
        fingertip_pos = reacher_env.get_body_com("fingertip")[:2]
        target_pos = reacher_env.get_body_com("target")[:2]
        distance = np.linalg.norm(fingertip_pos - target_pos)
        
        # ğŸ¯ æˆåŠŸåˆ¤æ–­ï¼šè·ç¦»å°äº0.05ï¼ˆ5cmï¼‰- æ›´åˆç†çš„é˜ˆå€¼
        is_success = distance < 0.05
        
        # æ·»åŠ ç»Ÿä¸€çš„ä¿¡æ¯
        if info is None:
            info = {}
        info.update({
            'max_reach': self.calculate_max_reach(),
            'target_range': self.calculate_target_range(),
            'distance_to_target': distance,
            'is_success': is_success,  # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ·»åŠ æ­£ç¡®çš„æˆåŠŸåˆ¤æ–­
            'fingertip_pos': fingertip_pos.copy(),
            'target_pos': target_pos.copy()
        })
        
        return obs, reward, terminated, truncated, info

def create_fixed_test_env(render_mode='human'):
    """åˆ›å»ºä¿®å¤åçš„æµ‹è¯•ç”¨2å…³èŠ‚ç¯å¢ƒ"""
    env = gym.make('Reacher-v5', render_mode=render_mode)
    env = Fixed2JointReacherWrapper(env)
    env = Monitor(env)
    return env

def test_fixed_2joint_success_logic(model_path, n_eval_episodes=5):
    """æµ‹è¯•ä¿®å¤åçš„2å…³èŠ‚æˆåŠŸåˆ¤æ–­é€»è¾‘"""
    print(f"ğŸ§ª æµ‹è¯•ä¿®å¤åçš„2å…³èŠ‚æˆåŠŸåˆ¤æ–­é€»è¾‘")
    print(f"ğŸ“Š æµ‹è¯•episodes: {n_eval_episodes}, æ¯ä¸ªepisode: 100æ­¥")
    print("ğŸ¯ æˆåŠŸæ ‡å‡†: è·ç¦»ç›®æ ‡ < 0.05 (5cm) - æ›´åˆç†çš„é˜ˆå€¼")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
    test_env = create_fixed_test_env(render_mode='human')
    
    # åŠ è½½æ¨¡å‹
    try:
        model = SAC.load(model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None
    
    # æµ‹è¯•ç»“æœ
    episode_results = []
    
    try:
        for episode in range(n_eval_episodes):
            print(f"\\nğŸ“ Episode {episode+1}/{n_eval_episodes}")
            print("-" * 40)
            
            obs, info = test_env.reset()
            episode_reward = 0
            episode_success = False
            min_distance = float('inf')
            distances = []
            step_count = 0
            
            # åˆå§‹ä¿¡æ¯
            initial_target_pos = info.get('target_pos', [0, 0])
            print(f"   ğŸ¯ ç›®æ ‡ä½ç½®: ({initial_target_pos[0]:.3f}, {initial_target_pos[1]:.3f})")
            print(f"   ğŸ“ ç›®æ ‡è·ç¦»: {np.linalg.norm(initial_target_pos):.3f}")
            
            for step in range(100):  # æ¯ä¸ªepisode 100æ­¥
                action, _ = model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = test_env.step(action)
                
                episode_reward += reward
                step_count += 1
                
                # è·å–è¯¦ç»†ä¿¡æ¯
                distance = info.get('distance_to_target', float('inf'))
                is_success = info.get('is_success', False)
                fingertip_pos = info.get('fingertip_pos', [0, 0])
                target_pos = info.get('target_pos', [0, 0])
                
                distances.append(distance)
                min_distance = min(min_distance, distance)
                
                if is_success and not episode_success:
                    episode_success = True
                    print(f"   âœ… æˆåŠŸ! æ­¥æ•°: {step+1}, è·ç¦»: {distance:.4f}")
                
                # æ¯20æ­¥æ‰“å°ä¸€æ¬¡çŠ¶æ€
                if (step + 1) % 20 == 0:
                    print(f"   æ­¥æ•° {step+1:3d}: è·ç¦»={distance:.4f}, æˆåŠŸ={is_success}, æœ«ç«¯=({fingertip_pos[0]:.3f},{fingertip_pos[1]:.3f})")
                
                if terminated or truncated:
                    print(f"   ğŸ Episodeç»“æŸ: æ­¥æ•°={step+1}, åŸå› ={'terminated' if terminated else 'truncated'}")
                    break
            
            # Episodeæ€»ç»“
            final_distance = distances[-1] if distances else float('inf')
            avg_distance = np.mean(distances) if distances else float('inf')
            
            episode_result = {
                'episode': episode + 1,
                'total_reward': episode_reward,
                'success': episode_success,
                'steps': step_count,
                'min_distance': min_distance,
                'final_distance': final_distance,
                'avg_distance': avg_distance,
                'target_pos': initial_target_pos
            }
            episode_results.append(episode_result)
            
            print(f"\\n   ğŸ“Š Episode {episode+1} æ€»ç»“:")
            print(f"      æ€»å¥–åŠ±: {episode_reward:.2f}")
            print(f"      æˆåŠŸ: {'âœ…' if episode_success else 'âŒ'}")
            print(f"      æœ€å°è·ç¦»: {min_distance:.4f}")
            print(f"      æœ€ç»ˆè·ç¦»: {final_distance:.4f}")
            
            # æš‚åœä¸€ä¸‹è®©ç”¨æˆ·è§‚å¯Ÿ
            time.sleep(1)
    
    except KeyboardInterrupt:
        print(f"\\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    
    finally:
        test_env.close()
    
    # æœ€ç»ˆç»Ÿè®¡
    if episode_results:
        print(f"\\n{'='*60}")
        print("ğŸ‰ ä¿®å¤åçš„æˆåŠŸåˆ¤æ–­æµ‹è¯•å®Œæˆ!")
        print(f"{'='*60}")
        
        success_episodes = sum(1 for r in episode_results if r['success'])
        total_episodes = len(episode_results)
        success_rate = success_episodes / total_episodes if total_episodes > 0 else 0
        
        avg_reward = np.mean([r['total_reward'] for r in episode_results])
        avg_min_distance = np.mean([r['min_distance'] for r in episode_results])
        
        print(f"\\nğŸ“Š ä¿®å¤åçš„ç»“æœ:")
        print(f"   æˆåŠŸç‡: {success_rate:.1%} ({success_episodes}/{total_episodes})")
        print(f"   å¹³å‡æ€»å¥–åŠ±: {avg_reward:.2f}")
        print(f"   å¹³å‡æœ€å°è·ç¦»: {avg_min_distance:.4f}")
        
        print(f"\\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        print(f"{'Episode':<8} {'å¥–åŠ±':<8} {'æˆåŠŸ':<6} {'æœ€å°è·ç¦»':<10}")
        print("-" * 40)
        for r in episode_results:
            success_mark = "âœ…" if r['success'] else "âŒ"
            print(f"{r['episode']:<8} {r['total_reward']:<8.2f} {success_mark:<6} {r['min_distance']:<10.4f}")
        
        if success_rate > 0:
            print(f"\\nğŸ‰ ä¿®å¤æˆåŠŸï¼ç°åœ¨2å…³èŠ‚æ¨¡å‹æœ‰ {success_rate:.1%} çš„æˆåŠŸç‡")
        else:
            print(f"\\nâš ï¸ ä»ç„¶æ²¡æœ‰æˆåŠŸï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        
        return episode_results
    
    return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ æµ‹è¯•ä¿®å¤åçš„2å…³èŠ‚ReacheræˆåŠŸåˆ¤æ–­é€»è¾‘")
    print("ğŸ¯ ç›®æ ‡: éªŒè¯ä¿®å¤åçš„æˆåŠŸåˆ¤æ–­æ˜¯å¦æ­£ç¡®å·¥ä½œ")
    print()
    
    # æµ‹è¯•æœ€æ–°çš„2å…³èŠ‚æ¨¡å‹
    model_path = "models/sequential_2joint_reacher.zip"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("ğŸ“‹ å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶:")
        if os.path.exists("models"):
            for file in os.listdir("models"):
                if "2joint" in file or "reacher" in file:
                    print(f"   - models/{file}")
        return
    
    # å¼€å§‹æµ‹è¯•
    results = test_fixed_2joint_success_logic(model_path, n_eval_episodes=5)
    
    if results:
        print(f"\\nâœ… æµ‹è¯•å®Œæˆ! æˆåŠŸåˆ¤æ–­é€»è¾‘å·²ä¿®å¤ã€‚")
    else:
        print(f"\\nâŒ æµ‹è¯•å¤±è´¥æˆ–è¢«ä¸­æ–­ã€‚")

if __name__ == "__main__":
    main()
