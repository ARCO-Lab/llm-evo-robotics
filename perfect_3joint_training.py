#!/usr/bin/env python3
"""
å®Œç¾çš„3å…³èŠ‚Reacherè®­ç»ƒ
åŒæ—¶æ˜¾ç¤ºloss tableå’Œè¿›åº¦æ¡
"""

import os
import tempfile
import numpy as np
from gymnasium.envs.mujoco import MujocoEnv
from gymnasium.spaces import Box
from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor

# è®¾ç½®æ¸²æŸ“ç¯å¢ƒå˜é‡
os.environ['MUJOCO_GL'] = 'glfw'
os.environ['MUJOCO_RENDERER'] = 'glfw'

def get_expanded_3joint_xml():
    """è·å–æ‰©å¤§åœºåœ°çš„3å…³èŠ‚XML"""
    return """
<mujoco model="perfect_3joint">
  <compiler angle="radian" inertiafromgeom="true"/>
  <default>
    <joint armature="1" damping="1" limited="true"/>
    <geom contype="0" friction="1 0.1 0.1" rgba="0.7 0.7 0 1"/>
  </default>
  <option gravity="0 0 -9.81" integrator="RK4" timestep="0.01"/>
  <worldbody>
    <!-- æ‰©å¤§çš„åœºåœ°ï¼š1.0m x 1.0m -->
    <geom conaffinity="0" contype="0" name="ground" pos="0 0 0" rgba="0.9 0.9 0.9 1" size="0.5 0.5 10" type="plane"/>
    
    <!-- æ‰©å¤§çš„è¾¹ç•Œ -->
    <geom conaffinity="0" fromto="-.5 -.5 .01 .5 -.5 .01" name="sideS" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto=" .5 -.5 .01 .5  .5 .01" name="sideE" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.5  .5 .01 .5  .5 .01" name="sideN" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    <geom conaffinity="0" fromto="-.5 -.5 .01 -.5  .5 .01" name="sideW" rgba="0.9 0.4 0.6 1" size=".02" type="capsule"/>
    
    <geom conaffinity="0" contype="0" fromto="0 0 0 0 0 0.02" name="root" rgba="0.9 0.4 0.6 1" size=".011" type="cylinder"/>
    
    <!-- 3å…³èŠ‚æœºæ¢°è‡‚ -->
    <body name="body0" pos="0 0 .01">
      <geom fromto="0 0 0 0.1 0 0" name="link0" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
      <joint axis="0 0 1" limited="false" name="joint0" pos="0 0 0" type="hinge"/>
      <body name="body1" pos="0.1 0 0">
        <joint axis="0 0 1" limited="true" name="joint1" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
        <geom fromto="0 0 0 0.1 0 0" name="link1" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
        <body name="body2" pos="0.1 0 0">
          <joint axis="0 0 1" limited="true" name="joint2" pos="0 0 0" range="-3.0 3.0" type="hinge"/>
          <geom fromto="0 0 0 0.1 0 0" name="link2" rgba="0.0 0.4 0.6 1" size=".01" type="capsule"/>
          <body name="fingertip" pos="0.1 0 0">
            <geom contype="0" name="fingertip" pos="0 0 0" rgba="0.0 0.8 0.6 1" size=".01" type="sphere"/>
          </body>
        </body>
      </body>
    </body>
    
    <!-- æ‰©å¤§ç›®æ ‡æ´»åŠ¨èŒƒå›´ -->
    <body name="target" pos=".2 -.2 .01">
      <joint armature="0" axis="1 0 0" damping="0" limited="true" name="target_x" pos="0 0 0" range="-.45 .45" ref=".2" stiffness="0" type="slide"/>
      <joint armature="0" axis="0 1 0" damping="0" limited="true" name="target_y" pos="0 0 0" range="-.45 .45" ref="-.2" stiffness="0" type="slide"/>
      <geom conaffinity="0" contype="0" name="target" pos="0 0 0" rgba="0.9 0.2 0.2 1" size=".012" type="sphere"/>
    </body>
  </worldbody>
  <actuator>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint0"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint1"/>
    <motor ctrllimited="true" ctrlrange="-1.0 1.0" gear="200.0" joint="joint2"/>
  </actuator>
</mujoco>
"""

class Perfect3JointReacherEnv(MujocoEnv):
    """
    å®Œç¾çš„3å…³èŠ‚Reacherç¯å¢ƒ
    - æ‰©å¤§åœºåœ°
    - æ­£ç¡®çš„episodeç»ˆæ­¢
    - æ˜¾ç¤ºè®­ç»ƒç»Ÿè®¡
    """
    
    def __init__(self, render_mode=None, **kwargs):
        print("ğŸŒŸ Perfect3JointReacherEnv åˆå§‹åŒ–")
        
        self.xml_file = tempfile.NamedTemporaryFile(mode='w', suffix='.xml', delete=False)
        self.xml_file.write(get_expanded_3joint_xml())
        self.xml_file.flush()
        
        print(f"   XMLæ–‡ä»¶: {self.xml_file.name}")
        print(f"   åœºåœ°å°ºå¯¸: 1.0m x 1.0m")
        print(f"   ç›®æ ‡èŒƒå›´: Â±0.45m")
        
        observation_space = Box(low=-np.inf, high=np.inf, shape=(13,), dtype=np.float64)
        
        super().__init__(
            self.xml_file.name,
            frame_skip=2,
            observation_space=observation_space,
            render_mode=render_mode
        )
        
        self.action_space = Box(low=-1.0, high=1.0, shape=(3,), dtype=np.float32)
        
        # Episodeç®¡ç†
        self.step_count = 0
        self.max_episode_steps = 50  # ä¸æ ‡å‡†Reacherç›¸åŒ
        
        print("âœ… Perfect3JointReacherEnv åˆ›å»ºå®Œæˆ")
        print(f"   è§‚å¯Ÿç©ºé—´: {self.observation_space}")
        print(f"   åŠ¨ä½œç©ºé—´: {self.action_space}")
        print(f"   æœ€å¤§episodeæ­¥æ•°: {self.max_episode_steps}")
    
    def step(self, action):
        """æ‰§è¡Œä¸€æ­¥"""
        self.do_simulation(action, self.frame_skip)
        obs = self._get_obs()
        
        # è®¡ç®—å¥–åŠ±
        vec = self.data.body("fingertip").xpos[:2] - self.data.body("target").xpos[:2]
        reward_dist = -np.linalg.norm(vec)
        reward_ctrl = -np.square(action).sum()
        reward = reward_dist + reward_ctrl
        
        # å¢åŠ æ­¥æ•°è®¡æ•°
        self.step_count += 1
        
        # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        distance = np.linalg.norm(vec)
        terminated = distance < 0.02  # æˆåŠŸæ¡ä»¶
        truncated = self.step_count >= self.max_episode_steps  # æœ€å¤§æ­¥æ•°
        
        info = {
            'reward_dist': reward_dist, 
            'reward_ctrl': reward_ctrl,
            'distance_to_target': distance,
            'is_success': terminated
        }
        
        # åªåœ¨humanæ¨¡å¼ä¸‹æ¸²æŸ“
        if self.render_mode == 'human':
            self.render()
        
        return obs, reward, terminated, truncated, info
    
    def _get_obs(self):
        """è·å–è§‚å¯Ÿ"""
        theta = self.data.qpos.flat[:3]
        return np.concatenate([
            np.cos(theta),
            np.sin(theta),
            self.data.qvel.flat[:3],
            self.data.body("fingertip").xpos[:2],
            self.data.body("target").xpos[:2],
        ])
    
    def reset_model(self):
        """é‡ç½®æ¨¡å‹"""
        # é‡ç½®æ­¥æ•°è®¡æ•°å™¨
        self.step_count = 0
        
        qpos = self.init_qpos + self.np_random.uniform(low=-0.1, high=0.1, size=self.model.nq)
        qvel = self.init_qvel + self.np_random.uniform(low=-0.005, high=0.005, size=self.model.nv)
        self.set_state(qpos, qvel)
        return self._get_obs()
    
    def __del__(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if hasattr(self, 'xml_file') and os.path.exists(self.xml_file.name):
            os.unlink(self.xml_file.name)

def train_perfect_3joint():
    """å®Œç¾çš„3å…³èŠ‚è®­ç»ƒ - åŒæ—¶æ˜¾ç¤ºloss tableå’Œè¿›åº¦æ¡"""
    print("ğŸš€ å®Œç¾çš„3å…³èŠ‚Reacherè®­ç»ƒ")
    print("ğŸ’¡ åŒæ—¶æ˜¾ç¤ºloss tableå’Œè¿›åº¦æ¡")
    print("ğŸ¯ æ‰©å¤§åœºåœ°ï¼Œæ­£ç¡®çš„episodeç»ˆæ­¢")
    print()
    
    # åˆ›å»ºè®­ç»ƒç¯å¢ƒ (å¸¦æ¸²æŸ“)
    print("ğŸŒ åˆ›å»ºè®­ç»ƒç¯å¢ƒ...")
    train_env = Perfect3JointReacherEnv(render_mode='human')
    train_env = Monitor(train_env)
    
    print("âœ… è®­ç»ƒç¯å¢ƒåˆ›å»ºå®Œæˆ")
    
    # åˆ›å»ºSACæ¨¡å‹ - å…³é”®å‚æ•°è®¾ç½®
    print("\nğŸ¤– åˆ›å»ºSACæ¨¡å‹...")
    model = SAC(
        'MlpPolicy',
        train_env,
        verbose=2,              # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿— (loss table)
        learning_starts=100,    # 100æ­¥åå¼€å§‹å­¦ä¹ 
        device='cpu',
        tensorboard_log="./tensorboard_logs/",
    )
    
    print("âœ… SACæ¨¡å‹åˆ›å»ºå®Œæˆ")
    print("   âœ… verbose=2: æ˜¾ç¤ºloss table")
    print("   âœ… learning_starts=100: å¿«é€Ÿå¼€å§‹å­¦ä¹ ")
    print("   âœ… tensorboard_log: å¯ç”¨è¯¦ç»†æ—¥å¿—")
    
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ (10000æ­¥)...")
    print("ğŸ’¡ æ‚¨åº”è¯¥èƒ½çœ‹åˆ°:")
    print("   ğŸ“Š Loss table (æ¯200æ­¥æ˜¾ç¤º)")
    print("   ğŸ“ˆ è¿›åº¦æ¡ (å®æ—¶æ˜¾ç¤º)")
    print("   ğŸ® è®­ç»ƒç»Ÿè®¡ (episodeé•¿åº¦ã€å¥–åŠ±ã€æˆåŠŸç‡)")
    print()
    
    try:
        import time
        start_time = time.time()
        
        # è®­ç»ƒæ¨¡å‹ - å…³é”®ï¼šåŒæ—¶è®¾ç½®ä¸¤ä¸ªå‚æ•°
        model.learn(
            total_timesteps=30000,
            log_interval=4,         # æ˜¾ç¤ºloss table
            progress_bar=True       # æ˜¾ç¤ºè¿›åº¦æ¡
        )
        
        training_time = time.time() - start_time
        
        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"â±ï¸ è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
        print(f"ğŸ“Š å¹³å‡FPS: {10000/training_time:.1f}")
        
        # ä¿å­˜æ¨¡å‹
        model.save("models/perfect_3joint_reacher_sac")
        print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: models/perfect_3joint_reacher_sac")
        
        # å¿«é€Ÿè¯„ä¼°
        print("\nğŸ® å¿«é€Ÿè¯„ä¼° (30æ­¥):")
        obs, info = train_env.reset()
        
        total_reward = 0
        distances = []
        successes = 0
        
        for step in range(30):
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = train_env.step(action)
            
            total_reward += reward
            distance = info['distance_to_target']
            distances.append(distance)
            
            if info['is_success']:
                successes += 1
            
            if step % 10 == 0:
                print(f"   Step {step}: è·ç¦»={distance:.3f}m, å¥–åŠ±={reward:.3f}")
            
            if terminated or truncated:
                obs, info = train_env.reset()
        
        avg_distance = np.mean(distances)
        avg_reward = total_reward / 30
        success_rate = successes / 30 * 100
        
        print(f"\nğŸ“Š è®­ç»ƒåè¯„ä¼°ç»“æœ:")
        print(f"   å¹³å‡è·ç¦»: {avg_distance:.3f}m")
        print(f"   å¹³å‡å¥–åŠ±: {avg_reward:.3f}")
        print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        
        if avg_distance < 0.1:
            print("   âœ… è®­ç»ƒæ•ˆæœè‰¯å¥½!")
        elif avg_distance < 0.2:
            print("   ğŸ”¶ è®­ç»ƒæ•ˆæœä¸€èˆ¬ï¼Œå¯ä»¥ç»§ç»­è®­ç»ƒ")
        else:
            print("   âš ï¸ è®­ç»ƒæ•ˆæœè¾ƒå·®ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å‚æ•°")
        
    except KeyboardInterrupt:
        training_time = time.time() - start_time
        print(f"\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        print(f"â±ï¸ å·²è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
        
        model.save("models/perfect_3joint_reacher_sac_interrupted")
        print("ğŸ’¾ ä¸­æ–­æ¨¡å‹å·²ä¿å­˜")
    
    finally:
        train_env.close()

def test_with_rendering():
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶æ˜¾ç¤ºæ¸²æŸ“ - 10ä¸ªepisodeï¼Œæ¯ä¸ªepisode 100æ­¥"""
    print("\nğŸ® æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹ (å¸¦æ¸²æŸ“)")
    
    try:
        # åŠ è½½æ¨¡å‹
        print("ğŸ“‚ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
        model = SAC.load("models/perfect_3joint_reacher_sac")
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºæ¸²æŸ“ç¯å¢ƒ
        print("ğŸŒ åˆ›å»ºæ¸²æŸ“ç¯å¢ƒ...")
        render_env = Perfect3JointReacherEnv(render_mode='human')
        
        print("âœ… æ¸²æŸ“ç¯å¢ƒåˆ›å»ºå®Œæˆ")
        print("ğŸ¯ å¼€å§‹æµ‹è¯• (10ä¸ªepisodeï¼Œæ¯ä¸ªepisodeæœ€å¤š100æ­¥)...")
        print("ğŸ’¡ è§‚å¯Ÿæœºæ¢°è‡‚æ˜¯å¦èƒ½æˆåŠŸåˆ°è¾¾ç›®æ ‡")
        
        # ç»Ÿè®¡æ‰€æœ‰episodeçš„ç»“æœ
        all_episode_rewards = []
        all_episode_lengths = []
        all_episode_successes = []
        all_episode_final_distances = []
        
        for episode in range(10):
            print(f"\nğŸ“ Episode {episode + 1}/10:")
            
            obs, info = render_env.reset()
            episode_reward = 0
            episode_length = 0
            episode_success = False
            
            for step in range(100):  # æ¯ä¸ªepisodeæœ€å¤š100æ­¥
                action, _states = model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = render_env.step(action)
                
                episode_reward += reward
                episode_length += 1
                distance = info['distance_to_target']
                
                # æ¯20æ­¥æ‰“å°ä¸€æ¬¡çŠ¶æ€
                if step % 20 == 0:
                    print(f"   Step {step}: è·ç¦»={distance:.3f}m, å¥–åŠ±={reward:.3f}")
                
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
                if info['is_success']:
                    episode_success = True
                    print(f"   âœ… æˆåŠŸ! åœ¨ç¬¬{step+1}æ­¥åˆ°è¾¾ç›®æ ‡ï¼Œè·ç¦»={distance:.3f}m")
                    break
                
                # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                if terminated or truncated:
                    final_distance = distance
                    if terminated and not episode_success:
                        print(f"   âš ï¸ Episodeç»“æŸï¼Œæœ€ç»ˆè·ç¦»={final_distance:.3f}m")
                    break
            else:
                # å¦‚æœå¾ªç¯æ­£å¸¸ç»“æŸï¼ˆæ²¡æœ‰breakï¼‰ï¼Œè¯´æ˜è¾¾åˆ°äº†100æ­¥
                final_distance = distance
                print(f"   â° è¾¾åˆ°æœ€å¤§æ­¥æ•°(100)ï¼Œæœ€ç»ˆè·ç¦»={final_distance:.3f}m")
            
            # è®°å½•episodeç»Ÿè®¡
            all_episode_rewards.append(episode_reward)
            all_episode_lengths.append(episode_length)
            all_episode_successes.append(episode_success)
            all_episode_final_distances.append(final_distance)
            
            print(f"   ğŸ“Š Episode {episode + 1} æ€»ç»“: å¥–åŠ±={episode_reward:.2f}, é•¿åº¦={episode_length}, æˆåŠŸ={'æ˜¯' if episode_success else 'å¦'}")
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        avg_reward = np.mean(all_episode_rewards)
        avg_length = np.mean(all_episode_lengths)
        success_rate = np.mean(all_episode_successes) * 100
        avg_final_distance = np.mean(all_episode_final_distances)
        
        print(f"\nğŸ“Š å®Œæ•´æµ‹è¯•ç»“æœ (10ä¸ªepisode):")
        print(f"   å¹³å‡episodeå¥–åŠ±: {avg_reward:.3f}")
        print(f"   å¹³å‡episodeé•¿åº¦: {avg_length:.1f}æ­¥")
        print(f"   å¹³å‡æœ€ç»ˆè·ç¦»: {avg_final_distance:.3f}m")
        print(f"   æˆåŠŸç‡: {success_rate:.1f}% ({int(success_rate/10)}/10 episodes)")
        
        # æ€§èƒ½è¯„ä¼°
        if success_rate >= 80:
            print("   ğŸ‰ è®­ç»ƒæ•ˆæœä¼˜ç§€!")
        elif success_rate >= 50:
            print("   âœ… è®­ç»ƒæ•ˆæœè‰¯å¥½!")
        elif success_rate >= 20:
            print("   ğŸ”¶ è®­ç»ƒæ•ˆæœä¸€èˆ¬ï¼Œå¯ä»¥ç»§ç»­è®­ç»ƒ")
        else:
            print("   âš ï¸ è®­ç»ƒæ•ˆæœè¾ƒå·®ï¼Œå»ºè®®è°ƒæ•´å‚æ•°æˆ–å»¶é•¿è®­ç»ƒ")
        
        # è¯¦ç»†ç»Ÿè®¡
        successful_episodes = [i+1 for i, success in enumerate(all_episode_successes) if success]
        if successful_episodes:
            print(f"   ğŸ¯ æˆåŠŸçš„episode: {successful_episodes}")
        
        render_env.close()
        
    except FileNotFoundError:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒ")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ å®Œç¾çš„3å…³èŠ‚Reacherè®­ç»ƒç³»ç»Ÿ")
    print("ğŸ’¡ åŒæ—¶æ˜¾ç¤ºloss tableå’Œè¿›åº¦æ¡")
    print("ğŸ¯ æ‰©å¤§åœºåœ°ï¼Œæ­£ç¡®çš„episodeç®¡ç†")
    print()
    
    try:
        # è®­ç»ƒ
        train_perfect_3joint()
        
        # è¯¢é—®æ˜¯å¦æµ‹è¯•
        print("\n" + "="*60)
        print("è®­ç»ƒå®Œæˆï¼æ˜¯å¦æµ‹è¯•æ¨¡å‹ (å¸¦æ¸²æŸ“)?")
        print("æŒ‰Enteræµ‹è¯•ï¼ŒCtrl+Cé€€å‡º")
        print("="*60)
        input("æŒ‰Enterç»§ç»­...")
        
        # æµ‹è¯•
        test_with_rendering()
        
        print(f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
        print(f"ğŸ’¡ ç°åœ¨æ‚¨æœ‰äº†ä¸€ä¸ªå®Œç¾å·¥ä½œçš„3å…³èŠ‚Reacherç¯å¢ƒ")
        print(f"âœ… åŒæ—¶æ˜¾ç¤ºloss tableå’Œè¿›åº¦æ¡")
        print(f"âœ… æ‰©å¤§åœºåœ°é€‚åˆ3å…³èŠ‚æ´»åŠ¨")
        print(f"âœ… æ­£ç¡®çš„episodeç»ˆæ­¢å’Œç»Ÿè®¡")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
