#!/usr/bin/env python3
"""
å¯å˜å…³èŠ‚ Reacher SAC è®­ç»ƒç³»ç»Ÿ
åŸºäº multi_joint_reacher_sac.py ä¿®æ”¹ï¼Œå®ç°çœŸæ­£æ„ä¹‰ä¸Šå¯ä»¥å…¼å®¹å¯å˜å…³èŠ‚æ•°é‡è®­ç»ƒçš„æ¨¡å‹

æ ¸å¿ƒæ”¹è¿›ï¼š
1. ä½¿ç”¨çœŸå®çš„å¤šå…³èŠ‚ MuJoCo ç¯å¢ƒ (ä¸æ˜¯åŸºäº Reacher-v5 çš„åŒ…è£…å™¨)
2. ä¿æŒé€šç”¨ç‰¹å¾æå–å™¨æ¶æ„
3. æ”¯æŒåœ¨åŒä¸€ä¸ªæ¨¡å‹ä¸­è®­ç»ƒä¸åŒå…³èŠ‚æ•°
4. ä½¿ç”¨ J_max ç­–ç•¥ï¼Œæ”¯æŒçœŸæ­£çš„å¯å˜å…³èŠ‚æ•°é‡
"""

import os
import time
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Tuple, Optional, Any
import gymnasium as gym
from gymnasium.spaces import Box
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.evaluation import evaluate_policy

# å¯¼å…¥çœŸå®å¤šå…³èŠ‚ç¯å¢ƒ
from real_multi_joint_reacher import RealMultiJointWrapper

# ============================================================================
# ğŸ§© å¯å˜å…³èŠ‚æ©ç ç³»ç»Ÿ
# ============================================================================

class VariableJointMaskSystem:
    """å¯å˜å…³èŠ‚æ©ç ç³»ç»Ÿï¼Œæ”¯æŒ J_max ç­–ç•¥"""
    
    @staticmethod
    def create_joint_mask(num_joints: int, max_joints: int) -> torch.Tensor:
        """
        åˆ›å»ºå…³èŠ‚æ©ç 
        Args:
            num_joints: å®é™…å…³èŠ‚æ•°
            max_joints: æœ€å¤§å…³èŠ‚æ•° (J_max)
        Returns:
            joint_mask: [max_joints,] (True for valid joints)
        """
        mask = torch.zeros(max_joints, dtype=torch.bool)
        mask[:num_joints] = True
        return mask
    
    @staticmethod
    def pad_observation(obs: np.ndarray, num_joints: int, max_joints: int, 
                       link_lengths: List[float]) -> np.ndarray:
        """
        å°†è§‚å¯Ÿå¡«å……åˆ° J_max ç»´åº¦
        
        Args:
            obs: åŸå§‹è§‚å¯Ÿ [joint_featuresÃ—N + global_featuresÃ—6]
            num_joints: å®é™…å…³èŠ‚æ•°
            max_joints: æœ€å¤§å…³èŠ‚æ•°
            link_lengths: å…³èŠ‚é•¿åº¦åˆ—è¡¨
        
        Returns:
            padded_obs: å¡«å……åçš„è§‚å¯Ÿ [joint_featuresÃ—J_max + global_featuresÃ—6]
        """
        # è§£æåŸå§‹è§‚å¯Ÿ
        joint_features_flat = obs[:4 * num_joints]  # [cos, sin, vel, link_length] Ã— num_joints
        global_features = obs[4 * num_joints:]      # [ee_pos, target_pos, target_vec]
        
        # é‡å¡‘å…³èŠ‚ç‰¹å¾
        joint_features = joint_features_flat.reshape(num_joints, 4)
        
        # åˆ›å»ºå¡«å……åçš„å…³èŠ‚ç‰¹å¾
        padded_joint_features = np.zeros((max_joints, 4), dtype=np.float32)
        padded_joint_features[:num_joints] = joint_features
        
        # å¯¹äºå¡«å……çš„å…³èŠ‚ï¼Œä½¿ç”¨é»˜è®¤å€¼
        for i in range(num_joints, max_joints):
            padded_joint_features[i] = [1.0, 0.0, 0.0, 0.05]  # [cos=1, sin=0, vel=0, link_len=0.05]
        
        # é‡æ–°ç»„åˆ
        padded_obs = np.concatenate([
            padded_joint_features.flatten(),  # 4 * max_joints
            global_features                   # 6
        ])
        
        return padded_obs
    
    @staticmethod
    def pad_action(action: np.ndarray, num_joints: int, max_joints: int) -> np.ndarray:
        """
        å°†åŠ¨ä½œå¡«å……åˆ° J_max ç»´åº¦
        
        Args:
            action: åŸå§‹åŠ¨ä½œ [num_joints,]
            num_joints: å®é™…å…³èŠ‚æ•°
            max_joints: æœ€å¤§å…³èŠ‚æ•°
        
        Returns:
            padded_action: å¡«å……åçš„åŠ¨ä½œ [max_joints,]
        """
        padded_action = np.zeros(max_joints, dtype=np.float32)
        padded_action[:num_joints] = action
        return padded_action
    
    @staticmethod
    def unpad_action(padded_action: np.ndarray, num_joints: int) -> np.ndarray:
        """
        ä»å¡«å……çš„åŠ¨ä½œä¸­æå–å®é™…åŠ¨ä½œ
        
        Args:
            padded_action: å¡«å……åçš„åŠ¨ä½œ [max_joints,]
            num_joints: å®é™…å…³èŠ‚æ•°
        
        Returns:
            action: å®é™…åŠ¨ä½œ [num_joints,]
        """
        return padded_action[:num_joints]

# ============================================================================
# ğŸ§© å¯å˜å…³èŠ‚ç¯å¢ƒåŒ…è£…å™¨
# ============================================================================

class VariableJointReacherWrapper(gym.Wrapper):
    """
    å¯å˜å…³èŠ‚ Reacher ç¯å¢ƒåŒ…è£…å™¨
    æ”¯æŒ J_max ç­–ç•¥ï¼Œå¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€æ”¹å˜å…³èŠ‚æ•°
    """
    
    def __init__(self, max_joints: int = 4, 
                 joint_configs: List[Dict] = None,
                 current_config_idx: int = 0):
        """
        Args:
            max_joints: æœ€å¤§å…³èŠ‚æ•° (J_max)
            joint_configs: å…³èŠ‚é…ç½®åˆ—è¡¨ [{'num_joints': 2, 'link_lengths': [0.1, 0.1]}, ...]
            current_config_idx: å½“å‰é…ç½®ç´¢å¼•
        """
        
        self.max_joints = max_joints
        self.joint_configs = joint_configs or [
            {'num_joints': 2, 'link_lengths': [0.1, 0.1]},
            {'num_joints': 3, 'link_lengths': [0.1, 0.1, 0.1]},
            {'num_joints': 4, 'link_lengths': [0.1, 0.1, 0.1, 0.1]}
        ]
        self.current_config_idx = current_config_idx
        self.current_config = self.joint_configs[current_config_idx]
        
        print(f"ğŸŒŸ VariableJointReacherWrapper åˆå§‹åŒ–:")
        print(f"   æœ€å¤§å…³èŠ‚æ•° (J_max): {max_joints}")
        print(f"   å…³èŠ‚é…ç½®æ•°é‡: {len(self.joint_configs)}")
        print(f"   å½“å‰é…ç½®: {self.current_config}")
        
        # åˆ›å»ºå½“å‰é…ç½®çš„ç¯å¢ƒ
        self._create_current_env()
        
        # åˆå§‹åŒ– wrapper
        super(VariableJointReacherWrapper, self).__init__(self.current_env)
        
        # è®¾ç½®ç»Ÿä¸€çš„è§‚å¯Ÿå’ŒåŠ¨ä½œç©ºé—´ (åŸºäº J_max)
        obs_dim = 4 * max_joints + 6  # joint_featuresÃ—J_max + global_features
        self.observation_space = Box(
            low=-np.inf, high=np.inf, 
            shape=(obs_dim,), dtype=np.float32
        )
        
        self.action_space = Box(
            low=-1.0, high=1.0, 
            shape=(max_joints,), dtype=np.float32
        )
        
        print(f"âœ… ç»Ÿä¸€ç©ºé—´è®¾ç½®å®Œæˆ:")
        print(f"   è§‚å¯Ÿç©ºé—´: {self.observation_space}")
        print(f"   åŠ¨ä½œç©ºé—´: {self.action_space}")
    
    def _create_current_env(self):
        """åˆ›å»ºå½“å‰é…ç½®çš„ç¯å¢ƒ"""
        config = self.current_config
        self.current_env = RealMultiJointWrapper(
            num_joints=config['num_joints'],
            link_lengths=config['link_lengths'],
            render_mode=None
        )
        self.current_num_joints = config['num_joints']
        self.current_link_lengths = config['link_lengths']
    
    def switch_config(self, config_idx: int):
        """åˆ‡æ¢åˆ°ä¸åŒçš„å…³èŠ‚é…ç½®"""
        if 0 <= config_idx < len(self.joint_configs):
            print(f"ğŸ”„ åˆ‡æ¢å…³èŠ‚é…ç½®: {self.joint_configs[config_idx]}")
            
            # å…³é—­å½“å‰ç¯å¢ƒ
            if hasattr(self, 'current_env'):
                self.current_env.close()
            
            # æ›´æ–°é…ç½®
            self.current_config_idx = config_idx
            self.current_config = self.joint_configs[config_idx]
            
            # åˆ›å»ºæ–°ç¯å¢ƒ
            self._create_current_env()
            
            # æ›´æ–° wrapper çš„ç¯å¢ƒ
            self.env = self.current_env
        else:
            raise ValueError(f"Invalid config_idx: {config_idx}")
    
    def reset(self, **kwargs):
        """é‡ç½®ç¯å¢ƒ"""
        obs, info = self.current_env.reset(**kwargs)
        
        # å¡«å……è§‚å¯Ÿåˆ° J_max
        padded_obs = VariableJointMaskSystem.pad_observation(
            obs, self.current_num_joints, self.max_joints, self.current_link_lengths
        )
        
        # æ·»åŠ å…³èŠ‚ä¿¡æ¯
        info['num_joints'] = self.current_num_joints
        info['max_joints'] = self.max_joints
        info['link_lengths'] = self.current_link_lengths
        info['joint_mask'] = VariableJointMaskSystem.create_joint_mask(
            self.current_num_joints, self.max_joints
        ).numpy()
        
        return padded_obs, info
    
    def step(self, action):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        # ä» J_max åŠ¨ä½œä¸­æå–å®é™…åŠ¨ä½œ
        real_action = VariableJointMaskSystem.unpad_action(action, self.current_num_joints)
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, reward, terminated, truncated, info = self.current_env.step(real_action)
        
        # å¡«å……è§‚å¯Ÿåˆ° J_max
        padded_obs = VariableJointMaskSystem.pad_observation(
            obs, self.current_num_joints, self.max_joints, self.current_link_lengths
        )
        
        # æ·»åŠ å…³èŠ‚ä¿¡æ¯
        info['num_joints'] = self.current_num_joints
        info['max_joints'] = self.max_joints
        info['link_lengths'] = self.current_link_lengths
        info['joint_mask'] = VariableJointMaskSystem.create_joint_mask(
            self.current_num_joints, self.max_joints
        ).numpy()
        
        return padded_obs, reward, terminated, truncated, info
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        if hasattr(self, 'current_env'):
            self.current_env.close()

# ============================================================================
# ğŸ§© å¯å˜å…³èŠ‚é€šç”¨ç‰¹å¾æå–å™¨
# ============================================================================

class VariableJointUniversalExtractor(BaseFeaturesExtractor):
    """å¯å˜å…³èŠ‚é€šç”¨ç‰¹å¾æå–å™¨ï¼Œæ”¯æŒ J_max ç­–ç•¥"""
    
    def __init__(self, observation_space: gym.Space, 
                 max_joints: int = 4,
                 joint_hidden_dim: int = 64,
                 pooled_dim: int = 128,
                 global_hidden_dim: int = 64,
                 features_dim: int = 256):
        
        super(VariableJointUniversalExtractor, self).__init__(observation_space, features_dim)
        
        self.max_joints = max_joints
        self.joint_hidden_dim = joint_hidden_dim
        self.pooled_dim = pooled_dim
        self.global_hidden_dim = global_hidden_dim
        
        print(f"ğŸ”§ VariableJointUniversalExtractor åˆå§‹åŒ–:")
        print(f"   æœ€å¤§å…³èŠ‚æ•°: {max_joints}")
        print(f"   è§‚å¯Ÿç©ºé—´: {observation_space}")
        print(f"   ç‰¹å¾ç»´åº¦: {features_dim}")
        
        # å…³èŠ‚ç¼–ç å™¨ (å¤„ç† [cos, sin, vel, link_length])
        self.joint_encoder = nn.Sequential(
            nn.Linear(4, joint_hidden_dim),
            nn.ReLU(),
            nn.Linear(joint_hidden_dim, joint_hidden_dim),
            nn.ReLU()
        )
        
        # å¤šå¤´è‡ªæ³¨æ„åŠ› (å…³èŠ‚é—´äº¤äº’)
        self.multihead_attention = nn.MultiheadAttention(
            embed_dim=joint_hidden_dim,
            num_heads=8,
            batch_first=True
        )
        
        # æ³¨æ„åŠ›æ± åŒ–
        self.attention_pooling = nn.Sequential(
            nn.Linear(joint_hidden_dim, 1),
            nn.Softmax(dim=1)
        )
        
        # å…¨å±€ç‰¹å¾å¤„ç†å™¨
        self.global_processor = nn.Sequential(
            nn.Linear(6, global_hidden_dim),  # [ee_pos, target_pos, target_vec]
            nn.ReLU(),
            nn.Linear(global_hidden_dim, global_hidden_dim),
            nn.ReLU()
        )
        
        # æœ€ç»ˆèåˆ
        self.final_fusion = nn.Sequential(
            nn.Linear(joint_hidden_dim + global_hidden_dim, features_dim),
            nn.ReLU(),
            nn.Linear(features_dim, features_dim)
        )
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        """
        Args:
            observations: [batch_size, obs_dim] (obs_dim = 4*max_joints + 6)
        Returns:
            features: [batch_size, features_dim]
        """
        batch_size = observations.shape[0]
        
        # è§£æè§‚å¯Ÿ
        joint_features_flat = observations[:, :4 * self.max_joints]  # [batch_size, 4*max_joints]
        joint_features = joint_features_flat.reshape(batch_size, self.max_joints, 4)  # [batch_size, max_joints, 4]
        
        global_features = observations[:, 4 * self.max_joints:]  # [batch_size, 6]
        
        # å…³èŠ‚ç‰¹å¾ç¼–ç 
        encoded_joints = self.joint_encoder(joint_features)  # [batch_size, max_joints, joint_hidden_dim]
        
        # å¤šå¤´è‡ªæ³¨æ„åŠ› (å…³èŠ‚é—´äº¤äº’)
        attended_joints, _ = self.multihead_attention(
            query=encoded_joints,
            key=encoded_joints,
            value=encoded_joints
        )  # [batch_size, max_joints, joint_hidden_dim]
        
        # æ³¨æ„åŠ›æ± åŒ–
        attention_weights = self.attention_pooling(attended_joints)  # [batch_size, max_joints, 1]
        pooled_joints = torch.sum(attended_joints * attention_weights, dim=1)  # [batch_size, joint_hidden_dim]
        
        # å…¨å±€ç‰¹å¾å¤„ç†
        processed_global = self.global_processor(global_features)  # [batch_size, global_hidden_dim]
        
        # æœ€ç»ˆèåˆ
        combined_features = torch.cat([pooled_joints, processed_global], dim=-1)
        final_features = self.final_fusion(combined_features)
        
        return final_features

# ============================================================================
# ğŸ§© è®­ç»ƒå‡½æ•°
# ============================================================================

def train_variable_joint_sac(max_joints: int = 4,
                            joint_configs: List[Dict] = None,
                            total_timesteps: int = 50000,
                            config_switch_freq: int = 10000) -> Dict[str, Any]:
    """
    è®­ç»ƒå¯å˜å…³èŠ‚ SAC æ¨¡å‹
    
    Args:
        max_joints: æœ€å¤§å…³èŠ‚æ•° (J_max)
        joint_configs: å…³èŠ‚é…ç½®åˆ—è¡¨
        total_timesteps: æ€»è®­ç»ƒæ­¥æ•°
        config_switch_freq: é…ç½®åˆ‡æ¢é¢‘ç‡
    
    Returns:
        è®­ç»ƒç»“æœ
    """
    
    if joint_configs is None:
        joint_configs = [
            {'num_joints': 2, 'link_lengths': [0.1, 0.1]},
            {'num_joints': 3, 'link_lengths': [0.1, 0.1, 0.1]},
            {'num_joints': 4, 'link_lengths': [0.1, 0.1, 0.1, 0.1]}
        ]
    
    print(f"\n{'='*70}")
    print(f"ğŸš€ å¯å˜å…³èŠ‚ Reacher SAC è®­ç»ƒ")
    print(f"{'='*70}")
    print(f"ğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"   æœ€å¤§å…³èŠ‚æ•° (J_max): {max_joints}")
    print(f"   å…³èŠ‚é…ç½®: {joint_configs}")
    print(f"   æ€»è®­ç»ƒæ­¥æ•°: {total_timesteps}")
    print(f"   é…ç½®åˆ‡æ¢é¢‘ç‡: {config_switch_freq}")
    
    # åˆ›å»ºå¯å˜å…³èŠ‚ç¯å¢ƒ
    print(f"\nğŸŒ åˆ›å»ºå¯å˜å…³èŠ‚ç¯å¢ƒ...")
    base_env = VariableJointReacherWrapper(
        max_joints=max_joints,
        joint_configs=joint_configs,
        current_config_idx=0
    )
    env = Monitor(base_env)
    
    # åˆ›å»ºè¯„ä¼°ç¯å¢ƒ
    base_eval_env = VariableJointReacherWrapper(
        max_joints=max_joints,
        joint_configs=joint_configs,
        current_config_idx=0
    )
    eval_env = Monitor(base_eval_env)
    
    print(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ")
    print(f"   è§‚å¯Ÿç©ºé—´: {env.observation_space}")
    print(f"   åŠ¨ä½œç©ºé—´: {env.action_space}")
    
    # åˆ›å»º SAC æ¨¡å‹
    print(f"\nğŸ¤– åˆ›å»ºå¯å˜å…³èŠ‚ SAC æ¨¡å‹...")
    
    policy_kwargs = {
        'features_extractor_class': VariableJointUniversalExtractor,
        'features_extractor_kwargs': {
            'max_joints': max_joints,
            'joint_hidden_dim': 64,
            'pooled_dim': 128,
            'global_hidden_dim': 64,
            'features_dim': 256
        },
        'net_arch': [512, 512]
    }
    
    model = SAC(
        'MlpPolicy',
        env,
        policy_kwargs=policy_kwargs,
        learning_rate=3e-4,
        buffer_size=100000,
        learning_starts=1000,
        batch_size=256,
        tau=0.005,
        gamma=0.99,
        train_freq=1,
        gradient_steps=1,
        ent_coef='auto',
        target_update_interval=1,
        verbose=2,
        device='auto',
        tensorboard_log="./variable_joint_logs/"
    )
    
    print(f"âœ… SAC æ¨¡å‹åˆ›å»ºå®Œæˆ")
    print(f"   ç­–ç•¥: MlpPolicy + VariableJointUniversalExtractor")
    print(f"   ç½‘ç»œæ¶æ„: [512, 512]")
    print(f"   ç¼“å†²åŒºå¤§å°: 100,000")
    
    # åˆ›å»ºè¯„ä¼°å›è°ƒ
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=f'./logs/variable_joint_sac/',
        log_path=f'./logs/variable_joint_sac/',
        eval_freq=5000,
        deterministic=True,
        render=False
    )
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\nğŸ¯ å¼€å§‹å¯å˜å…³èŠ‚è®­ç»ƒ...")
    start_time = time.time()
    
    try:
        # è®­ç»ƒå¾ªç¯ï¼Œå®šæœŸåˆ‡æ¢å…³èŠ‚é…ç½®
        steps_trained = 0
        config_idx = 0
        
        while steps_trained < total_timesteps:
            # è®¡ç®—è¿™æ¬¡è®­ç»ƒçš„æ­¥æ•°
            steps_to_train = min(config_switch_freq, total_timesteps - steps_trained)
            
            print(f"\nğŸ”„ è®­ç»ƒé˜¶æ®µ {steps_trained//config_switch_freq + 1}:")
            print(f"   å½“å‰é…ç½®: {joint_configs[config_idx]}")
            print(f"   è®­ç»ƒæ­¥æ•°: {steps_to_train}")
            
            # åˆ‡æ¢ç¯å¢ƒé…ç½®
            base_env.switch_config(config_idx)
            base_eval_env.switch_config(config_idx)
            
            # è®­ç»ƒ
            model.learn(
                total_timesteps=steps_to_train,
                callback=eval_callback,
                progress_bar=True,
                reset_num_timesteps=False
            )
            
            steps_trained += steps_to_train
            
            # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªé…ç½®
            config_idx = (config_idx + 1) % len(joint_configs)
        
        training_time = time.time() - start_time
        print(f"âœ… å¯å˜å…³èŠ‚è®­ç»ƒå®Œæˆï¼ç”¨æ—¶: {training_time:.1f} ç§’")
        
    except KeyboardInterrupt:
        training_time = time.time() - start_time
        print(f"âš ï¸ è®­ç»ƒè¢«ä¸­æ–­ï¼å·²è®­ç»ƒæ—¶é—´: {training_time:.1f} ç§’")
    
    # è¯„ä¼°æ‰€æœ‰é…ç½®
    print(f"\nğŸ“ˆ è¯„ä¼°æ‰€æœ‰å…³èŠ‚é…ç½®...")
    
    results = {
        'max_joints': max_joints,
        'joint_configs': joint_configs,
        'training_time': training_time,
        'total_timesteps': total_timesteps,
        'config_results': []
    }
    
    for i, config in enumerate(joint_configs):
        print(f"\nğŸ§ª è¯„ä¼°é…ç½® {i+1}: {config}")
        
        # åˆ‡æ¢åˆ°å½“å‰é…ç½®
        base_eval_env.switch_config(i)
        
        try:
            mean_reward, std_reward = evaluate_policy(
                model, eval_env, n_eval_episodes=10, deterministic=True
            )
            
            print(f"   å¹³å‡å¥–åŠ±: {mean_reward:.3f} Â± {std_reward:.3f}")
            
            results['config_results'].append({
                'config': config,
                'mean_reward': mean_reward,
                'std_reward': std_reward
            })
            
        except Exception as e:
            print(f"   è¯„ä¼°å¤±è´¥: {e}")
            results['config_results'].append({
                'config': config,
                'error': str(e)
            })
    
    # ä¿å­˜æ¨¡å‹
    model_path = f"variable_joint_sac_j{max_joints}_model"
    model.save(model_path)
    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    results['model_path'] = model_path
    
    env.close()
    eval_env.close()
    
    return results

# ============================================================================
# ğŸ§© ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ å¯å˜å…³èŠ‚ Reacher SAC è®­ç»ƒç³»ç»Ÿ")
    print("ğŸ’¡ çœŸæ­£æ„ä¹‰ä¸Šå¯ä»¥å…¼å®¹å¯å˜å…³èŠ‚æ•°é‡è®­ç»ƒçš„æ¨¡å‹")
    print("ğŸ¯ åŸºäº J_max ç­–ç•¥ï¼Œæ”¯æŒåŠ¨æ€å…³èŠ‚æ•°åˆ‡æ¢")
    print()
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs('logs', exist_ok=True)
    
    # è®­ç»ƒé…ç½®
    joint_configs = [
        {'num_joints': 2, 'link_lengths': [0.1, 0.1]},
        {'num_joints': 3, 'link_lengths': [0.1, 0.1, 0.1]},
        {'num_joints': 4, 'link_lengths': [0.1, 0.1, 0.1, 0.1]}
    ]
    
    try:
        results = train_variable_joint_sac(
            max_joints=4,
            joint_configs=joint_configs,
            total_timesteps=30000,  # å‡å°‘è®­ç»ƒæ­¥æ•°ä»¥ä¾¿æµ‹è¯•
            config_switch_freq=5000  # æ¯5000æ­¥åˆ‡æ¢ä¸€æ¬¡é…ç½®
        )
        
        # æ‰“å°ç»“æœ
        print(f"\n{'='*70}")
        print(f"ğŸ“Š å¯å˜å…³èŠ‚è®­ç»ƒç»“æœ")
        print(f"{'='*70}")
        
        for i, result in enumerate(results['config_results']):
            if 'error' in result:
                print(f"âŒ é…ç½® {i+1}: {result['config']} - å¤±è´¥: {result['error']}")
            else:
                print(f"âœ… é…ç½® {i+1}: {result['config']}")
                print(f"   å¹³å‡å¥–åŠ±: {result['mean_reward']:.3f} Â± {result['std_reward']:.3f}")
        
        print(f"\nğŸ‰ å¯å˜å…³èŠ‚æ¨¡å‹è®­ç»ƒæˆåŠŸï¼")
        print(f"   è®­ç»ƒæ—¶é—´: {results['training_time']:.1f} ç§’")
        print(f"   æ¨¡å‹è·¯å¾„: {results['model_path']}")
        
    except Exception as e:
        print(f"âŒ å¯å˜å…³èŠ‚è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
