#!/usr/bin/env python3
"""
SAC + GNN + ç®€åŒ–æ³¨æ„åŠ›æœºåˆ¶
æ”¯æŒä»»æ„æ•°é‡å…³èŠ‚çš„ Reacher ä»»åŠ¡
ä¸ºå¤šå…³èŠ‚ Reacher åšå‡†å¤‡
"""

import gymnasium as gym
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import time
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.policies import ActorCriticPolicy
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.evaluation import evaluate_policy
from typing import Dict, List, Tuple, Type, Union, Optional
import torch_geometric
from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool
from torch_geometric.data import Data, Batch

class JointGraphBuilder(nn.Module):
    """
    å…³èŠ‚å›¾æ„å»ºå™¨ - å°†å…³èŠ‚ä¿¡æ¯è½¬æ¢ä¸ºå›¾ç»“æ„
    æ”¯æŒä»»æ„æ•°é‡çš„å…³èŠ‚
    """
    def __init__(self, max_joints: int = 10):
        super(JointGraphBuilder, self).__init__()
        self.max_joints = max_joints
        
        print(f"ğŸ”— JointGraphBuilder åˆå§‹åŒ–: æœ€å¤§å…³èŠ‚æ•°={max_joints}")
    
    def build_chain_graph(self, num_joints: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ„å»ºé“¾å¼å…³èŠ‚å›¾ (é€‚ç”¨äº Reacher)
        æ¯ä¸ªå…³èŠ‚è¿æ¥åˆ°ä¸‹ä¸€ä¸ªå…³èŠ‚
        """
        # è¾¹ç´¢å¼•: æ¯ä¸ªå…³èŠ‚è¿æ¥åˆ°ä¸‹ä¸€ä¸ªå…³èŠ‚
        edge_list = []
        for i in range(num_joints - 1):
            edge_list.append([i, i + 1])  # å‰å‘è¿æ¥
            edge_list.append([i + 1, i])  # åå‘è¿æ¥ (æ— å‘å›¾)
        
        if len(edge_list) == 0:
            # å•å…³èŠ‚æƒ…å†µ
            edge_index = torch.empty((2, 0), dtype=torch.long)
        else:
            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()
        
        # è¾¹æƒé‡ (æš‚æ—¶è®¾ä¸º1)
        edge_attr = torch.ones(edge_index.size(1), 1)
        
        return edge_index, edge_attr
    
    def extract_joint_features(self, obs: torch.Tensor, num_joints: int) -> torch.Tensor:
        """
        ä»è§‚å¯Ÿä¸­æå–å…³èŠ‚ç‰¹å¾
        obs: [batch_size, obs_dim]
        return: [batch_size, num_joints, joint_feature_dim]
        """
        batch_size = obs.size(0)
        
        if num_joints == 2:
            # MuJoCo Reacher-v5 (2å…³èŠ‚)
            # [0:2] - cos/sin of joint angles
            # [2:4] - joint velocities
            joint_angles = obs[:, :2]  # [batch_size, 2]
            joint_velocities = obs[:, 2:4]  # [batch_size, 2]
            
            # ç»„åˆå…³èŠ‚ç‰¹å¾
            joint_features = torch.stack([
                torch.cat([joint_angles[:, 0:1], joint_velocities[:, 0:1]], dim=1),  # å…³èŠ‚1
                torch.cat([joint_angles[:, 1:2], joint_velocities[:, 1:2]], dim=1)   # å…³èŠ‚2
            ], dim=1)  # [batch_size, 2, 2]
            
        else:
            # é€šç”¨æƒ…å†µ (ä¸ºæœªæ¥å¤šå…³èŠ‚åšå‡†å¤‡)
            # å‡è®¾è§‚å¯Ÿæ ¼å¼: [joint_angles, joint_velocities, ...]
            joint_dim = num_joints
            joint_angles = obs[:, :joint_dim]
            joint_velocities = obs[:, joint_dim:2*joint_dim]
            
            joint_features = torch.stack([
                torch.cat([joint_angles[:, i:i+1], joint_velocities[:, i:i+1]], dim=1)
                for i in range(num_joints)
            ], dim=1)  # [batch_size, num_joints, 2]
        
        return joint_features

class GNNLayer(nn.Module):
    """
    å›¾ç¥ç»ç½‘ç»œå±‚ - å¤„ç†å…³èŠ‚å›¾
    """
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, gnn_type: str = "GCN"):
        super(GNNLayer, self).__init__()
        self.gnn_type = gnn_type
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        
        if gnn_type == "GCN":
            self.conv1 = GCNConv(input_dim, hidden_dim)
            self.conv2 = GCNConv(hidden_dim, output_dim)
        elif gnn_type == "GAT":
            self.conv1 = GATConv(input_dim, hidden_dim, heads=4, dropout=0.1)
            self.conv2 = GATConv(hidden_dim * 4, output_dim, heads=1, dropout=0.1)
        else:
            raise ValueError(f"Unsupported GNN type: {gnn_type}")
        
        self.dropout = nn.Dropout(0.1)
        self.layer_norm = nn.LayerNorm(output_dim)
        
        print(f"ğŸ§  GNNLayer åˆå§‹åŒ–: {gnn_type}, {input_dim}â†’{hidden_dim}â†’{output_dim}")
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, batch: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        x: [num_nodes, input_dim] èŠ‚ç‚¹ç‰¹å¾
        edge_index: [2, num_edges] è¾¹ç´¢å¼•
        batch: [num_nodes] æ‰¹æ¬¡ç´¢å¼• (ç”¨äºæ‰¹å¤„ç†)
        """
        # ç¬¬ä¸€å±‚ GNN
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.dropout(x)
        
        # ç¬¬äºŒå±‚ GNN
        x = self.conv2(x, edge_index)
        x = self.layer_norm(x)
        
        return x

class AdaptiveJointAttention(nn.Module):
    """
    è‡ªé€‚åº”å…³èŠ‚æ³¨æ„åŠ›æœºåˆ¶
    å¯ä»¥å¤„ç†ä»»æ„æ•°é‡çš„å…³èŠ‚
    """
    def __init__(self, joint_feature_dim: int = 32, attention_dim: int = 64):
        super(AdaptiveJointAttention, self).__init__()
        self.joint_feature_dim = joint_feature_dim
        self.attention_dim = attention_dim
        
        # æ³¨æ„åŠ›è®¡ç®—
        self.attention_net = nn.Sequential(
            nn.Linear(joint_feature_dim, attention_dim),
            nn.ReLU(),
            nn.Linear(attention_dim, 1)
        )
        
        print(f"ğŸ¯ AdaptiveJointAttention åˆå§‹åŒ–: joint_dim={joint_feature_dim}, attention_dim={attention_dim}")
    
    def forward(self, joint_features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è®¡ç®—å…³èŠ‚æ³¨æ„åŠ›æƒé‡
        joint_features: [batch_size, num_joints, joint_feature_dim]
        return: (weighted_features, attention_weights)
        """
        batch_size, num_joints, feature_dim = joint_features.shape
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        attention_scores = self.attention_net(joint_features)  # [batch_size, num_joints, 1]
        attention_weights = F.softmax(attention_scores, dim=1)  # [batch_size, num_joints, 1]
        
        # åº”ç”¨æ³¨æ„åŠ›æƒé‡
        weighted_features = joint_features * attention_weights  # [batch_size, num_joints, feature_dim]
        
        return weighted_features, attention_weights.squeeze(-1)

class GNNAttentionExtractor(BaseFeaturesExtractor):
    """
    GNN + æ³¨æ„åŠ›ç‰¹å¾æå–å™¨
    æ”¯æŒä»»æ„æ•°é‡å…³èŠ‚çš„ Reacher ä»»åŠ¡
    """
    def __init__(self, observation_space: gym.Space, features_dim: int = 128, num_joints: int = 2, gnn_type: str = "GCN"):
        super(GNNAttentionExtractor, self).__init__(observation_space, features_dim)
        
        self.obs_dim = observation_space.shape[0]
        self.num_joints = num_joints
        self.gnn_type = gnn_type
        
        print(f"ğŸ” GNNAttentionExtractor åˆå§‹åŒ–:")
        print(f"   è§‚å¯Ÿç©ºé—´ç»´åº¦: {self.obs_dim}")
        print(f"   å…³èŠ‚æ•°é‡: {num_joints}")
        print(f"   è¾“å‡ºç‰¹å¾ç»´åº¦: {features_dim}")
        print(f"   GNN ç±»å‹: {gnn_type}")
        
        # ç»„ä»¶åˆå§‹åŒ–
        self.graph_builder = JointGraphBuilder(max_joints=10)
        
        # å…³èŠ‚ç‰¹å¾å¤„ç†
        joint_input_dim = 2  # æ¯ä¸ªå…³èŠ‚: [angle, velocity]
        joint_hidden_dim = 32
        joint_output_dim = 32
        
        self.joint_encoder = nn.Sequential(
            nn.Linear(joint_input_dim, joint_hidden_dim),
            nn.ReLU(),
            nn.LayerNorm(joint_hidden_dim),
            nn.Linear(joint_hidden_dim, joint_output_dim)
        )
        
        # GNN å±‚
        self.gnn = GNNLayer(
            input_dim=joint_output_dim,
            hidden_dim=64,
            output_dim=joint_output_dim,
            gnn_type=gnn_type
        )
        
        # è‡ªé€‚åº”æ³¨æ„åŠ›
        self.joint_attention = AdaptiveJointAttention(
            joint_feature_dim=joint_output_dim,
            attention_dim=64
        )
        
        # å…¨å±€ç‰¹å¾å¤„ç† (ä½ç½®ã€ç›®æ ‡ç­‰éå…³èŠ‚ä¿¡æ¯)
        if num_joints == 2:
            # MuJoCo Reacher-v5: [4:6] end effector, [6:8] target, [8:10] vector
            global_feature_dim = 6  # end_effector(2) + target(2) + vector(2)
        else:
            # é€šç”¨æƒ…å†µ
            global_feature_dim = max(0, self.obs_dim - 2 * num_joints)
        
        self.global_encoder = nn.Sequential(
            nn.Linear(global_feature_dim, 64),
            nn.ReLU(),
            nn.LayerNorm(64),
            nn.Linear(64, 64)
        ) if global_feature_dim > 0 else nn.Identity()
        
        # ç‰¹å¾èåˆ
        fusion_input_dim = joint_output_dim + (64 if global_feature_dim > 0 else 0)
        self.fusion_net = nn.Sequential(
            nn.Linear(fusion_input_dim, features_dim),
            nn.ReLU(),
            nn.LayerNorm(features_dim),
            nn.Dropout(0.1),
            nn.Linear(features_dim, features_dim)
        )
        
        # é¢„æ„å»ºå›¾ç»“æ„ (å¯¹äºå›ºå®šå…³èŠ‚æ•°)
        self.edge_index, self.edge_attr = self.graph_builder.build_chain_graph(num_joints)
        
        print(f"âœ… GNNAttentionExtractor æ„å»ºå®Œæˆ")
        print(f"   å…³èŠ‚ç‰¹å¾ç»´åº¦: {joint_input_dim}â†’{joint_output_dim}")
        print(f"   å…¨å±€ç‰¹å¾ç»´åº¦: {global_feature_dim}")
        print(f"   èåˆè¾“å…¥ç»´åº¦: {fusion_input_dim}")
        print(f"   å›¾è¾¹æ•°: {self.edge_index.size(1)}")
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        observations: [batch_size, obs_dim]
        return: [batch_size, features_dim]
        """
        batch_size = observations.size(0)
        device = observations.device
        
        # ç§»åŠ¨å›¾ç»“æ„åˆ°æ­£ç¡®è®¾å¤‡
        edge_index = self.edge_index.to(device)
        
        # 1. æå–å…³èŠ‚ç‰¹å¾
        joint_features = self.graph_builder.extract_joint_features(observations, self.num_joints)
        # joint_features: [batch_size, num_joints, 2]
        
        # 2. ç¼–ç å…³èŠ‚ç‰¹å¾
        joint_encoded = self.joint_encoder(joint_features)
        # joint_encoded: [batch_size, num_joints, joint_output_dim]
        
        # 3. å‡†å¤‡ GNN è¾“å…¥
        # é‡å¡‘ä¸º [batch_size * num_joints, joint_output_dim]
        joint_flat = joint_encoded.view(-1, joint_encoded.size(-1))
        
        # åˆ›å»ºæ‰¹æ¬¡ç´¢å¼•
        batch_idx = torch.arange(batch_size, device=device).repeat_interleave(self.num_joints)
        
        # è°ƒæ•´è¾¹ç´¢å¼•ä»¥é€‚åº”æ‰¹å¤„ç†
        edge_index_batch = edge_index.clone()
        for i in range(1, batch_size):
            batch_edges = edge_index + i * self.num_joints
            edge_index_batch = torch.cat([edge_index_batch, batch_edges], dim=1)
        
        # 4. GNN å¤„ç†
        joint_gnn_output = self.gnn(joint_flat, edge_index_batch, batch_idx)
        # joint_gnn_output: [batch_size * num_joints, joint_output_dim]
        
        # é‡å¡‘å› [batch_size, num_joints, joint_output_dim]
        joint_gnn_reshaped = joint_gnn_output.view(batch_size, self.num_joints, -1)
        
        # 5. å…³èŠ‚æ³¨æ„åŠ›
        joint_attended, attention_weights = self.joint_attention(joint_gnn_reshaped)
        # joint_attended: [batch_size, num_joints, joint_output_dim]
        
        # 6. å…¨å±€æ± åŒ–å…³èŠ‚ç‰¹å¾
        joint_global = torch.mean(joint_attended, dim=1)  # [batch_size, joint_output_dim]
        
        # 7. å¤„ç†å…¨å±€ç‰¹å¾ (éå…³èŠ‚ä¿¡æ¯)
        if self.num_joints == 2:
            # MuJoCo Reacher-v5
            global_features = observations[:, 4:]  # [batch_size, 6]
            global_encoded = self.global_encoder(global_features)  # [batch_size, 64]
        else:
            # é€šç”¨æƒ…å†µ
            if self.obs_dim > 2 * self.num_joints:
                global_features = observations[:, 2*self.num_joints:]
                global_encoded = self.global_encoder(global_features)
            else:
                global_encoded = torch.zeros(batch_size, 0, device=device)
        
        # 8. ç‰¹å¾èåˆ
        if global_encoded.size(1) > 0:
            fused_features = torch.cat([joint_global, global_encoded], dim=1)
        else:
            fused_features = joint_global
        
        output = self.fusion_net(fused_features)
        
        return output

class AdaptiveActionHead(nn.Module):
    """
    è‡ªé€‚åº”åŠ¨ä½œå¤´ - å¯ä»¥ç”Ÿæˆä»»æ„æ•°é‡å…³èŠ‚çš„åŠ¨ä½œ
    """
    def __init__(self, input_dim: int, num_joints: int, hidden_dim: int = 128):
        super(AdaptiveActionHead, self).__init__()
        self.input_dim = input_dim
        self.num_joints = num_joints
        self.hidden_dim = hidden_dim
        
        # å…±äº«ç‰¹å¾å¤„ç†
        self.shared_net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.LayerNorm(hidden_dim),
            nn.Dropout(0.1)
        )
        
        # æ¯ä¸ªå…³èŠ‚çš„åŠ¨ä½œå¤´
        self.joint_heads = nn.ModuleList([
            nn.Sequential(
                nn.Linear(hidden_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Linear(hidden_dim // 2, 1)  # æ¯ä¸ªå…³èŠ‚è¾“å‡º1ä¸ªåŠ¨ä½œ
            ) for _ in range(num_joints)
        ])
        
        print(f"ğŸ® AdaptiveActionHead åˆå§‹åŒ–: {input_dim}â†’{hidden_dim}, {num_joints}ä¸ªå…³èŠ‚")
    
    def forward(self, features: torch.Tensor) -> torch.Tensor:
        """
        ç”Ÿæˆå…³èŠ‚åŠ¨ä½œ
        features: [batch_size, input_dim]
        return: [batch_size, num_joints]
        """
        shared_features = self.shared_net(features)
        
        joint_actions = []
        for joint_head in self.joint_heads:
            action = joint_head(shared_features)  # [batch_size, 1]
            joint_actions.append(action)
        
        actions = torch.cat(joint_actions, dim=1)  # [batch_size, num_joints]
        return actions

def sac_with_gnn_attention_training(num_joints: int = 2, gnn_type: str = "GCN"):
    print("ğŸš€ SAC + GNN + æ³¨æ„åŠ›æœºåˆ¶è®­ç»ƒ")
    print(f"ğŸ”— å…³èŠ‚æ•°é‡: {num_joints}")
    print(f"ğŸ§  GNN ç±»å‹: {gnn_type}")
    print("ğŸ¯ æ”¯æŒä»»æ„æ•°é‡å…³èŠ‚ï¼Œä¸ºå¤šå…³èŠ‚ Reacher åšå‡†å¤‡")
    print("=" * 70)
    
    # åˆ›å»ºåŸç”Ÿ MuJoCo Reacher ç¯å¢ƒ
    print("ğŸ­ åˆ›å»º MuJoCo Reacher-v5 ç¯å¢ƒ...")
    env = gym.make('Reacher-v5', render_mode='human')
    env = Monitor(env)
    
    print(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ")
    print(f"ğŸ® åŠ¨ä½œç©ºé—´: {env.action_space}")
    print(f"ğŸ‘ï¸ è§‚å¯Ÿç©ºé—´: {env.observation_space}")
    print(f"ğŸ“ è§‚å¯Ÿç»´åº¦: {env.observation_space.shape}")
    print(f"ğŸ”— å®é™…å…³èŠ‚æ•°: {env.action_space.shape[0]} (ç¯å¢ƒå›ºå®š)")
    print(f"ğŸ§  æ¨¡å‹å…³èŠ‚æ•°: {num_joints} (æ¨¡å‹è®¾è®¡)")
    
    # åˆ›å»ºè¯„ä¼°ç¯å¢ƒ
    eval_env = gym.make('Reacher-v5')
    eval_env = Monitor(eval_env)
    
    print("=" * 70)
    
    # åˆ›å»º GNN + æ³¨æ„åŠ› SAC æ¨¡å‹
    print("ğŸ¤– åˆ›å»º SAC + GNN + æ³¨æ„åŠ›æ¨¡å‹...")
    
    # å®šä¹‰ç­–ç•¥å‚æ•°
    policy_kwargs = {
        "features_extractor_class": GNNAttentionExtractor,
        "features_extractor_kwargs": {
            "features_dim": 128,
            "num_joints": num_joints,
            "gnn_type": gnn_type
        },
        "net_arch": [256, 256],  # Actor å’Œ Critic ç½‘ç»œæ¶æ„
        "activation_fn": torch.nn.ReLU,
    }
    
    model = SAC(
        "MlpPolicy",
        env,
        learning_rate=3e-4,          # ä¸ä¹‹å‰ç›¸åŒ
        buffer_size=1000000,         # ä¸ä¹‹å‰ç›¸åŒ
        learning_starts=100,         # ä¸ä¹‹å‰ç›¸åŒ
        batch_size=256,              # ä¸ä¹‹å‰ç›¸åŒ
        tau=0.005,                   # ä¸ä¹‹å‰ç›¸åŒ
        gamma=0.99,                  # ä¸ä¹‹å‰ç›¸åŒ
        train_freq=1,                # ä¸ä¹‹å‰ç›¸åŒ
        gradient_steps=1,            # ä¸ä¹‹å‰ç›¸åŒ
        ent_coef='auto',             # ä¸ä¹‹å‰ç›¸åŒ
        target_update_interval=1,    # ä¸ä¹‹å‰ç›¸åŒ
        use_sde=False,               # ä¸ä¹‹å‰ç›¸åŒ
        policy_kwargs=policy_kwargs, # GNN + æ³¨æ„åŠ›æœºåˆ¶
        verbose=1,
        device='cpu'
    )
    
    print("âœ… SAC + GNN + æ³¨æ„åŠ›æ¨¡å‹åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°:")
    print(f"   ç­–ç•¥: MlpPolicy + GNNAttentionExtractor")
    print(f"   GNN ç±»å‹: {gnn_type}")
    print(f"   å…³èŠ‚æ•°é‡: {num_joints}")
    print(f"   ç‰¹å¾ç»´åº¦: 128")
    print(f"   ç½‘ç»œæ¶æ„: [256, 256]")
    print(f"   æ”¯æŒä»»æ„å…³èŠ‚æ•°é‡")
    
    print("=" * 70)
    
    # åˆ›å»ºè¯„ä¼°å›è°ƒ
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=f'./sac_gnn_attention_{gnn_type}_{num_joints}joints_best/',
        log_path=f'./sac_gnn_attention_{gnn_type}_{num_joints}joints_logs/',
        eval_freq=5000,
        n_eval_episodes=10,
        deterministic=True,
        render=False
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
    print("ğŸ“Š è®­ç»ƒé…ç½®:")
    print("   æ€»æ­¥æ•°: 50,000")
    print("   è¯„ä¼°é¢‘ç‡: æ¯ 5,000 æ­¥")
    print("   é¢„æœŸ: GNN å¢å¼ºå…³èŠ‚é—´åè°ƒï¼Œæ³¨æ„åŠ›æå‡ç‰¹å¾é€‰æ‹©")
    print("=" * 70)
    
    start_time = time.time()
    
    # è®­ç»ƒæ¨¡å‹
    model.learn(
        total_timesteps=50000,
        callback=eval_callback,
        log_interval=10,
        progress_bar=True
    )
    
    training_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ† è®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸ è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
    print("=" * 70)
    
    # ä¿å­˜æ¨¡å‹
    model.save(f"sac_gnn_attention_{gnn_type}_{num_joints}joints_final")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º: sac_gnn_attention_{gnn_type}_{num_joints}joints_final.zip")
    
    # æœ€ç»ˆè¯„ä¼°
    print("\nğŸ” æœ€ç»ˆè¯„ä¼° (20 episodes)...")
    mean_reward, std_reward = evaluate_policy(
        model, 
        eval_env, 
        n_eval_episodes=20,
        deterministic=True,
        render=False
    )
    
    print(f"ğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœ:")
    print(f"   å¹³å‡å¥–åŠ±: {mean_reward:.2f} Â± {std_reward:.2f}")
    
    # ä¸ä¹‹å‰ç»“æœå¯¹æ¯”
    baseline_reward = -4.86
    simple_attention_reward = -4.69
    
    improvement_vs_baseline = mean_reward - baseline_reward
    improvement_vs_simple = mean_reward - simple_attention_reward
    
    print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
    print(f"   Baseline SAC: {baseline_reward:.2f}")
    print(f"   ç®€åŒ–æ³¨æ„åŠ›: {simple_attention_reward:.2f}")
    print(f"   GNN + æ³¨æ„åŠ›: {mean_reward:.2f}")
    print(f"   vs Baseline: {improvement_vs_baseline:+.2f}")
    print(f"   vs ç®€åŒ–æ³¨æ„åŠ›: {improvement_vs_simple:+.2f}")
    
    if improvement_vs_baseline > 0.3 and improvement_vs_simple > 0.1:
        print("   ğŸ‰ GNN + æ³¨æ„åŠ›æ•ˆæœæœ€ä½³!")
    elif improvement_vs_baseline > 0.1:
        print("   ğŸ‘ GNN + æ³¨æ„åŠ›æœ‰æ•ˆæ”¹è¿›!")
    elif improvement_vs_baseline > -0.1:
        print("   âš–ï¸ GNN + æ³¨æ„åŠ›æ•ˆæœç›¸å½“")
    else:
        print("   âš ï¸ GNN + æ³¨æ„åŠ›éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    # æ¼”ç¤ºè®­ç»ƒå¥½çš„æ¨¡å‹
    print("\nğŸ® æ¼”ç¤ºè®­ç»ƒå¥½çš„æ¨¡å‹ (10 episodes)...")
    demo_env = gym.make('Reacher-v5', render_mode='human')
    
    episode_rewards = []
    episode_lengths = []
    success_count = 0
    
    for episode in range(10):
        obs, info = demo_env.reset()
        episode_reward = 0
        episode_length = 0
        
        while True:
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = demo_env.step(action)
            
            episode_reward += reward
            episode_length += 1
            
            if terminated or truncated:
                break
        
        episode_rewards.append(episode_reward)
        episode_lengths.append(episode_length)
        
        # åˆ¤æ–­æˆåŠŸ
        if episode_reward > -5:
            success_count += 1
            print(f"ğŸ¯ Episode {episode+1}: æˆåŠŸ! å¥–åŠ±={episode_reward:.2f}, é•¿åº¦={episode_length}")
        else:
            print(f"ğŸ“Š Episode {episode+1}: å¥–åŠ±={episode_reward:.2f}, é•¿åº¦={episode_length}")
    
    demo_env.close()
    
    # æ¼”ç¤ºç»Ÿè®¡
    demo_success_rate = success_count / 10
    demo_avg_reward = np.mean(episode_rewards)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š æ¼”ç¤ºç»Ÿè®¡:")
    print(f"   æˆåŠŸç‡: {demo_success_rate:.1%} ({success_count}/10)")
    print(f"   å¹³å‡å¥–åŠ±: {demo_avg_reward:.2f}")
    print(f"   å¹³å‡é•¿åº¦: {np.mean(episode_lengths):.1f}")
    print(f"   å¥–åŠ±æ ‡å‡†å·®: {np.std(episode_rewards):.2f}")
    
    # ä¸ä¹‹å‰æ¼”ç¤ºå¯¹æ¯”
    baseline_demo_success = 0.9
    simple_demo_success = 0.7
    baseline_demo_reward = -4.82
    simple_demo_reward = -3.91
    
    print(f"\nğŸ“ˆ æ¼”ç¤ºæ•ˆæœå¯¹æ¯”:")
    print(f"   Baseline æˆåŠŸç‡: {baseline_demo_success:.1%}")
    print(f"   ç®€åŒ–æ³¨æ„åŠ›æˆåŠŸç‡: {simple_demo_success:.1%}")
    print(f"   GNN + æ³¨æ„åŠ›æˆåŠŸç‡: {demo_success_rate:.1%}")
    print(f"   ")
    print(f"   Baseline å¹³å‡å¥–åŠ±: {baseline_demo_reward:.2f}")
    print(f"   ç®€åŒ–æ³¨æ„åŠ›å¹³å‡å¥–åŠ±: {simple_demo_reward:.2f}")
    print(f"   GNN + æ³¨æ„åŠ›å¹³å‡å¥–åŠ±: {demo_avg_reward:.2f}")
    
    # è®­ç»ƒæ—¶é—´å¯¹æ¯”
    baseline_time = 14.3
    simple_time = 16.4
    time_vs_baseline = training_time/60 - baseline_time
    time_vs_simple = training_time/60 - simple_time
    
    print(f"\nâ±ï¸ è®­ç»ƒæ—¶é—´å¯¹æ¯”:")
    print(f"   Baseline: {baseline_time:.1f} åˆ†é’Ÿ")
    print(f"   ç®€åŒ–æ³¨æ„åŠ›: {simple_time:.1f} åˆ†é’Ÿ")
    print(f"   GNN + æ³¨æ„åŠ›: {training_time/60:.1f} åˆ†é’Ÿ")
    print(f"   vs Baseline: {time_vs_baseline:+.1f} åˆ†é’Ÿ")
    print(f"   vs ç®€åŒ–æ³¨æ„åŠ›: {time_vs_simple:+.1f} åˆ†é’Ÿ")
    
    if abs(time_vs_simple) < 3:
        print("   âœ… è®­ç»ƒæ—¶é—´å¢åŠ å¯æ¥å—ï¼ŒGNN å¼€é”€åˆç†")
    elif time_vs_simple > 5:
        print("   âš ï¸ è®­ç»ƒæ—¶é—´æ˜¾è‘—å¢åŠ ï¼ŒGNN è®¡ç®—å¼€é”€è¾ƒå¤§")
    
    print("\nâœ… SAC + GNN + æ³¨æ„åŠ›è®­ç»ƒå®Œæˆ!")
    print("ğŸ”— æ¨¡å‹å·²å‡†å¤‡å¥½å¤„ç†å¤šå…³èŠ‚ Reacher ä»»åŠ¡!")
    
    # æ¸…ç†
    env.close()
    eval_env.close()
    
    return {
        'mean_reward': mean_reward,
        'std_reward': std_reward,
        'training_time': training_time,
        'demo_success_rate': demo_success_rate,
        'demo_avg_reward': demo_avg_reward,
        'improvement_vs_baseline': improvement_vs_baseline,
        'improvement_vs_simple': improvement_vs_simple,
        'time_vs_baseline': time_vs_baseline,
        'time_vs_simple': time_vs_simple
    }

if __name__ == "__main__":
    print("ğŸ”¥ å¼€å§‹ SAC + GNN + æ³¨æ„åŠ›æœºåˆ¶è®­ç»ƒ")
    print("ğŸ”— æ”¯æŒä»»æ„æ•°é‡å…³èŠ‚çš„ Reacher ä»»åŠ¡")
    print("ğŸ¯ ä¸ºå¤šå…³èŠ‚ Reacher åšå‡†å¤‡")
    print()
    
    # æµ‹è¯•ä¸åŒé…ç½®
    configs = [
        {"num_joints": 2, "gnn_type": "GCN"},
        # {"num_joints": 2, "gnn_type": "GAT"},  # å¯é€‰: æµ‹è¯•ä¸åŒ GNN ç±»å‹
    ]
    
    for config in configs[:1]:  # å…ˆæµ‹è¯•ä¸€ä¸ªé…ç½®
        print(f"\n{'='*60}")
        print(f"ğŸ§  æµ‹è¯•é…ç½®: {config['num_joints']} å…³èŠ‚, {config['gnn_type']} GNN")
        print(f"{'='*60}")
        
        try:
            results = sac_with_gnn_attention_training(**config)
            
            print(f"\nğŸŠ {config} è®­ç»ƒç»“æœæ€»ç»“:")
            print(f"   æœ€ç»ˆè¯„ä¼°å¥–åŠ±: {results['mean_reward']:.2f} Â± {results['std_reward']:.2f}")
            print(f"   è®­ç»ƒæ—¶é—´: {results['training_time']/60:.1f} åˆ†é’Ÿ")
            print(f"   æ¼”ç¤ºæˆåŠŸç‡: {results['demo_success_rate']:.1%}")
            print(f"   æ¼”ç¤ºå¹³å‡å¥–åŠ±: {results['demo_avg_reward']:.2f}")
            print(f"   vs Baseline æ”¹è¿›: {results['improvement_vs_baseline']:+.2f}")
            print(f"   vs ç®€åŒ–æ³¨æ„åŠ›æ”¹è¿›: {results['improvement_vs_simple']:+.2f}")
            print(f"   è®­ç»ƒæ—¶é—´ vs Baseline: {results['time_vs_baseline']:+.1f} åˆ†é’Ÿ")
            print(f"   è®­ç»ƒæ—¶é—´ vs ç®€åŒ–æ³¨æ„åŠ›: {results['time_vs_simple']:+.1f} åˆ†é’Ÿ")
            
            # æ€»ä½“è¯„ä¼°
            if (results['improvement_vs_baseline'] > 0.3 and 
                results['demo_success_rate'] > 0.8 and 
                results['time_vs_simple'] < 5):
                print(f"\nğŸ† GNN + æ³¨æ„åŠ›æœºåˆ¶è¡¨ç°ä¼˜ç§€!")
                print("   æ€§èƒ½æå‡ + é«˜æˆåŠŸç‡ + åˆç†è®­ç»ƒæ—¶é—´")
            elif results['improvement_vs_baseline'] > 0.1:
                print(f"\nğŸ‘ GNN + æ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆ!")
            else:
                print(f"\nâš ï¸ GNN + æ³¨æ„åŠ›æœºåˆ¶éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            
            print(f"\nğŸ”— æ¨¡å‹å·²å‡†å¤‡å¥½æ‰©å±•åˆ°å¤šå…³èŠ‚ Reacher!")
            
        except Exception as e:
            print(f"âŒ {config} è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
