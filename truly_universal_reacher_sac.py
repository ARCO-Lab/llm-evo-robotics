#!/usr/bin/env python3
"""
çœŸæ­£é€šç”¨ Reacher SAC æ¶æ„
åŸºäº GPT-5 å»ºè®®çš„å®Œæ•´å®ç°ï¼š
A. å¯å˜å…³èŠ‚æ•°ç¯å¢ƒåŒ…è£…å™¨
B. è‡ªå®šä¹‰ SAC ç­–ç•¥æ”¯æŒ J_max ç»´è¾“å‡º
C. çœŸæ­£æ”¯æŒä»»æ„å…³èŠ‚æ•°è®­ç»ƒ
"""

import gymnasium as gym
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import time
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.policies import ActorCriticPolicy
from stable_baselines3.common.distributions import SquashedDiagGaussianDistribution
from stable_baselines3.common.type_aliases import Schedule
from typing import Dict, List, Tuple, Type, Union, Optional, Any
import math

# ============================================================================
# ğŸ§© æ–¹æ¡ˆ A: å¯å˜å…³èŠ‚æ•°ç¯å¢ƒåŒ…è£…å™¨
# ============================================================================

class VariableJointReacherWrapper(gym.Wrapper):
    """
    å¯å˜å…³èŠ‚æ•° Reacher ç¯å¢ƒåŒ…è£…å™¨
    
    åŠŸèƒ½ï¼š
    1. ç»Ÿä¸€ action_space åˆ° J_max ç»´
    2. ç»Ÿä¸€ observation_space åˆ° padded ç»´åº¦
    3. æ”¯æŒåŠ¨æ€åˆ‡æ¢å…³èŠ‚æ•°
    4. æä¾› mask å’Œ link_lengths ä¿¡æ¯
    """
    
    def __init__(self, env, max_joints: int = 10, current_joints: int = 2, 
                 link_lengths: Optional[List[float]] = None):
        super(VariableJointReacherWrapper, self).__init__(env)
        
        self.max_joints = max_joints
        self.current_joints = current_joints
        self.original_action_space = env.action_space
        self.original_obs_space = env.observation_space
        
        # è®¾ç½® link é•¿åº¦
        if link_lengths is None:
            self.link_lengths = [0.1] * max_joints
        else:
            self.link_lengths = link_lengths + [0.1] * (max_joints - len(link_lengths))
        
        # é‡æ–°å®šä¹‰åŠ¨ä½œç©ºé—´ä¸º J_max ç»´
        self.action_space = gym.spaces.Box(
            low=-1.0, high=1.0, 
            shape=(max_joints,), 
            dtype=np.float32
        )
        
        # é‡æ–°å®šä¹‰è§‚å¯Ÿç©ºé—´ (padding åˆ°é€‚åˆ J_max çš„ç»´åº¦)
        # åŸå§‹ Reacher-v5: 10ç»´ [cos1, sin1, cos2, sin2, vel1, vel2, ee_x, ee_y, target_x, target_y]
        # é€šç”¨æ ¼å¼: J_max*4 + global_features
        padded_obs_dim = max_joints * 4 + 4  # 4 global features (ee + target)
        self.observation_space = gym.spaces.Box(
            low=-np.inf, high=np.inf,
            shape=(padded_obs_dim,),
            dtype=np.float32
        )
        
        print(f"ğŸŒ VariableJointReacherWrapper åˆå§‹åŒ–:")
        print(f"   åŸå§‹ç¯å¢ƒ: {env.spec.id if hasattr(env, 'spec') else 'Unknown'}")
        print(f"   å½“å‰å…³èŠ‚æ•°: {current_joints}")
        print(f"   æœ€å¤§å…³èŠ‚æ•°: {max_joints}")
        print(f"   åŸå§‹åŠ¨ä½œç©ºé—´: {self.original_action_space}")
        print(f"   åŒ…è£…ååŠ¨ä½œç©ºé—´: {self.action_space}")
        print(f"   åŸå§‹è§‚å¯Ÿç©ºé—´: {self.original_obs_space}")
        print(f"   åŒ…è£…åè§‚å¯Ÿç©ºé—´: {self.observation_space}")
        print(f"   Link é•¿åº¦: {self.link_lengths[:current_joints]}")
    
    def set_joint_config(self, num_joints: int, link_lengths: Optional[List[float]] = None):
        """åŠ¨æ€è®¾ç½®å…³èŠ‚é…ç½®"""
        self.current_joints = min(num_joints, self.max_joints)
        if link_lengths is not None:
            self.link_lengths[:len(link_lengths)] = link_lengths
        
        print(f"ğŸ”„ æ›´æ–°å…³èŠ‚é…ç½®: {self.current_joints} å…³èŠ‚, Linké•¿åº¦: {self.link_lengths[:self.current_joints]}")
    
    def _pad_observation(self, obs: np.ndarray) -> np.ndarray:
        """
        å°†åŸå§‹è§‚å¯Ÿ padding åˆ°ç»Ÿä¸€æ ¼å¼
        
        MuJoCo Reacher-v5 è§‚å¯Ÿæ ¼å¼ (10ç»´):
        [0-1]: cos/sin of joint 1 angle
        [2-3]: cos/sin of joint 2 angle  
        [4-5]: joint 1 and joint 2 velocities
        [6-7]: end effector position (x, y)
        [8-9]: target position (x, y)
        
        è½¬æ¢ä¸ºé€šç”¨æ ¼å¼: [joint_features_padded, global_features]
        joint_features: [cos, sin, vel, link_length] Ã— max_joints
        global_features: [ee_x, ee_y, target_x, target_y]
        """
        # è§£æåŸå§‹è§‚å¯Ÿ
        if self.current_joints == 2 and len(obs) == 10:
            # MuJoCo Reacher-v5 æ ¼å¼
            joint1_cos, joint1_sin = obs[0], obs[1]
            joint2_cos, joint2_sin = obs[2], obs[3]
            joint1_vel, joint2_vel = obs[4], obs[5]
            ee_x, ee_y = obs[6], obs[7]
            target_x, target_y = obs[8], obs[9]
            
            # æ„é€ å…³èŠ‚ç‰¹å¾
            joint_features = []
            
            # Joint 1: [cos, sin, vel, link_length]
            joint1_feature = [joint1_cos, joint1_sin, joint1_vel, self.link_lengths[0]]
            joint_features.extend(joint1_feature)
            
            # Joint 2: [cos, sin, vel, link_length]
            joint2_feature = [joint2_cos, joint2_sin, joint2_vel, self.link_lengths[1]]
            joint_features.extend(joint2_feature)
            
            # Padding å‰©ä½™å…³èŠ‚ (å…¨é›¶ + link_length)
            for i in range(2, self.max_joints):
                padding_feature = [0.0, 0.0, 0.0, self.link_lengths[i]]
                joint_features.extend(padding_feature)
            
            # å…¨å±€ç‰¹å¾
            global_features = [ee_x, ee_y, target_x, target_y]
            
            # ç»„åˆ
            padded_obs = np.array(joint_features + global_features, dtype=np.float32)
            
        else:
            # é€šç”¨æ ¼å¼æˆ–å…¶ä»–æƒ…å†µï¼Œç®€å• padding
            padded_obs = np.zeros(self.observation_space.shape[0], dtype=np.float32)
            copy_len = min(len(obs), len(padded_obs))
            padded_obs[:copy_len] = obs[:copy_len]
        
        return padded_obs
    
    def _unpad_action(self, action: np.ndarray) -> np.ndarray:
        """å°† J_max ç»´åŠ¨ä½œåˆ‡ç‰‡åˆ°å½“å‰å…³èŠ‚æ•°"""
        # åªå–å‰ current_joints ç»´
        unpadded_action = action[:self.current_joints]
        
        # ç¡®ä¿ç»´åº¦åŒ¹é…åŸå§‹ç¯å¢ƒ
        if len(unpadded_action) != self.original_action_space.shape[0]:
            # å¦‚æœç»´åº¦ä¸åŒ¹é…ï¼Œæˆªæ–­æˆ–å¡«å……åˆ°åŸå§‹ç»´åº¦
            original_dim = self.original_action_space.shape[0]
            if len(unpadded_action) > original_dim:
                unpadded_action = unpadded_action[:original_dim]
            else:
                padded_action = np.zeros(original_dim, dtype=np.float32)
                padded_action[:len(unpadded_action)] = unpadded_action
                unpadded_action = padded_action
        
        return unpadded_action
    
    def reset(self, **kwargs):
        """é‡ç½®ç¯å¢ƒ"""
        obs, info = self.env.reset(**kwargs)
        
        # Padding è§‚å¯Ÿ
        padded_obs = self._pad_observation(obs)
        
        # æ·»åŠ å…³èŠ‚é…ç½®ä¿¡æ¯åˆ° info
        info['num_joints'] = self.current_joints
        info['max_joints'] = self.max_joints
        info['link_lengths'] = self.link_lengths[:self.current_joints]
        info['joint_mask'] = [True] * self.current_joints + [False] * (self.max_joints - self.current_joints)
        
        return padded_obs, info
    
    def step(self, action):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        # å°† J_max ç»´åŠ¨ä½œåˆ‡ç‰‡åˆ°å½“å‰å…³èŠ‚æ•°
        unpadded_action = self._unpad_action(action)
        
        # åœ¨åŸå§‹ç¯å¢ƒä¸­æ‰§è¡Œ
        obs, reward, terminated, truncated, info = self.env.step(unpadded_action)
        
        # Padding è§‚å¯Ÿ
        padded_obs = self._pad_observation(obs)
        
        # æ·»åŠ å…³èŠ‚é…ç½®ä¿¡æ¯åˆ° info
        info['num_joints'] = self.current_joints
        info['max_joints'] = self.max_joints
        info['link_lengths'] = self.link_lengths[:self.current_joints]
        info['joint_mask'] = [True] * self.current_joints + [False] * (self.max_joints - self.current_joints)
        
        return padded_obs, reward, terminated, truncated, info

# ============================================================================
# ğŸ§© å¤ç”¨ç°æœ‰çš„ä¼˜ç§€ç‰¹å¾æå–ç»„ä»¶
# ============================================================================

class CorrectMaskSystem:
    """ä¿®å¤ç‰ˆ Mask ç³»ç»Ÿ"""
    
    @staticmethod
    def create_joint_mask(batch_size: int, num_joints: int, max_joints: int, device: torch.device) -> torch.Tensor:
        mask = torch.zeros(batch_size, max_joints, dtype=torch.bool, device=device)
        mask[:, :num_joints] = True
        return mask
    
    @staticmethod
    def parse_observation_universal(obs: torch.Tensor, max_joints: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        é€šç”¨è§‚å¯Ÿè§£æï¼šä»åŒ…è£…å™¨çš„ç»Ÿä¸€æ ¼å¼è§£æ
        obs: [batch_size, max_joints*4 + global_dim]
        return: (joint_features, global_features)
        """
        batch_size = obs.size(0)
        
        # åˆ†ç¦»å…³èŠ‚ç‰¹å¾å’Œå…¨å±€ç‰¹å¾
        joint_dim = max_joints * 4
        joint_features_flat = obs[:, :joint_dim]  # [batch_size, max_joints*4]
        global_features = obs[:, joint_dim:]      # [batch_size, global_dim]
        
        # é‡å¡‘å…³èŠ‚ç‰¹å¾
        joint_features = joint_features_flat.view(batch_size, max_joints, 4)  # [batch_size, max_joints, 4]
        
        return joint_features, global_features

class LinkAwareJointEncoder(nn.Module):
    """Link-Aware å…³èŠ‚ç¼–ç å™¨"""
    def __init__(self, joint_input_dim: int = 4, joint_feature_dim: int = 64):
        super(LinkAwareJointEncoder, self).__init__()
        self.joint_input_dim = joint_input_dim
        self.joint_feature_dim = joint_feature_dim
        
        # Link é•¿åº¦ç‰¹å¾å¤„ç†
        self.link_processor = nn.Sequential(
            nn.Linear(1, 8),
            nn.ReLU(),
            nn.LayerNorm(8)
        )
        
        # è¿åŠ¨ç‰¹å¾å¤„ç†
        self.motion_processor = nn.Sequential(
            nn.Linear(3, 24),
            nn.ReLU(),
            nn.LayerNorm(24)
        )
        
        # å‡ ä½•-è¿åŠ¨èåˆ
        self.fusion_processor = nn.Sequential(
            nn.Linear(32, joint_feature_dim),
            nn.ReLU(),
            nn.LayerNorm(joint_feature_dim)
        )
        
        print(f"ğŸ”— LinkAwareJointEncoder: {joint_input_dim} â†’ {joint_feature_dim}")
    
    def forward(self, joint_features: torch.Tensor) -> torch.Tensor:
        batch_size, max_joints, _ = joint_features.shape
        
        # åˆ†ç¦»ç‰¹å¾
        motion_features = joint_features[:, :, :3]  # [cos, sin, vel]
        link_lengths = joint_features[:, :, 3:4]    # [link_length]
        
        # é‡å¡‘
        motion_flat = motion_features.view(-1, 3)
        link_flat = link_lengths.view(-1, 1)
        
        # ç¼–ç 
        motion_encoded = self.motion_processor(motion_flat)
        link_encoded = self.link_processor(link_flat)
        
        # èåˆ
        fused_features = torch.cat([motion_encoded, link_encoded], dim=1)
        joint_encoded = self.fusion_processor(fused_features)
        
        # é‡å¡‘å›åŸå½¢çŠ¶
        encoded_features = joint_encoded.view(batch_size, max_joints, self.joint_feature_dim)
        
        return encoded_features

class FixedSelfAttention(nn.Module):
    """ä¿®å¤ç‰ˆè‡ªæ³¨æ„åŠ›"""
    def __init__(self, feature_dim: int = 64, num_heads: int = 4, dropout: float = 0.0):
        super(FixedSelfAttention, self).__init__()
        self.feature_dim = feature_dim
        self.num_heads = num_heads
        
        assert feature_dim % num_heads == 0
        
        self.multihead_attn = nn.MultiheadAttention(
            embed_dim=feature_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        
        self.layer_norm = nn.LayerNorm(feature_dim)
        self.feed_forward = nn.Sequential(
            nn.Linear(feature_dim, feature_dim * 2),
            nn.ReLU(),
            nn.Linear(feature_dim * 2, feature_dim)
        )
        self.layer_norm2 = nn.LayerNorm(feature_dim)
        
        print(f"ğŸ§  FixedSelfAttention: {feature_dim}d, {num_heads} heads")
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        key_padding_mask = None
        if mask is not None:
            key_padding_mask = ~mask
        
        attn_output, _ = self.multihead_attn(
            query=x, key=x, value=x,
            key_padding_mask=key_padding_mask,
            need_weights=False
        )
        
        x = self.layer_norm(x + attn_output)
        ff_output = self.feed_forward(x)
        x = self.layer_norm2(x + ff_output)
        
        if mask is not None:
            x = x * mask.unsqueeze(-1).float()
        
        return x

class FixedAttentionPooling(nn.Module):
    """ä¿®å¤ç‰ˆæ³¨æ„åŠ›æ± åŒ–"""
    def __init__(self, input_dim: int = 64, output_dim: int = 128):
        super(FixedAttentionPooling, self).__init__()
        
        self.score = nn.Sequential(
            nn.Linear(input_dim, input_dim // 2),
            nn.ReLU(),
            nn.Linear(input_dim // 2, 1)
        )
        
        self.proj = nn.Sequential(
            nn.Linear(input_dim, output_dim),
            nn.ReLU(),
            nn.LayerNorm(output_dim)
        )
        
        print(f"ğŸ¯ FixedAttentionPooling: {input_dim} â†’ {output_dim}")
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        s = self.score(x).squeeze(-1)
        
        if mask is not None:
            s = s.masked_fill(~mask, -1e9)
        
        w = F.softmax(s, dim=1).unsqueeze(-1)
        pooled = (x * w).sum(dim=1)
        output = self.proj(pooled)
        
        return output

# ============================================================================
# ğŸ§© é€šç”¨ç‰¹å¾æå–å™¨
# ============================================================================

class TrulyUniversalExtractor(BaseFeaturesExtractor):
    """çœŸæ­£é€šç”¨ç‰¹å¾æå–å™¨"""
    def __init__(self, observation_space: gym.Space, features_dim: int = 128, 
                 max_joints: int = 10):
        super(TrulyUniversalExtractor, self).__init__(observation_space, features_dim)
        
        self.obs_dim = observation_space.shape[0]
        self.max_joints = max_joints
        self.joint_input_dim = 4  # [cos, sin, vel, link_length]
        
        print(f"ğŸŒŸ TrulyUniversalExtractor åˆå§‹åŒ–:")
        print(f"   è§‚å¯Ÿç©ºé—´ç»´åº¦: {self.obs_dim}")
        print(f"   æœ€å¤§å…³èŠ‚æ•°: {max_joints}")
        print(f"   å…³èŠ‚è¾“å…¥ç»´åº¦: {self.joint_input_dim}")
        print(f"   è¾“å‡ºç‰¹å¾ç»´åº¦: {features_dim}")
        
        # æ¨¡å—ç»„è£…
        self.joint_encoder = LinkAwareJointEncoder(
            joint_input_dim=self.joint_input_dim,
            joint_feature_dim=64
        )
        
        self.self_attention = FixedSelfAttention(
            feature_dim=64,
            num_heads=4,
            dropout=0.0
        )
        
        self.attention_pooling = FixedAttentionPooling(
            input_dim=64,
            output_dim=features_dim // 2
        )
        
        # å…¨å±€ç‰¹å¾å¤„ç†
        global_dim = 4  # [ee_x, ee_y, target_x, target_y]
        self.global_processor = nn.Sequential(
            nn.Linear(global_dim, features_dim // 2),
            nn.ReLU(),
            nn.LayerNorm(features_dim // 2)
        )
        
        # æœ€ç»ˆèåˆ
        self.final_fusion = nn.Sequential(
            nn.Linear(features_dim, features_dim),
            nn.ReLU(),
            nn.LayerNorm(features_dim)
        )
        
        # Mask ç³»ç»Ÿ
        self.mask_system = CorrectMaskSystem()
        
        print(f"âœ… TrulyUniversalExtractor æ„å»ºå®Œæˆ")
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        batch_size = observations.size(0)
        device = observations.device
        
        # è§£æè§‚å¯Ÿç©ºé—´
        joint_features, global_features = self.mask_system.parse_observation_universal(
            observations, self.max_joints
        )
        
        # åŠ¨æ€æ£€æµ‹æœ‰æ•ˆå…³èŠ‚æ•° (åŸºäº link_length != 0)
        link_lengths = joint_features[:, :, 3]  # [batch_size, max_joints]
        joint_mask = (link_lengths > 0).bool()  # [batch_size, max_joints]
        
        # å…³èŠ‚ç¼–ç 
        encoded_joints = self.joint_encoder(joint_features)
        
        # è‡ªæ³¨æ„åŠ›
        attended_joints = self.self_attention(encoded_joints, mask=joint_mask)
        
        # æ³¨æ„åŠ›æ± åŒ–
        pooled_joint_features = self.attention_pooling(attended_joints, mask=joint_mask)
        
        # å…¨å±€ç‰¹å¾å¤„ç†
        processed_global = self.global_processor(global_features)
        
        # èåˆ
        fused_features = torch.cat([pooled_joint_features, processed_global], dim=1)
        final_features = self.final_fusion(fused_features)
        
        return final_features

# ============================================================================
# ğŸ§© æ–¹æ¡ˆ B: è‡ªå®šä¹‰ SAC ç­–ç•¥æ”¯æŒ J_max ç»´è¾“å‡º
# ============================================================================

class UniversalJointGaussianHeads(nn.Module):
    """é€šç”¨é€å…³èŠ‚é«˜æ–¯å¤´ï¼šæ”¯æŒ J_max ç»´è¾“å‡º"""
    def __init__(self, input_dim: int = 128, max_joints: int = 10):
        super(UniversalJointGaussianHeads, self).__init__()
        self.input_dim = input_dim
        self.max_joints = max_joints
        
        # å…±äº«ç‰¹å¾å¤„ç†
        self.shared_net = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU()
        )
        
        # ä¸ºæ¯ä¸ªå…³èŠ‚åˆ›å»ºç‹¬ç«‹çš„é«˜æ–¯å¤´
        self.joint_heads = nn.ModuleList()
        for i in range(max_joints):
            joint_head = nn.Sequential(
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, 2)  # mean + log_std for 1D action
            )
            self.joint_heads.append(joint_head)
        
        print(f"ğŸ¯ UniversalJointGaussianHeads: {max_joints} joints, 1D each")
    
    def forward(self, features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ç”Ÿæˆ J_max ç»´é«˜æ–¯ç­–ç•¥å‚æ•°
        features: [batch_size, input_dim]
        return: (mean, log_std) æ¯ä¸ªéƒ½æ˜¯ [batch_size, max_joints]
        """
        batch_size = features.size(0)
        
        # å…±äº«ç‰¹å¾å¤„ç†
        shared_features = self.shared_net(features)
        
        # æ”¶é›†æ‰€æœ‰å…³èŠ‚çš„è¾“å‡º
        joint_outputs = []
        for i in range(self.max_joints):
            joint_output = self.joint_heads[i](shared_features)  # [batch_size, 2]
            joint_outputs.append(joint_output)
        
        # å †å æ‰€æœ‰å…³èŠ‚è¾“å‡º
        all_outputs = torch.stack(joint_outputs, dim=1)  # [batch_size, max_joints, 2]
        
        # åˆ†ç¦» mean å’Œ log_std
        mean_all = all_outputs[:, :, 0]  # [batch_size, max_joints]
        log_std_all = all_outputs[:, :, 1]  # [batch_size, max_joints]
        
        # é™åˆ¶ log_std èŒƒå›´
        log_std_all = torch.clamp(log_std_all, -20, 2)
        
        return mean_all, log_std_all

class TrulyUniversalSACPolicy(ActorCriticPolicy):
    """çœŸæ­£é€šç”¨çš„ SAC ç­–ç•¥ï¼šæ”¯æŒ J_max ç»´è¾“å‡º"""
    
    def __init__(
        self,
        observation_space: gym.Space,
        action_space: gym.Space,
        lr_schedule: Schedule,
        max_joints: int = 10,
        **kwargs
    ):
        self.max_joints = max_joints
        
        print(f"ğŸ¤– TrulyUniversalSACPolicy åˆå§‹åŒ–:")
        print(f"   æœ€å¤§å…³èŠ‚æ•°: {max_joints}")
        print(f"   åŠ¨ä½œç©ºé—´: {action_space}")
        
        super(TrulyUniversalSACPolicy, self).__init__(
            observation_space, action_space, lr_schedule, **kwargs
        )
        
        # æ›¿æ¢ action_net ä¸ºé€šç”¨é€å…³èŠ‚é«˜æ–¯å¤´
        # æ³¨æ„ï¼šlatent_pi çš„ç»´åº¦å¯èƒ½ä¸ features_dim ä¸åŒï¼Œéœ€è¦ä½¿ç”¨ net_arch çš„æœ€åä¸€å±‚
        latent_dim = self.net_arch[-1] if self.net_arch else self.features_dim
        self.action_net = UniversalJointGaussianHeads(
            input_dim=latent_dim,
            max_joints=max_joints
        )
        
        # åˆ›å»ºåˆ†å¸ƒ
        self.action_dist = SquashedDiagGaussianDistribution(max_joints)
        
        # ä¸º SB3 å…¼å®¹æ€§æ·»åŠ å¿…è¦å±æ€§
        self.actor = self.action_net
        
        # ç¡®ä¿ critic å’Œ critic_target åœ¨åˆå§‹åŒ–æ—¶å°±è®¾ç½®
        # ä½¿ç”¨ mlp_extractor ä½œä¸º critic (åœ¨ super().__init__ ä¸­å·²åˆ›å»º)
        if hasattr(self, 'mlp_extractor') and self.mlp_extractor is not None:
            self.critic = self.mlp_extractor
            import copy
            self.critic_target = copy.deepcopy(self.mlp_extractor)
        else:
            # å¦‚æœ mlp_extractor è¿˜æœªåˆ›å»ºï¼Œåˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„
            from stable_baselines3.common.torch_layers import MlpExtractor
            temp_extractor = MlpExtractor(
                self.features_dim,
                net_arch=self.net_arch,
                activation_fn=self.activation_fn,
                device=self.device,
            )
            self.critic = temp_extractor
            import copy
            self.critic_target = copy.deepcopy(temp_extractor)
        
        print(f"âœ… TrulyUniversalSACPolicy æ„å»ºå®Œæˆ")
    
    def _build_mlp_extractor(self) -> None:
        """æ„å»º MLP æå–å™¨"""
        from stable_baselines3.common.torch_layers import MlpExtractor
        
        self.mlp_extractor = MlpExtractor(
            self.features_dim,
            net_arch=self.net_arch,
            activation_fn=self.activation_fn,
            device=self.device,
        )
        
        # è®¾ç½® critic ç›¸å…³å±æ€§
        self.critic = self.mlp_extractor
        
        # åˆ›å»º critic_target (æ·±æ‹·è´)
        import copy
        self.critic_target = copy.deepcopy(self.mlp_extractor)
    
    def forward_actor(self, obs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """Actor å‰å‘ä¼ æ’­"""
        # æå–ç‰¹å¾
        features = self.extract_features(obs, self.features_extractor)
        latent_pi = self.mlp_extractor.forward_actor(features)
        
        # ç”Ÿæˆ J_max ç»´åŠ¨ä½œåˆ†å¸ƒå‚æ•°
        mean, log_std = self.action_net(latent_pi)
        
        return mean, log_std
    
    def _predict(self, observation: torch.Tensor, deterministic: bool = False) -> torch.Tensor:
        """é¢„æµ‹åŠ¨ä½œ"""
        mean, log_std = self.forward_actor(observation)
        
        # åˆ›å»ºåˆ†å¸ƒ
        self.action_dist = self.action_dist.proba_distribution(mean, log_std)
        
        # é‡‡æ ·åŠ¨ä½œ
        if deterministic:
            actions = self.action_dist.mode()
        else:
            actions = self.action_dist.sample()
        
        return actions
    
    def evaluate_actions(self, obs: torch.Tensor, actions: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """è¯„ä¼°åŠ¨ä½œ"""
        # å‰å‘ä¼ æ’­
        mean, log_std = self.forward_actor(obs)
        
        # åˆ›å»ºåˆ†å¸ƒ
        self.action_dist = self.action_dist.proba_distribution(mean, log_std)
        
        # è®¡ç®— log_prob å’Œ entropy
        log_prob = self.action_dist.log_prob(actions)
        entropy = self.action_dist.entropy()
        
        # Critic è¯„ä¼°
        features = self.extract_features(obs, self.features_extractor)
        latent_vf = self.mlp_extractor.forward_critic(features)
        values = self.value_net(latent_vf)
        
        return values, log_prob, entropy

# ============================================================================
# ğŸ§© è®­ç»ƒå‡½æ•°
# ============================================================================

def train_truly_universal_reacher_sac(max_joints: int = 10, 
                                     joint_configs: List[Tuple[int, List[float]]] = None,
                                     total_timesteps: int = 50000):
    """
    è®­ç»ƒçœŸæ­£é€šç”¨ Reacher SAC
    
    Args:
        max_joints: æœ€å¤§æ”¯æŒå…³èŠ‚æ•°
        joint_configs: [(num_joints, link_lengths), ...] å…³èŠ‚é…ç½®åˆ—è¡¨
        total_timesteps: æ€»è®­ç»ƒæ­¥æ•°
    """
    print("ğŸŒŸ çœŸæ­£é€šç”¨ Reacher SAC è®­ç»ƒ")
    print(f"ğŸ”— æœ€å¤§æ”¯æŒå…³èŠ‚æ•°: {max_joints}")
    print(f"ğŸ’¡ æ¶æ„: GPT-5 å»ºè®®çš„å®Œæ•´å®ç°")
    print(f"ğŸ¯ ç›®æ ‡: çœŸæ­£æ”¯æŒä»»æ„å…³èŠ‚æ•°è®­ç»ƒ")
    print("=" * 70)
    
    # é»˜è®¤å…³èŠ‚é…ç½®
    if joint_configs is None:
        joint_configs = [
            (2, [0.1, 0.1]),  # 2å…³èŠ‚ Reacher
            # å¯ä»¥æ·»åŠ æ›´å¤šé…ç½®
            # (3, [0.1, 0.1, 0.1]),  # 3å…³èŠ‚ Reacher
            # (4, [0.1, 0.1, 0.1, 0.1]),  # 4å…³èŠ‚ Reacher
        ]
    
    print(f"ğŸ”§ å…³èŠ‚é…ç½®:")
    for i, (num_joints, link_lengths) in enumerate(joint_configs):
        print(f"   é…ç½® {i+1}: {num_joints} å…³èŠ‚, Linké•¿åº¦: {link_lengths}")
    
    # åˆ›å»ºç¯å¢ƒ (å…ˆç”¨ç¬¬ä¸€ä¸ªé…ç½®)
    print(f"\nğŸ­ åˆ›å»ºç¯å¢ƒ...")
    base_env = gym.make('Reacher-v5')
    
    # åŒ…è£…ä¸ºå¯å˜å…³èŠ‚æ•°ç¯å¢ƒ
    num_joints, link_lengths = joint_configs[0]
    env = VariableJointReacherWrapper(
        base_env, 
        max_joints=max_joints, 
        current_joints=num_joints,
        link_lengths=link_lengths
    )
    env = Monitor(env)
    
    # è¯„ä¼°ç¯å¢ƒ
    eval_base_env = gym.make('Reacher-v5')
    eval_env = VariableJointReacherWrapper(
        eval_base_env,
        max_joints=max_joints,
        current_joints=num_joints,
        link_lengths=link_lengths
    )
    eval_env = Monitor(eval_env)
    
    print(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ")
    print(f"ğŸ® åŒ…è£…ååŠ¨ä½œç©ºé—´: {env.action_space}")
    print(f"ğŸ‘ï¸ åŒ…è£…åè§‚å¯Ÿç©ºé—´: {env.observation_space}")
    
    print("=" * 70)
    
    # åˆ›å»ºçœŸæ­£é€šç”¨æ¨¡å‹
    print("ğŸ¤– åˆ›å»ºçœŸæ­£é€šç”¨ SAC æ¨¡å‹...")
    
    policy_kwargs = {
        "features_extractor_class": TrulyUniversalExtractor,
        "features_extractor_kwargs": {
            "features_dim": 128,
            "max_joints": max_joints
        },
        "max_joints": max_joints,
        "net_arch": [256, 256],
        "activation_fn": torch.nn.ReLU,
    }
    
    model = SAC(
        TrulyUniversalSACPolicy,
        env,
        learning_rate=3e-4,
        buffer_size=1000000,
        learning_starts=100,
        batch_size=256,
        tau=0.005,
        gamma=0.99,
        train_freq=1,
        gradient_steps=1,
        ent_coef='auto',
        target_update_interval=1,
        use_sde=False,
        policy_kwargs=policy_kwargs,
        verbose=1,
        device='cpu'
    )
    
    print("âœ… çœŸæ­£é€šç”¨ SAC æ¨¡å‹åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“Š GPT-5 å»ºè®®å®ç°:")
    print(f"   âœ… å¯å˜å…³èŠ‚æ•°ç¯å¢ƒåŒ…è£…å™¨")
    print(f"   âœ… è‡ªå®šä¹‰ SAC ç­–ç•¥æ”¯æŒ J_max ç»´è¾“å‡º")
    print(f"   âœ… ç»Ÿä¸€ action_space å’Œ observation_space")
    print(f"   âœ… åŠ¨æ€ mask å’Œ link_lengths å¤„ç†")
    
    print("=" * 70)
    
    # è¯„ä¼°å›è°ƒ
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=f'./truly_universal_reacher_{max_joints}joints_best/',
        log_path=f'./truly_universal_reacher_{max_joints}joints_logs/',
        eval_freq=5000,
        n_eval_episodes=10,
        deterministic=True,
        render=False
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸ¯ å¼€å§‹çœŸæ­£é€šç”¨è®­ç»ƒ...")
    print("ğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"   æ€»æ­¥æ•°: {total_timesteps:,}")
    print("   è¯„ä¼°é¢‘ç‡: æ¯ 5,000 æ­¥")
    print("   é¢„æœŸ: çœŸæ­£æ”¯æŒä»»æ„å…³èŠ‚æ•°")
    print("=" * 70)
    
    start_time = time.time()
    
    model.learn(
        total_timesteps=total_timesteps,
        callback=eval_callback,
        log_interval=10,
        progress_bar=True
    )
    
    training_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("ğŸ† çœŸæ­£é€šç”¨è®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸ è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
    print("=" * 70)
    
    # ä¿å­˜æ¨¡å‹
    model_name = f"truly_universal_reacher_{max_joints}joints_final"
    model.save(model_name)
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º: {model_name}.zip")
    
    # æœ€ç»ˆè¯„ä¼°
    print("\nğŸ” æœ€ç»ˆè¯„ä¼° (20 episodes)...")
    mean_reward, std_reward = evaluate_policy(
        model, 
        eval_env, 
        n_eval_episodes=20,
        deterministic=True,
        render=False
    )
    
    print(f"ğŸ“Š çœŸæ­£é€šç”¨æ¨¡å‹è¯„ä¼°ç»“æœ:")
    print(f"   å¹³å‡å¥–åŠ±: {mean_reward:.2f} Â± {std_reward:.2f}")
    
    # æ¼”ç¤º
    print("\nğŸ® æ¼”ç¤ºçœŸæ­£é€šç”¨æ¨¡å‹ (10 episodes)...")
    demo_base_env = gym.make('Reacher-v5', render_mode='human')
    demo_env = VariableJointReacherWrapper(
        demo_base_env,
        max_joints=max_joints,
        current_joints=num_joints,
        link_lengths=link_lengths
    )
    
    episode_rewards = []
    success_count = 0
    
    for episode in range(10):
        obs, info = demo_env.reset()
        episode_reward = 0
        
        while True:
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = demo_env.step(action)
            episode_reward += reward
            
            if terminated or truncated:
                break
        
        episode_rewards.append(episode_reward)
        
        if episode_reward > -5:
            success_count += 1
            print(f"ğŸ¯ Episode {episode+1}: æˆåŠŸ! å¥–åŠ±={episode_reward:.2f}")
        else:
            print(f"ğŸ“Š Episode {episode+1}: å¥–åŠ±={episode_reward:.2f}")
    
    demo_env.close()
    
    demo_success_rate = success_count / 10
    demo_avg_reward = np.mean(episode_rewards)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š çœŸæ­£é€šç”¨æ¼”ç¤ºç»Ÿè®¡:")
    print(f"   æˆåŠŸç‡: {demo_success_rate:.1%} ({success_count}/10)")
    print(f"   å¹³å‡å¥–åŠ±: {demo_avg_reward:.2f}")
    print(f"   å¥–åŠ±æ ‡å‡†å·®: {np.std(episode_rewards):.2f}")
    
    print(f"\nğŸŒŸ çœŸæ­£é€šç”¨æ¶æ„ä¼˜åŠ¿:")
    print(f"   âœ… å¯å˜å…³èŠ‚æ•°ç¯å¢ƒåŒ…è£…å™¨")
    print(f"   âœ… ç»Ÿä¸€ J_max ç»´ action_space")
    print(f"   âœ… åŠ¨æ€ mask å’Œ link_lengths")
    print(f"   âœ… è‡ªå®šä¹‰ç­–ç•¥æ”¯æŒä»»æ„å…³èŠ‚æ•°")
    print(f"   ğŸŒ çœŸæ­£æ”¯æŒä»»æ„å…³èŠ‚æ•°æ‰©å±•")
    
    # æ¸…ç†
    env.close()
    eval_env.close()
    
    return {
        'mean_reward': mean_reward,
        'std_reward': std_reward,
        'training_time': training_time,
        'demo_success_rate': demo_success_rate,
        'demo_avg_reward': demo_avg_reward,
        'max_joints': max_joints,
        'joint_configs': joint_configs
    }

if __name__ == "__main__":
    print("ğŸŒŸ çœŸæ­£é€šç”¨ Reacher SAC è®­ç»ƒç³»ç»Ÿ")
    print("ğŸ’¡ åŸºäº GPT-5 å»ºè®®çš„å®Œæ•´å®ç°")
    print("ğŸ¯ ç›®æ ‡: çœŸæ­£æ”¯æŒä»»æ„å…³èŠ‚æ•°")
    print()
    
    try:
        result = train_truly_universal_reacher_sac(
            max_joints=10,
            joint_configs=[(2, [0.1, 0.1])],  # å…ˆæµ‹è¯• 2 å…³èŠ‚
            total_timesteps=50000
        )
        
        print(f"\nğŸŠ çœŸæ­£é€šç”¨è®­ç»ƒç»“æœæ€»ç»“:")
        print(f"   æœ€ç»ˆè¯„ä¼°å¥–åŠ±: {result['mean_reward']:.2f} Â± {result['std_reward']:.2f}")
        print(f"   è®­ç»ƒæ—¶é—´: {result['training_time']/60:.1f} åˆ†é’Ÿ")
        print(f"   æ¼”ç¤ºæˆåŠŸç‡: {result['demo_success_rate']:.1%}")
        print(f"   æ¼”ç¤ºå¹³å‡å¥–åŠ±: {result['demo_avg_reward']:.2f}")
        print(f"   æœ€å¤§æ”¯æŒå…³èŠ‚æ•°: {result['max_joints']}")
        
        print(f"\nğŸ† GPT-5 å»ºè®®å®ç°æˆåŠŸ!")
        print("   çœŸæ­£é€šç”¨æ¶æ„éªŒè¯å®Œæˆ!")
        
        print(f"\nâœ… ç°åœ¨å¯ä»¥æ‰©å±•åˆ°ä»»æ„å…³èŠ‚æ•°!")
        print("   åªéœ€ä¿®æ”¹ joint_configs å³å¯è®­ç»ƒä¸åŒå…³èŠ‚æ•°çš„ Reacher")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
